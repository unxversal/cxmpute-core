"use client"
import { notFound } from "next/navigation";
import ReactMarkdown from "react-markdown";
import remarkGfm from "remark-gfm";
import styles from "./docs.module.css";
import Link from "next/link";
import { CodeBlock } from "@/components/docs/CodeBlock";
import { 
  FileText, 
  Users, 
  Cpu, 
  Gift, 
  Info, 
  Volume2, 
  MessageSquare, 
  Search, 
  Globe, 
  Wrench,
  Brain,
  LucideIcon
} from "lucide-react";
export const docsContent: Record<string, string> = {
  "about": "Cxmpute is a distributed AI/Compute services platform that connects users who need AI services with providers who offer compute resources, creating a global network of AI compute power.\n\n## Our Mission\n\nWe're building the future of AI infrastructure by democratizing access to compute resources and creating new income opportunities for hardware owners worldwide.\n\n### The Problem We Solve\n\n- **Limited Access**: Many developers can't access enterprise-grade AI infrastructure easily\n- **Wasted Resources**: Millions of powerful computers sit idle while AI demand grows\n- **Centralization**: AI compute is concentrated in a few major cloud providers\n- **Pricing Uncertainty**: Unpredictable costs and complex pricing models\n\n### Our Solution\n\nCxmpute creates a **decentralized marketplace** where:\n- **Users** get affordable, high-quality AI services\n- **Providers** monetize their idle hardware\n- **Everyone** benefits from a more distributed, resilient AI infrastructure\n\n## How Cxmpute Works\n\n### The Network\n\n```bash\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Users & Apps  ‚îÇ    ‚îÇ  Cxmpute Core    ‚îÇ    ‚îÇ    Providers    ‚îÇ\n‚îÇ                 ‚îÇ    ‚îÇ  (AWS/Platform)  ‚îÇ    ‚îÇ                 ‚îÇ\n‚îÇ ‚Ä¢ Developers    ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ                  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ ‚Ä¢ Home Gamers   ‚îÇ\n‚îÇ ‚Ä¢ Businesses    ‚îÇ    ‚îÇ  ‚Ä¢ Load Balancer ‚îÇ    ‚îÇ ‚Ä¢ Data Centers  ‚îÇ\n‚îÇ ‚Ä¢ AI Companies  ‚îÇ    ‚îÇ  ‚Ä¢ Health Monitor‚îÇ    ‚îÇ ‚Ä¢ Universities  ‚îÇ\n‚îÇ ‚Ä¢ Researchers   ‚îÇ    ‚îÇ  ‚Ä¢ Orchestrator  ‚îÇ    ‚îÇ ‚Ä¢ Crypto Miners ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Core Components\n\n#### 1. **Cxmpute Core** (Central Platform)\n- **Load Balancing**: Routes requests to optimal providers\n- **Health Monitoring**: Ensures provider reliability\n- **Orchestration**: Manages the entire network\n- **Billing & Rewards**: Handles payments and provider compensation\n\n#### 2. **User Layer** (API & Dashboard)\n- **OpenAI-Compatible APIs**: Easy integration for developers\n- **Dashboard**: User-friendly interface for management\n- **Analytics**: Usage tracking and insights\n- **Account Management**: Usage monitoring and service access\n\n#### 3. **Provider Network** (Distributed Compute)\n- **Provider CLI**: Simple onboarding and management\n- **Auto-Discovery**: Automatic hardware profiling\n- **Service Orchestration**: Smart service assignment\n- **Earnings Dashboard**: Real-time earnings tracking\n\n## What We Offer\n\n### For Users\n\n**ü§ñ LLM Inference**\n- Chat completions with dozens of models\n- OpenAI-compatible API endpoints\n- Streaming and non-streaming responses\n- Custom model support\n\n**üîç Text Embeddings**\n- High-quality vector embeddings\n- Multiple embedding models\n- Batch processing support\n- Optimized for semantic search\n\n**üó£Ô∏è Text-to-Speech**\n- Natural voice synthesis\n- Multiple voice models\n- High-quality audio output\n- Fast generation times\n\n**üåê Web Scraping**\n- Intelligent content extraction\n- Markdown conversion\n- Batch URL processing\n- Metadata extraction\n\n**üõ†Ô∏è Advanced Features**\n- Tool calling and function execution\n- Structured JSON outputs\n- Custom response formats\n- Vision and multimodal capabilities\n\n### For Providers\n\n**üí∞ Passive Income**\n- Earn money from idle hardware\n- Automatic service orchestration\n- Real-time earnings tracking\n- Flexible participation levels\n\n**üèÜ Tiered System**\n- Rewards based on hardware capabilities\n- Higher tiers get premium rates\n- Performance-based bonuses\n- Referral earnings\n\n**üîß Simple Setup**\n- One-click CLI installation\n- Automatic hardware detection\n- No technical expertise required\n- Continuous updates and support\n\n## Technology Stack\n\n### Platform Architecture\n\n**Frontend & API**\n- **Next.js 15**: Modern React framework with App Router\n- **TypeScript**: Type-safe development\n- **OpenAI Compatibility**: Seamless integration\n\n**Backend Infrastructure**\n- **AWS Serverless**: Lambda, DynamoDB, API Gateway\n- **SST v3**: Infrastructure as Code\n- **Health Monitoring**: Real-time provider tracking\n- **Load Balancing**: Intelligent request routing\n\n**Provider Network**\n- **React Ink CLI**: Professional terminal interface\n- **Ollama/llama.cpp Integration**: Local LLM serving\n- **Tunneling**: Secure public access via ngrok\n- **Multi-platform**: macOS, Linux, Windows support\n\n### Security & Privacy\n\n**Data Protection**\n- End-to-end encryption for all communications\n- No access to provider's personal files\n- Isolated compute environments\n- Privacy-first architecture\n\n**Provider Security**\n- Sandboxed AI model execution\n- No system access beyond compute\n- Automatic security updates\n- Encrypted credential management\n\n**Network Security**\n- DDoS protection and mitigation\n- Rate limiting and abuse prevention\n- Health monitoring and automatic failover\n- Secure tunnel management\n\n## Business Model\n\n### Current Phase: Free Testnet\n\nDuring our testnet phase, all services are completely **free** for all users! Pricing for the mainnet launch is **to be determined (TBD)**.\n\nJoin our [Discord community](https://discord.gg/vE3xvFsZA8) to stay updated on pricing announcements, give feedback, and connect with other developers building with Cxmpute.\n\n### Future Model (TBD)\n\n- **Service-Based**: Revenue model to be determined based on community feedback\n- **Provider Rewards**: Fair compensation system for compute providers\n- **Premium Features**: Advanced analytics and custom model support\n- **Enterprise Solutions**: Dedicated infrastructure and support\n\n### Sustainability\n\n- **Community-Driven**: Network grows through user and provider satisfaction\n- **Efficient Resource Use**: Better utilization of existing hardware\n- **Fair Economics**: Balanced system benefiting all participants\n\n## Roadmap & Vision\n\n### Current Phase: Testnet\n\n‚úÖ **Complete**\n- Core platform infrastructure\n- Provider CLI and onboarding\n- Basic AI services (chat, embeddings, TTS, scraping)\n- Reward system and analytics\n\n### Near Term (6 months)\n\nüöß **In Progress**\n- Advanced model support and custom models\n- Enhanced provider analytics and optimization\n- Typescript and Python SDK and expanded API features\n- Mainnet launch with pricing structure (TBD)\n\n### Long Term (12+ months)\n\nüîÆ **Planned**\n- Cross-chain integration and payment options\n- Enterprise partnerships and custom solutions\n- Global expansion and regulatory compliance\n\n## Community & Governance\n\n### Open Source Commitment\n\n- **Transparent Development**: Core platform is open source\n- **Community Contributions**: Open to external developers\n- **Public Roadmap**: Community input on feature priorities\n- **Regular Updates**: Frequent communication and releases\n\n### Community Channels\n\n- **Discord**: [Real-time community chat](https://discord.gg/vE3xvFsZA8)\n- **GitHub**: [Open source development](https://github.com/unxversal/cxmpute-core)\n- **Twitter**: [@cxmpute](https://twitter.com/cxmpute) for news and updates\n- **Reddit**: [r/cxmpute](https://reddit.com/r/cxmpute) for discussions\n\n## Team & Support\n\n### Founded By\n\nExperienced developers and entrepreneurs passionate about democratizing AI infrastructure and creating new economic opportunities through technology.\n\n### Values\n\n- **Accessibility**: Making AI services available to everyone\n- **Transparency**: Open development and clear communication\n- **Community**: Building together with users and providers\n- **Innovation**: Pushing the boundaries of distributed computing\n\n### Support\n\n- **24/7 Community**: Active Discord community for peer support\n- **Documentation**: Comprehensive guides and API reference\n- **Email Support**: Direct contact for technical issues\n- **Regular Updates**: Continuous platform improvements\n\n## Getting Started\n\n### For Users\n1. **[Create Account](https://cxmpute.cloud/dashboard)** - Sign up and get your API key\n2. **[Read Docs](/docs/user)** - Learn about our APIs and services\n3. **[Make First Request](/docs/user#getting-started)** - Try our services for free\n\n### For Providers\n1. **[Download CLI](https://github.com/unxversal/cxmpute-core/releases)** - Get the provider software\n2. **[Follow Setup](/docs/provider)** - Complete onboarding process\n3. **[Start Earning](/docs/provider#step-5-start-earning)** - Begin receiving requests and rewards\n\n### For Developers\n1. **[API Documentation](/docs/user)** - Complete API reference\n2. **[Code Examples](/docs/text-to-text)** - Sample implementations\n3. **[Community](/docs#community--support)** - Join our developer community\n\n---\n\n**Ready to be part of the future of AI?** Whether you want to use our services or provide compute power, Cxmpute makes it simple to participate in the decentralized AI economy.\n\n[Get Started Today ‚Üí](https://cxmpute.cloud/dashboard) ",
  "advanced-llms": "Explore advanced capabilities of Cxmpute's large language models including thinking models, vision understanding, structured outputs, and specialized coding models.\n\n## Overview\n\nCxmpute provides access to cutting-edge language models with advanced features that go beyond basic text generation:\n\n### Advanced Capabilities\n\n- **Thinking Models**: Models with visible reasoning processes\n- **Vision Capabilities**: Analyze images and visual content  \n- **Structured Outputs**: Reliable JSON and schema-based responses\n- **Code Generation**: Specialized models optimized for programming tasks\n\n## Thinking Models\n\nAdvanced reasoning models that show their step-by-step thought process, leading to more accurate and transparent results.\n\n### Available Thinking Models\n\n- ‚úÖ **DeepSeek-R1** (1.5B, 7B, 8B, 14B, 32B, 70B) - Open reasoning models with performance approaching leading models\n- ‚úÖ **Qwen 3** (4B, 8B, 14B, 30B, 32B) - Latest generation with comprehensive reasoning capabilities\n\n### Enable Thinking Mode\n\n```python\nimport requests\n\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"your_user_id\",\n    \"Content-Type\": \"application/json\"\n}\n\nresponse = requests.post(\n    \"https://cxmpute.cloud/api/v1/chat/completions\",\n    headers=headers,\n    json={\n        \"model\": \"deepseek-r1:8b\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"How many r's are in the word strawberry? Think step by step.\"}\n        ],\n        \"think\": True\n    }\n)\n\nresult = response.json()\nmessage = result[\"choices\"][0][\"message\"]\n\nprint(\"Thinking Process:\")\nprint(message.get(\"thinking\", \"\"))\nprint(\"\\nFinal Answer:\")\nprint(message[\"content\"])\n```\n\n### When to Use Thinking Models\n\n**Best for:**\n- Complex reasoning tasks\n- Mathematical problems\n- Multi-step analysis\n- Debugging logical issues\n- Academic research questions\n\n**Trade-offs:**\n- **With Thinking**: More accurate, transparent reasoning, slower response\n- **Without Thinking**: Faster responses, direct answers, less transparency\n\n### Thinking Model Comparison\n\n```python\ndef compare_thinking_models(question):\n    \"\"\"Compare different thinking models on the same question\"\"\"\n    \n    models = [\"deepseek-r1:8b\", \"deepseek-r1:32b\", \"qwen3:8b\"]\n    results = {}\n    \n    for model in models:\n        response = requests.post(\n            \"https://cxmpute.cloud/api/v1/chat/completions\",\n            headers=headers,\n            json={\n                \"model\": model,\n                \"messages\": [{\"role\": \"user\", \"content\": question}],\n                \"think\": True\n            }\n        )\n        \n        result = response.json()\n        message = result[\"choices\"][0][\"message\"]\n        \n        results[model] = {\n            \"thinking\": message.get(\"thinking\", \"\"),\n            \"answer\": message[\"content\"]\n        }\n    \n    return results\n\n# Usage\nquestion = \"If a train travels 120 km in 90 minutes, what is its average speed in km/h?\"\ncomparisons = compare_thinking_models(question)\n\nfor model, result in comparisons.items():\n    print(f\"\\n=== {model} ===\")\n    print(\"Thinking:\", result[\"thinking\"][:200] + \"...\")\n    print(\"Answer:\", result[\"answer\"])\n```\n\n## Vision Models\n\nAnalyze images, charts, diagrams, and visual content with multimodal models that understand both text and images.\n\n### Available Vision Models\n\n- ‚úÖ **Gemma 3** (1B, 4B, 12B, 24B) - Capable vision-language model\n- ‚úÖ **Llama 3.2 Vision** (11B) - Instruction-tuned image reasoning\n- ‚úÖ **Qwen 2.5 VL** (3B, 7B, 32B, 72B) - Flagship vision-language model\n- ‚úÖ **Mistral Small 3.1** (24B) - Vision + tool calling + 128k context\n- ‚úÖ **Granite 3.2 Vision** (2B) - Document understanding specialist\n- ‚úÖ **MiniCPM-V** (8B) - Efficient multimodal understanding\n- ‚úÖ **LLaVA-Llama3** (8B) - LLaVA fine-tuned from Llama 3\n- ‚úÖ **Moondream** (1.8B) - Lightweight edge-optimized vision model\n\n### Image Analysis\n\n```python\nimport base64\n\ndef encode_image(image_path):\n    \"\"\"Convert image to base64 for API\"\"\"\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\ndef analyze_image(image_path, question, model=\"llama3.2-vision:11b\"):\n    \"\"\"Analyze an image with a vision model\"\"\"\n    \n    image_base64 = encode_image(image_path)\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": question},\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}\n                        }\n                    ]\n                }\n            ]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Usage examples\nresult = analyze_image(\"chart.png\", \"What trends do you see in this sales chart?\")\nprint(result)\n\nresult = analyze_image(\"document.jpg\", \"Extract all the text from this document\", \"granite3.2-vision\")\nprint(result)\n```\n\n### Vision Use Cases\n\n#### 1. Document Processing\n```python\ndef extract_document_data(image_path):\n    \"\"\"Extract structured data from documents using Granite 3.2 Vision\"\"\"\n    return analyze_image(\n        image_path,\n        \"Extract all text, tables, and structured data from this document. Format as JSON.\",\n        \"granite3.2-vision\"\n    )\n```\n\n#### 2. Chart Analysis\n```python\ndef analyze_chart(image_path):\n    \"\"\"Analyze charts and graphs\"\"\"\n    return analyze_image(\n        image_path,\n        \"Analyze this chart. Describe the trends, key insights, and data points.\",\n        \"qwen2.5vl:7b\"\n    )\n```\n\n#### 3. Visual Question Answering\n```python\ndef visual_qa(image_path, question):\n    \"\"\"Answer questions about images\"\"\"\n    return analyze_image(\n        image_path,\n        f\"Answer this question about the image: {question}\",\n        \"llama3.2-vision:11b\"\n    )\n```\n\n#### 4. Multi-Image Comparison\n```python\ndef compare_images(image_paths, comparison_question):\n    \"\"\"Compare multiple images\"\"\"\n    \n    content = [{\"type\": \"text\", \"text\": comparison_question}]\n    \n    for i, image_path in enumerate(image_paths):\n        image_base64 = encode_image(image_path)\n        content.append({\n            \"type\": \"text\", \n            \"text\": f\"Image {i+1}:\"\n        })\n        content.append({\n            \"type\": \"image_url\",\n            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}\n        })\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"qwen2.5vl:32b\",\n            \"messages\": [{\"role\": \"user\", \"content\": content}]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n```\n\n## Structured Outputs & Tool Use\n\nModels that can reliably generate JSON responses and call functions for complex workflows.\n\n### Tool-Capable Models\n\nAll models from our [tool calling documentation](/docs/tool-use-json):\n\n- ‚úÖ **Qwen 3** (4B, 8B, 14B, 30B, 32B) - Full tool calling support\n- ‚úÖ **Llama 3.1** (8B) - Full tool calling support\n- ‚úÖ **Llama 3.2** (1B, 3B) - Tool calling support\n- ‚úÖ **Llama 3.3** (70B) - Tool calling support\n- ‚úÖ **Qwen 2.5** (7B, 14B, 32B, 72B) - Tool calling support\n- ‚úÖ **Qwen 2.5 Coder** (3B, 7B, 14B, 32B) - Tool calling support\n- ‚úÖ **QwQ** (32B) - Reasoning with tool calling support\n- ‚úÖ **Cogito** (3B, 8B, 14B, 32B, 70B) - Tool calling support\n- ‚úÖ **Mistral** (7B) - Tool calling support\n- ‚úÖ **Mistral Nemo** (12B) - Tool calling support\n- ‚úÖ **Mistral Small 3.1** (24B) - Vision + tool calling support\n- ‚úÖ **Phi-4 Mini** (3.8B) - Tool calling support\n- ‚úÖ **Granite 3.2 Vision** (2B) - Vision + tool calling support\n\n### Structured JSON Output\n\n```python\ndef get_structured_analysis(text, model=\"qwen3:8b\"):\n    \"\"\"Get structured analysis in JSON format\"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [\n                {\n                    \"role\": \"user\", \n                    \"content\": f\"\"\"Analyze this text and respond with valid JSON only:\n\nText: {text}\n\nRequired JSON structure:\n{{\n    \"sentiment\": \"positive|negative|neutral\",\n    \"key_topics\": [\"topic1\", \"topic2\"],\n    \"summary\": \"brief summary\",\n    \"confidence\": 0.0-1.0,\n    \"entities\": {{\n        \"people\": [\"name1\", \"name2\"],\n        \"organizations\": [\"org1\", \"org2\"],\n        \"locations\": [\"loc1\", \"loc2\"]\n    }}\n}}\"\"\"\n                }\n            ],\n            \"response_format\": {\"type\": \"json_object\"}\n        }\n    )\n    \n    return json.loads(response.json()[\"choices\"][0][\"message\"][\"content\"])\n```\n\n### Function Calling\n\n```python\ndef create_data_analysis_tool():\n    \"\"\"Example tool for data analysis\"\"\"\n    \n    tools = [\n        {\n            \"type\": \"function\",\n            \"function\": {\n                \"name\": \"analyze_data\",\n                \"description\": \"Analyze numerical data and generate insights\",\n                \"parameters\": {\n                    \"type\": \"object\",\n                    \"properties\": {\n                        \"data\": {\n                            \"type\": \"array\",\n                            \"items\": {\"type\": \"number\"},\n                            \"description\": \"Array of numerical values\"\n                        },\n                        \"analysis_type\": {\n                            \"type\": \"string\",\n                            \"enum\": [\"trend\", \"statistics\", \"correlation\"],\n                            \"description\": \"Type of analysis to perform\"\n                        }\n                    },\n                    \"required\": [\"data\", \"analysis_type\"]\n                }\n            }\n        }\n    ]\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"qwen3:14b\",\n            \"messages\": [\n                {\"role\": \"user\", \"content\": \"Analyze this sales data: [100, 120, 115, 140, 160, 180, 200]\"}\n            ],\n            \"tools\": tools\n        }\n    )\n    \n    result = response.json()\n    message = result[\"choices\"][0][\"message\"]\n    \n    if message.get(\"tool_calls\"):\n        tool_call = message[\"tool_calls\"][0]\n        function_name = tool_call[\"function\"][\"name\"]\n        function_args = json.loads(tool_call[\"function\"][\"arguments\"])\n        \n        print(f\"Model wants to call: {function_name}\")\n        print(f\"With arguments: {function_args}\")\n        \n        # Here you would execute the actual function\n        # and return the result back to the model\n    \n    return result\n```\n\n## Code Generation Models\n\nSpecialized models optimized for programming tasks, code generation, and software development.\n\n### Available Code Models\n\n- ‚úÖ **Qwen 2.5 Coder** (3B, 7B, 14B, 32B) - Latest code-specific models\n- ‚úÖ **DeepSeek Coder** (1.3B, 6.7B) - Efficient coding models\n- ‚úÖ **DeepSeek Coder V2** (16B) - Advanced coding with reasoning\n- ‚úÖ **DeepCoder** (14B) - Specialized deep coding model\n- ‚úÖ **CodeGemma** (2B, 7B) - Google's code generation models\n\n### Code Generation\n\n```python\ndef generate_code(task, language=\"python\", model=\"qwen2.5-coder:7b\"):\n    \"\"\"Generate code for specific programming tasks\"\"\"\n    \n    prompt = f\"\"\"\nTask: {task}\nLanguage: {language}\n\nRequirements:\n- Write clean, well-commented code\n- Include error handling where appropriate\n- Provide usage examples\n- Follow best practices for {language}\n\"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.2  # Lower temperature for more deterministic code\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Usage examples\napi_code = generate_code(\"Create a REST API endpoint for user authentication using Flask\")\nprint(api_code)\n\nalgorithm_code = generate_code(\"Implement a binary search algorithm\", \"python\", \"deepseek-coder:6.7b\")\nprint(algorithm_code)\n```\n\n### Code Review and Debugging\n\n```python\ndef review_code(code, model=\"qwen2.5-coder:14b\"):\n    \"\"\"Review code for bugs and improvements\"\"\"\n    \n    prompt = f\"\"\"\nPlease review this code and provide:\n1. Bug identification\n2. Security vulnerabilities\n3. Performance improvements\n4. Best practice recommendations\n5. Refactored version if needed\n\nCode to review:\n\\`\\`\\`\n{code}\n\\`\\`\\`\n\"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\ndef explain_code(code, model=\"deepseek-coder-v2:16b\"):\n    \"\"\"Explain complex code snippets\"\"\"\n    \n    prompt = f\"\"\"\nExplain this code in detail:\n1. What it does\n2. How it works\n3. Key algorithms or patterns used\n4. Potential use cases\n\nCode:\n\\`\\`\\`\n{code}\n\\`\\`\\`\n\"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n```\n\n### Multi-Language Code Generation\n\n```python\ndef generate_multilang_solution(problem, languages=[\"python\", \"javascript\", \"rust\"]):\n    \"\"\"Generate solutions in multiple programming languages\"\"\"\n    \n    solutions = {}\n    \n    for lang in languages:\n        # Choose optimal model for each language\n        if lang in [\"python\", \"javascript\"]:\n            model = \"qwen2.5-coder:7b\"\n        elif lang in [\"rust\", \"c++\", \"go\"]:\n            model = \"deepseek-coder-v2:16b\"\n        else:\n            model = \"codegemma:7b\"\n        \n        code = generate_code(problem, lang, model)\n        solutions[lang] = code\n    \n    return solutions\n\n# Usage\nproblem = \"Implement a function to find the longest common subsequence between two strings\"\nsolutions = generate_multilang_solution(problem)\n\nfor lang, code in solutions.items():\n    print(f\"\\n=== {lang.upper()} ===\")\n    print(code[:300] + \"...\")\n```\n\n### Code Completion\n\nComplete partially written code with intelligent suggestions and context awareness.\n\n```python\ndef complete_code(partial_code, language=\"python\", model=\"qwen2.5-coder:14b\"):\n    \"\"\"Complete partially written code\"\"\"\n    \n    prompt = f\"\"\"Complete this {language} code. Only provide the completion, not the entire code:\n\n\\`\\`\\`{language}\n{partial_code}\n\\`\\`\\`\n\nComplete the code from where it left off. Provide clean, efficient completion that follows best practices.\"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.1,  # Very low temperature for consistent completions\n            \"max_tokens\": 500\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\ndef complete_function(function_signature, description=\"\", model=\"deepseek-coder:6.7b\"):\n    \"\"\"Complete a function based on its signature and description\"\"\"\n    \n    prompt = f\"\"\"Complete this function implementation:\n\n{function_signature}\n    # {description}\n    \nProvide only the function body (implementation inside the function).\"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.2\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Usage Examples\n\n# 1. Complete a loop\npartial_loop = \"\"\"\ndata = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\nresult = []\nfor item in data:\n    if item % 2 == 0:\n\"\"\"\n\ncompletion = complete_code(partial_loop, \"python\")\nprint(\"Completed code:\")\nprint(partial_loop + completion)\n\n# 2. Complete a function\nfunction_sig = \"\"\"\ndef binary_search(arr, target):\n\"\"\"\n\nfunction_body = complete_function(\n    function_sig, \n    \"Implement binary search algorithm to find target in sorted array\"\n)\nprint(\"Completed function:\")\nprint(function_sig + function_body)\n\n# 3. Complete class method\npartial_class = \"\"\"\nclass DataProcessor:\n    def __init__(self, data):\n        self.data = data\n    \n    def filter_data(self, condition_func):\n        filtered = []\n        for item in self.data:\n\"\"\"\n\ncompletion = complete_code(partial_class, \"python\", \"qwen2.5-coder:32b\")\nprint(\"Completed class method:\")\nprint(partial_class + completion)\n\n# 4. Complete error handling\npartial_error = \"\"\"\ndef safe_divide(a, b):\n    try:\n        result = a / b\n\"\"\"\n\ncompletion = complete_code(partial_error, \"python\")\nprint(\"Completed with error handling:\")\nprint(partial_error + completion)\n```\n\n### Interactive Code Completion\n\n```python\ndef interactive_completion_session(model=\"qwen2.5-coder:14b\"):\n    \"\"\"Interactive code completion session\"\"\"\n    \n    print(\"=== Interactive Code Completion ===\")\n    print(\"Type your code and press Enter twice to get completion.\")\n    print(\"Type 'exit' to quit.\\n\")\n    \n    while True:\n        print(\"Enter your partial code:\")\n        lines = []\n        while True:\n            line = input()\n            if line == \"exit\":\n                return\n            if line == \"\" and lines:  # Empty line after content\n                break\n            lines.append(line)\n        \n        if not lines:\n            continue\n            \n        partial_code = \"\\n\".join(lines)\n        \n        # Detect language based on syntax hints\n        language = \"python\"  # Default\n        if \"function\" in partial_code or \"=>\" in partial_code:\n            language = \"javascript\"\n        elif \"fn \" in partial_code or \"let mut\" in partial_code:\n            language = \"rust\"\n        elif \"#include\" in partial_code or \"std::\" in partial_code:\n            language = \"cpp\"\n        \n        print(f\"\\nDetected language: {language}\")\n        print(\"Completing...\")\n        \n        try:\n            completion = complete_code(partial_code, language, model)\n            print(f\"\\n--- Completion ---\")\n            print(completion)\n            print(f\"\\n--- Full Code ---\")\n            print(partial_code + completion)\n            print(\"=\" * 50)\n        except Exception as e:\n            print(f\"Error: {e}\")\n\n# Usage\n# interactive_completion_session()\n```\n\n### Context-Aware Completion\n\n```python\ndef context_aware_completion(code_context, partial_code, model=\"deepseek-coder-v2:16b\"):\n    \"\"\"Complete code with additional context from the codebase\"\"\"\n    \n    prompt = f\"\"\"Given this codebase context:\n\n{code_context}\n\nComplete this partial code:\n\\`\\`\\`\n{partial_code}\n\\`\\`\\`\n\nConsider the existing code structure, naming conventions, and patterns used in the context.\"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.15\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Example with context\ncodebase_context = \"\"\"\nclass APIClient:\n    def __init__(self, base_url, api_key):\n        self.base_url = base_url\n        self.api_key = api_key\n        self.session = requests.Session()\n    \n    def _make_request(self, method, endpoint, **kwargs):\n        url = f\"{self.base_url}/{endpoint}\"\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\"}\n        return self.session.request(method, url, headers=headers, **kwargs)\n    \n    def get_user(self, user_id):\n        return self._make_request(\"GET\", f\"users/{user_id}\")\n\"\"\"\n\npartial_new_method = \"\"\"\n    def create_user(self, user_data):\n\"\"\"\n\ncompletion = context_aware_completion(codebase_context, partial_new_method)\nprint(\"Context-aware completion:\")\nprint(partial_new_method + completion)\n```\n\n## Advanced Use Cases\n\n### 1. Multi-Modal Code Analysis\n\nCombine vision and code models to analyze code screenshots or diagrams:\n\n```python\ndef analyze_code_screenshot(image_path, model=\"granite3.2-vision\"):\n    \"\"\"Extract and analyze code from screenshots\"\"\"\n    \n    extracted_code = analyze_image(\n        image_path,\n        \"Extract all code from this screenshot. Preserve formatting and syntax.\",\n        model\n    )\n    \n    # Then analyze with code model\n    review = review_code(extracted_code, \"qwen2.5-coder:14b\")\n    \n    return {\n        \"extracted_code\": extracted_code,\n        \"analysis\": review\n    }\n```\n\n### 2. Thinking + Vision Analysis\n\nCombine thinking models with vision for complex visual reasoning:\n\n```python\ndef deep_visual_analysis(image_path, question):\n    \"\"\"Perform deep visual analysis with reasoning\"\"\"\n    \n    image_base64 = encode_image(image_path)\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"qwen3:14b\",  # Thinking + vision capable\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": f\"{question}\\n\\nThink step by step about what you see.\"},\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}\n                        }\n                    ]\n                }\n            ],\n            \"think\": True\n        }\n    )\n    \n    result = response.json()\n    message = result[\"choices\"][0][\"message\"]\n    \n    return {\n        \"thinking\": message.get(\"thinking\", \"\"),\n        \"analysis\": message[\"content\"]\n    }\n```\n\n### 3. Structured Code Generation\n\nGenerate code with structured outputs for better integration:\n\n```python\ndef generate_structured_code(requirements, model=\"qwen2.5-coder:14b\"):\n    \"\"\"Generate code with structured metadata\"\"\"\n    \n    prompt = f\"\"\"\nGenerate code for: {requirements}\n\nRespond with valid JSON containing:\n{{\n    \"code\": \"the actual code\",\n    \"language\": \"programming language\",\n    \"dependencies\": [\"list\", \"of\", \"dependencies\"],\n    \"complexity\": \"simple|medium|complex\",\n    \"explanation\": \"brief explanation\",\n    \"tests\": \"example test code\",\n    \"usage_example\": \"how to use the code\"\n}}\n\"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"response_format\": {\"type\": \"json_object\"}\n        }\n    )\n    \n    return json.loads(response.json()[\"choices\"][0][\"message\"][\"content\"])\n```\n\n## Performance Optimization\n\n### Model Selection Guide\n\n```python\ndef select_optimal_model(task_type, complexity=\"medium\", speed_requirement=\"balanced\"):\n    \"\"\"Select the best model for your specific needs\"\"\"\n    \n    models = {\n        \"thinking\": {\n            \"simple\": \"deepseek-r1:1.5b\",\n            \"medium\": \"deepseek-r1:8b\", \n            \"complex\": \"deepseek-r1:32b\"\n        },\n        \"vision\": {\n            \"simple\": \"moondream\",\n            \"medium\": \"llama3.2-vision:11b\",\n            \"complex\": \"qwen2.5vl:32b\"\n        },\n        \"coding\": {\n            \"simple\": \"codegemma:2b\",\n            \"medium\": \"qwen2.5-coder:7b\",\n            \"complex\": \"deepseek-coder-v2:16b\"\n        },\n        \"structured\": {\n            \"simple\": \"qwen3:4b\",\n            \"medium\": \"qwen3:14b\",\n            \"complex\": \"qwen3:32b\"\n        }\n    }\n    \n    if speed_requirement == \"fastest\":\n        complexity = \"simple\"\n    elif speed_requirement == \"quality\":\n        complexity = \"complex\"\n    \n    return models.get(task_type, {}).get(complexity, \"llama3.1:8b\")\n\n# Usage\nmodel = select_optimal_model(\"vision\", \"complex\", \"quality\")\nprint(f\"Recommended model: {model}\")\n```\n\n## Pricing\n\nDuring our **testnet phase**, all advanced model features are completely **free** for all users! Pricing for the mainnet launch is **to be determined (TBD)**.\n\nJoin our [Discord community](https://discord.gg/vE3xvFsZA8) to stay updated on pricing announcements, give feedback, and connect with other developers building with Cxmpute.\n\n## Support\n\n- **Discord**: [Community support](https://discord.gg/vE3xvFsZA8)\n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready for advanced AI?** Explore thinking models, vision understanding, and structured outputs with Cxmpute's cutting-edge capabilities! ",
  "embeddings": "Generate high-quality vector embeddings for semantic search, RAG applications, and AI-powered features using Cxmpute's distributed embedding service.\n\n## Overview\n\nCxmpute's Text Embeddings service converts text into dense vector representations that capture semantic meaning. These embeddings are essential for building semantic search, recommendation systems, and retrieval-augmented generation (RAG) applications.\n\n### Key Features\n\n- **High-Quality Embeddings**: State-of-the-art embedding models\n- **Multiple Models**: Various embedding models optimized for different use cases\n- **Batch Processing**: Efficient processing of multiple texts\n- **Global Network**: Low-latency access worldwide\n- **OpenAI Compatible**: Familiar API structure\n\n## Quick Start\n\n### Basic Request\n\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/embeddings \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"nomic-embed-text\",\n    \"input\": \"Cxmpute provides distributed AI inference services.\"\n  }'\n```\n\n### Python Example\n\n```python\nimport requests\n\nurl = \"https://cxmpute.cloud/api/v1/embeddings\"\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"YOUR_USER_ID\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"model\": \"nomic-embed-text\",\n    \"input\": \"This is a sample text for embedding\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n\nembedding = result[\"data\"][0][\"embedding\"]\nprint(f\"Embedding dimension: {len(embedding)}\")\n```\n\n## API Reference\n\n### Endpoint\n\n```http\nPOST /v1/embeddings\n```\n\n### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `model` | string | Yes | Embedding model name |\n| `input` | string/array | Yes | Text(s) to embed |\n| `truncate` | boolean | No | Truncate input to model's max length |\n\n### Available Models\n\n| Model | Dimension | Description |\n|-------|-----------|-------------|\n| `nomic-embed-text` | 768 | General-purpose embeddings |\n| `all-minilm-l6-v2` | 384 | Fast, lightweight |\n| `bge-large-en-v1.5` | 1024 | High-quality English |\n\n### Response Format\n\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"embedding\", \n      \"embedding\": [0.1, -0.2, 0.3, ...],\n      \"index\": 0\n    }\n  ],\n  \"model\": \"nomic-embed-text\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\n```\n\n## Use Cases\n\n### 1. Semantic Search\n\nBuild search systems that understand meaning, not just keywords.\n\n### 2. Recommendation Systems\n\nRecommend content based on semantic similarity.\n\n### 3. RAG Applications\n\nEnhance LLM responses with relevant context retrieval.\n\n### 4. Document Clustering\n\nGroup similar documents automatically.\n\n### 5. Text Classification\n\nClassify text using embedding-based similarity.\n\n## Pricing\n\nDuring our **testnet phase**, all services are completely **free** for all users! Pricing for the mainnet launch is **to be determined (TBD)**.\n\nJoin our [Discord community](https://discord.gg/vE3xvFsZA8) to stay updated on pricing announcements, give feedback, and connect with other developers building with Cxmpute.\n\n## Support\n\n- **Discord**: [Community support](https://discord.gg/vE3xvFsZA8)\n- **Contact**: [Contact us](https://tally.so/r/w4DvLA)\n\n---\n\n**Ready to build semantic applications?** Start with our high-quality embeddings and create intelligent search, recommendation, and AI systems! ",
  "index": "Welcome to the Cxmpute documentation! Cxmpute is a distributed AI/Compute services platform that connects users who need AI services with providers who offer compute resources, creating a global network of AI compute power.\n\n## Quick Start\n\n### For Users\n- **Get Started**: [Create an account](https://cxmpute.cloud/dashboard) and start using AI services in minutes\n- **API Reference**: [Complete API documentation](/docs/user) for all endpoints\n- **Service Guides**: Learn about specific services like [chat](/docs/text-to-text), [embeddings](/docs/embeddings), [TTS](/docs/text-to-speech), and [scraping](/docs/scraping)\n\n### For Providers\n- **Become a Provider**: [Download the CLI](https://github.com/unxversal/cxmpute-core/releases) and start earning rewards\n- **Provider Guide**: [Complete setup instructions](/docs/provider) and earning tips\n- **Rewards System**: Learn about [earnings and referrals](/docs/rewards)\n\n## What is Cxmpute?\n\nCxmpute provides inference and related services powered by a global network of nodes run by providers. We offer:\n\n- **LLM Inference**: OpenAI-compatible chat completions with dozens of models\n- **Text Embeddings**: High-quality vector embeddings for your applications\n- **Text-to-Speech**: Natural voice synthesis with multiple voice models\n- **Web Scraping**: Reliable content extraction and markdown conversion\n- **Tool Use & JSON**: Structured outputs and function calling capabilities\n\n[Learn more about Cxmpute ‚Üí](/docs/about)\n\n## Service Documentation\n\n### AI Services\n- [**Text-to-Text (LLM)**](/docs/text-to-text) - Chat completions and text generation\n- [**Embeddings**](/docs/embeddings) - Vector embeddings for semantic search\n- [**Text-to-Speech**](/docs/text-to-speech) - Audio generation from text\n- [**Web Scraping**](/docs/scraping) - Content extraction and processing\n- [**Tool Use & JSON**](/docs/tool-use-json) - Structured outputs and function calling\n- [**Advanced LLMs**](/docs/advanced-llms) - Advanced features for large language models\n\n### Platform\n- [**User Guide**](/docs/user) - Complete API reference and getting started\n- [**Provider Guide**](/docs/provider) - How to become a compute provider\n- [**Rewards System**](/docs/rewards) - Earning rewards and referral program\n- [**About Cxmpute**](/docs/about) - Platform overview and architecture\n\n## Key Features\n\n### üöÄ **Easy to Use**\n- OpenAI-compatible APIs - just change the base URL\n- Simple authentication with API keys\n- Comprehensive documentation and examples\n\n### üåç **Global Network**\n- Distributed provider network for low latency\n- Automatic load balancing and health monitoring\n- Geographic distribution for optimal performance\n\n### üí∞ **Cost-Effective**\n- Currently free during testnet phase\n- Future pricing to be announced (TBA)\n- Competitive rates through decentralized provider network\n\n### üîí **Secure & Reliable**\n- Enterprise-grade security and privacy\n- 99.5%+ uptime with automatic failover\n- Provider verification and health monitoring\n\n## Getting Started\n\n### 1. Create an Account\nVisit the [Cxmpute Dashboard](https://cxmpute.cloud/dashboard) to create your account and get your API key.\n\n### 2. Make Your First Request\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/chat/completions \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"Hello, world!\"}]\n  }'\n```\n\n### 3. Explore Services\nTry different AI services:\n- [Chat completions](/docs/text-to-text) for conversations and text generation\n- [Embeddings](/docs/embeddings) for semantic search and RAG\n- [Text-to-speech](/docs/text-to-speech) for voice applications\n- [Web scraping](/docs/scraping) for data collection\n\n## Testnet Phase\n\nüéâ **All services are currently free!** During our testnet phase, you can use all Cxmpute services without charges. Pricing for the mainnet launch is **to be determined (TBD)**.\n\nJoin our [Discord community](https://discord.gg/vE3xvFsZA8) to stay updated on pricing announcements, give feedback, and connect with other developers building with Cxmpute.\n\n[Learn more about rewards ‚Üí](/docs/rewards)\n\n## Community & Support\n\n- **Discord**: Join our [community](https://discord.gg/vE3xvFsZA8) for support and latest news\n- **GitHub**: Check out our [open source code](https://github.com/unxversal/cxmpute-core)\n- **Email**: Contact us at support@cxmpute.cloud\n\n## Model Catalog\n\nExplore our full range of available models at [cxmpute.cloud/models](https://cxmpute.cloud/models).\n\n---\n\n*Ready to get started? [Create your account](https://cxmpute.cloud/dashboard) or [become a provider](https://github.com/unxversal/cxmpute-core/releases) today!* ",
  "provider": "Transform your computer into an AI compute provider and start earning rewards! This guide will walk you through becoming part of the Cxmpute network.\n\n## What is a Cxmpute Provider?\n\nCxmpute provides inference and related services powered by a global network of nodes run by providers. [Learn more about using Cxmpute services ‚Üí](/docs/user)\n\nA **provider** is someone who runs a Cxmpute node on their computer. This node is essentially an inference server connected to our main orchestrator, so requests are routed to your node for inference and completion, and you are rewarded proportionally.\n\n## Hardware Tiers\n\nWe categorize devices into different tiers based on their capabilities. **We need devices of all tiers**, but we highly recommend becoming a provider if you have at least **16GB RAM and 30GB free disc space**.\n\n### Device Tiers\n\n| Tier | Name | VRAM | Capabilities | Testnet Rewards |\n|------|------|------|--------------|-----------------|\n| **Tier 0** | Basic | <1GB | Lightweight tasks, TTS | Points & Rewards |\n| **Tier 1** | Tide Pool | 1-4GB | Small embeddings, basic TTS | Points & Rewards |\n| **Tier 2** | Blue Surf | 4-8GB | Small LLMs, all services | Points & Rewards |\n| **Tier 3** | Open Ocean | 8-22GB | Medium LLMs, high throughput | Points & Rewards |\n| **Tier 4** | Mariana Depth | 22GB+ | Large LLMs, premium service | Points & Rewards |\n\n*During testnet, all providers earn points and rewards. Mainnet earnings structure is to be determined (TBD).*\n\n### System Requirements\n\n#### Minimum Requirements\n- **OS**: macOS 10.15+, Linux (Ubuntu 18.04+), Windows 10+\n- **RAM**: 4GB+ (16GB+ recommended for LLM services)\n- **Storage**: 10GB+ free space\n- **Internet**: Stable broadband connection\n\n#### Optimal Requirements\n- **GPU**: NVIDIA GPU with 8GB+ VRAM (for LLM hosting)\n- **RAM**: 16GB+ (32GB+ for large models)\n- **CPU**: Multi-core processor (Intel i5/AMD Ryzen 5+/Apple Silicon)\n- **Internet**: High-speed connection (100+ Mbps)\nIf your system is supported by llama.cpp, your device is eligible to be a provider.\n\n## Getting Started\n\n### Step 1: Create an Account\n\nCreate an account in the [Cxmpute Dashboard](https://cxmpute.cloud/dashboard).\n\n### Step 2: Download the Provider CLI\n\nDownload the Cxmpute Provider CLI from our releases:\nüëâ **[Download Latest Release](https://github.com/unxversal/cxmpute-core/releases)**\n\n#### Choose Your Platform\n\n**üçé macOS**\n- Intel Macs (x64): `cxmpute-provider-macos` or `cxmpute-provider-macos-intel`\n- Apple Silicon (M1/M2/M3/M4): `cxmpute-provider-macos-arm64` or `cxmpute-provider-macos-m1`\n\n**üêß Linux**\n- x64: `cxmpute-provider-linux`\n\n**ü™ü Windows**\n- x64: `cxmpute-provider.exe` or `cxmpute-provider-windows.exe`\n\n### Step 3: Install and Setup\n\n#### Make Executable (macOS/Linux)\n\n```bash\n# Navigate to your Downloads folder\ncd ~/Downloads\n\n# Make the file executable\nchmod +x cxmpute-provider-macos    # or cxmpute-provider-linux\n```\n\n#### Run the Provider\n\n**üçé macOS**\n```bash\n# Run directly\n./cxmpute-provider-macos\n\n# First time? macOS might show security warning:\n# Go to System Preferences > Security & Privacy > General\n# Click \"Allow Anyway\" for cxmpute-provider-macos\n```\n\n**üêß Linux**\n```bash\n# Run directly\n./cxmpute-provider-linux\n```\n\n**ü™ü Windows**\n```bash\n# Run directly (double-click or command line)\ncxmpute-provider.exe\n\n# First time? Windows might show SmartScreen warning:\n# Click \"More info\" > \"Run anyway\"\n```\n\n### Step 4: Follow the Setup Wizard\n\nWhen you run `cxmpute-provider` for the first time, you'll see:\n\n```bash\n ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù\n‚ñà‚ñà‚ïë      ‚ïö‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  \n‚ñà‚ñà‚ïë      ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  \n‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\nüîß SETUP WIZARD\n```\n\nThe CLI will guide you through:\n\n1. **Hardware Detection**: Automatic system profiling\n2. **Provider Registration**: Creating your provider account\n3. **Service Configuration**: Selecting services based on your hardware\n4. **Network Setup**: Configuring tunnels and connectivity\n\n### Step 5: Start Earning!\n\nAfter setup, you'll see your **provider dashboard**:\n\n```bash\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ PROVIDER/REFERRAL ID: abc123...                        ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ ‚óè STATUS: ACTIVE                                       ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ TODAY'S POINTS: 1,245    ‚îÇ ‚îÇ ALL TIME POINTS: 34,210   ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ REFERRALS: 3                    LEARN MORE             ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ DEVICE TIER: Deep Ocean (Tier 4 - 22GB+ VRAM)         ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n```\n\n**üéâ Congratulations!** Your node is running and earning rewards.\n\n**Join our [Discord community](https://discord.gg/vE3xvFsZA8)** to stay updated on earnings announcements, connect with other providers, and get support!\n\n## Maximizing Your Earnings\n\n### üí∞ Earning Rewards\n\n#### Service Types & Rewards\n\nDuring testnet, providers earn points and rewards for all services. Mainnet earnings structure is **to be announced (TBA)**.\n\n- **ü§ñ LLM Inference**: Points for token generation (varies by model)\n- **üîç Embeddings**: Points for embedding requests\n- **üåê Web Scraping**: Points per scraping request\n- **üó£Ô∏è Text-to-Speech**: Points for audio generation\n\n#### Best Practices\n\n1. **‚è∞ Uptime**: Keep your provider running as much as you can for maximum earnings\n2. **üöÄ Performance**: Ensure stable internet and optimal hardware\n3. **üë• Referrals**: Invite others and earn from their activity ([learn more](/docs/rewards))\n4. **üîÑ Updates**: Keep your CLI updated for new features\n5. **üîß Optimization**: Run when you're not using your computer to maximize resources\n\n### When to Run Your Node\n\n**üí° Recommended**: Run your node when you're not using your computer, as it tries to use most of your computing power to maximize earnings.\n\n- **üåô Overnight**: Perfect time for maximum resource allocation\n- **üìÖ Weekends**: Extended periods of high earning potential\n- **üéØ Scheduled**: Set up automated schedules for consistent operation\n\n## How Providers Earn\n\n### Points System\n\nProviders earn **points** based on:\n- **Usage**: Requests processed and tokens generated\n- **Quality**: Response time and reliability\n- **Referrals**: People you invite who become active users or providers\n\n### Revenue Distribution\n\nAt the end of each **epoch** (usually a month), revenue is distributed proportionally based on points accumulated:\n\n1. Platform collects revenue from users\n2. Points are tallied for all providers\n3. Revenue is distributed based on each provider's share of total points\n4. Payments are processed automatically\n\n### Earning More Points\n\n- **üìà High Uptime**: Consistent availability increases point multiplier\n- **‚ö° Fast Response**: Better performance = more requests routed to you\n- **üéØ Referrals**: Earn bonus points from referred users' activity\n- **üîß Better Hardware**: Higher tiers get priority for premium requests\n\n## Service Types\n\nYour node will automatically provide services based on your hardware capabilities:\n\n### ü§ñ LLM Inference (`/chat/completions`)\n- **Requirements**: 16GB+ VRAM recommended\n- **Models**: Various sizes from 7B to 70B+ parameters\n- **Earnings**: Highest earning potential\n\n### üîç Embeddings (`/embeddings`)\n- **Requirements**: 2GB+ VRAM\n- **Models**: Specialized embedding models\n- **Earnings**: Consistent, moderate volume\n\n### üó£Ô∏è Text-to-Speech (`/tts`)\n- **Requirements**: 1GB+ VRAM or good CPU\n- **Models**: Voice synthesis models\n- **Earnings**: Steady demand\n\n### üåê Web Scraping (`/scrape`)\n- **Requirements**: Good internet connection\n- **Function**: Content extraction and processing\n- **Earnings**: Per-request based\n\n## Troubleshooting\n\n### Common Issues\n\n#### \"Command not found: cxmpute-provider\"\n- **Cause**: Binary not in PATH or not executable\n- **Fix**: Follow the installation steps above, ensure file is executable\n\n#### \"Permission denied\"\n- **macOS/Linux**: Run `chmod +x cxmpute-provider-*`\n- **Windows**: Run as Administrator\n\n#### \"Node start failed: ECONNREFUSED\"\n- **Cause**: Network connectivity issue\n- **Fix**: Check internet connection, restart the CLI\n\n#### macOS Security Warning\n1. Go to **System Preferences** > **Security & Privacy** > **General**\n2. Click **\"Allow Anyway\"** for cxmpute-provider\n3. Re-run the application\n\n#### Windows SmartScreen Warning\n1. Click **\"More info\"**\n2. Click **\"Run anyway\"**\n3. The application will start normally\n\n#### Low Earnings\n- Check your device tier - upgrade hardware for better rates\n- Ensure stable internet connection (100+ Mbps recommended)\n- Maximize uptime - run 24/7 for consistent earnings\n- Check for software conflicts (antivirus, firewall)\n\n### Status Indicators\n\n- **Green ‚óè**: Provider active and earning\n- **Yellow ‚óè**: Provider starting up\n- **Red ‚óè**: Provider error or offline\n\n## Security & Privacy\n\n### What Data is Collected\n- **Hardware specs**: For service assignment\n- **Usage metrics**: For earnings calculation\n- **Error logs**: For debugging and support\n\n### What's NOT Collected\n- **Personal files**: No access to your documents\n- **Browsing history**: No tracking of web activity\n- **Sensitive data**: No personal information stored\n\n### Data Protection\n- All communications are encrypted\n- Provider credentials are embedded securely\n- No sensitive data is transmitted\n\n## Install Globally (Optional)\n\nMake `cxmpute-provider` available from anywhere on your system:\n\n**üçé macOS**\n```bash\n# Install globally\nsudo mv ~/Downloads/cxmpute-provider-macos /usr/local/bin/cxmpute-provider\n\n# Now run from anywhere\ncxmpute-provider\n```\n\n**üêß Linux**\n```bash\n# Install globally\nsudo mv ~/Downloads/cxmpute-provider-linux /usr/local/bin/cxmpute-provider\n\n# Now run from anywhere\ncxmpute-provider\n```\n\n**ü™ü Windows**\n\n*Option 1: System32 (requires admin)*\n```cmd\n# Open Command Prompt as Administrator\nmove \"%USERPROFILE%\\Downloads\\cxmpute-provider.exe\" \"C:\\Windows\\System32\\cxmpute-provider.exe\"\n\n# Now run from anywhere\ncxmpute-provider\n```\n\n*Option 2: Add to PATH*\n1. Create folder: `C:\\cxmpute\\`\n2. Move `cxmpute-provider.exe` to `C:\\cxmpute\\`\n3. Add `C:\\cxmpute\\` to your PATH environment variable\n4. Restart Command Prompt/PowerShell\n5. Run: `cxmpute-provider`\n\n## Commands & Controls\n\n### Basic Commands\n```bash\n# Start the provider\ncxmpute-provider\n\n# Stop the provider\n# Press Ctrl+C in the terminal\n```\n\n### Advanced Usage\n- The CLI handles all complex operations automatically\n- No manual configuration required\n- Updates are handled through new releases\n\n## Support\n\n### Getting Help\n- **Discord**: Join our [community](https://discord.gg/vE3xvFsZA8) for real-time support\n- **GitHub**: Report issues on our [repository](https://github.com/unxversal/cxmpute-core)\n- **Email**: Contact support@cxmpute.cloud\n\n### Community\nJoin our Discord for:\n- Latest news and updates\n- Provider tips and tricks\n- Community support\n- Feature announcements\n\n## Next Steps\n\n1. **üìä Monitor Earnings**: Keep track of your progress in the dashboard\n2. **üë• Invite Friends**: Use the [referral system](/docs/rewards) to boost earnings\n3. **‚¨ÜÔ∏è Upgrade Hardware**: Consider hardware improvements for higher tiers\n4. **üåç Join Community**: Connect with other providers on Discord\n\n---\n\n**Ready to start earning?** [Download the CLI](https://github.com/unxversal/cxmpute-core/releases) and join thousands of providers powering the Cxmpute network! ",
  "rewards": "Earn rewards and grow the Cxmpute network through our comprehensive referral system! Both users and providers can earn through platform usage and by building referral networks.\n\n## üéâ System Overview\n\nCxmpute operates a **multi-tier rewards system** with:\n\n‚úÖ **Tiered Provider Earnings**: Rewards based on hardware capability and model complexity  \n‚úÖ **User Points**: Earn points for API usage and activity  \n‚úÖ **Multi-Level Referrals**: Earn from your referrals' referrals' referrals  \n‚úÖ **Automatic Distribution**: Rewards processed in real-time  \n‚úÖ **Direct Referral Bonuses**: Instant rewards when someone uses your code  \n‚úÖ **Performance Incentives**: Bonuses for fast, reliable service\n\n## How Rewards Work\n\n### For Providers\n\n**üí∞ Tiered Compute Earnings**\n\nProviders earn based on **hardware tier**, **model complexity**, and **actual work performed**:\n\n| Tier | VRAM | Base Reward | Token Multiplier | Description |\n|------|------|-------------|------------------|-------------|\n| **Tide Pool** | ‚â§4GB | 0.005 | 0.00001 | Entry-level models |\n| **Blue Surge** | 4-8GB | 0.015 | 0.00003 | Mid-tier workhorses |\n| **Open Ocean** | 8-22GB | 0.035 | 0.00007 | High-end performance |\n| **Mariana Depth** | 22GB+ | 0.075 | 0.00015 | Premium powerhouses |\n\n**Service Multipliers:**\n- **Chat Completions**: 1.0√ó (full rate)\n- **TTS**: 0.6√ó (moderate compute)\n- **Embeddings**: 0.3√ó (lighter workload)\n- **Web Scraping**: 0.2√ó (network-bound)\n\n**Performance Bonuses:**\n- **Fast Response** (<2s): +10% bonus\n- **Slow Response** (>10s): -10% penalty\n\n**üéØ Referral Network Earnings**\n- **Direct Bonus**: 50 points when someone uses your Provider ID as referral\n- **Primary Level**: 10% of your direct referrals' compute earnings\n- **Secondary Level**: 5% of your secondary referrals' compute earnings  \n- **Tertiary Level**: 2.5% of your tertiary referrals' compute earnings\n\n### For Users\n\n**‚ö° API Usage Points**\n- Earn points for every API request you make\n- Different endpoints have different point values\n- Token-based bonuses for LLM endpoints\n\n**üéØ Referral Network Earnings**\n- **Direct Bonus**: 25 points when someone uses your User ID as referral\n- **Primary Level**: 15% of your direct referrals' usage points\n- **Secondary Level**: 8% of your secondary referrals' usage points\n- **Tertiary Level**: 4% of your tertiary referrals' usage points\n\n## Provider Earnings Examples\n\n### Real Reward Calculations\n\n**Example 1: 70B Model (Mariana Depth) - 1000 tokens**\n```\nBase Reward: 0.075 √ó 1.0 (chat) √ó 3.0 (complexity) = 0.225\nToken Reward: 1000 √ó 0.00015 √ó 1.0 = 0.15\nTotal: 0.375 per request\n```\n\n**Example 2: 7B Model (Blue Surge) - 1000 tokens**\n```\nBase Reward: 0.015 √ó 1.0 (chat) √ó 1.0 (complexity) = 0.015\nToken Reward: 1000 √ó 0.00003 √ó 1.0 = 0.03\nTotal: 0.045 per request\n```\n\n**Example 3: Embeddings (any tier) - 500 tokens**\n```\nBase Reward: 0.035 √ó 0.3 (embeddings) √ó 1.5 (complexity) = 0.01575\nToken Reward: 500 √ó 0.00007 √ó 0.3 = 0.0105\nTotal: 0.02625 per request\n```\n\n### Model Complexity Tiers\n\n| Model | Tier | Complexity | Typical Earnings |\n|-------|------|------------|------------------|\n| **Llama3-70B** | Mariana Depth | 3.0√ó | Highest |\n| **Mixtral-8x7B** | Open Ocean | 2.5√ó | High |\n| **Llama3-13B** | Open Ocean | 1.5√ó | Medium-High |\n| **Llama3-8B** | Blue Surge | 1.0√ó | Medium |\n| **Mistral-7B** | Blue Surge | 1.0√ó | Medium |\n| **Phi-3-Mini** | Tide Pool | 0.5√ó | Light |\n| **Gemma-2B** | Tide Pool | 0.3√ó | Minimal |\n\n### Referral Earnings Impact\n\n**If you refer a high-earning provider:**\n- Provider earns 0.375 per request\n- **You earn**: 0.0375 (10%) as primary referrer\n- **Your referrer earns**: 0.01875 (5%) as secondary referrer\n- **Their referrer earns**: 0.009375 (2.5%) as tertiary referrer\n\n**Monthly scaling example:**\n- Referred provider: 1000 requests/month √ó 0.375 = 375 total earnings\n- **Your monthly bonus**: 37.5 from this one referral\n- **With 5 similar referrals**: 187.5 monthly passive income\n\n## User Points System\n\n### API Usage Points\n\n| Endpoint | Base Points | Token Bonus |\n|----------|------------|-------------|\n| `/chat/completions` | 1 point | +0.001 per token |\n| `/embeddings` | 0.5 points | +0.0005 per token |\n| `/scrape` | 0.2 points | - |\n| `/tts` | 0.8 points | - |\n\n**Example**: A chat completion with 1000 tokens = 1 + (1000 √ó 0.001) = 2 points\n\n### Real-Time Earning\n\nPoints are awarded automatically with every API request:\n1. You make an API call\n2. Points calculated based on endpoint and usage\n3. Points added to your account instantly\n4. Referral bonuses distributed up the chain automatically\n\n## Multi-Level Referral System\n\n### How It Works\n\nWhen you refer someone, you earn from their activity **and** from anyone they refer:\n\n```\nYou (Level 0)\n‚îú‚îÄ‚îÄ Direct Referral (Level 1) ‚Üí You earn 10-15% of their earnings\n    ‚îú‚îÄ‚îÄ Secondary Referral (Level 2) ‚Üí You earn 5-8% of their earnings\n        ‚îî‚îÄ‚îÄ Tertiary Referral (Level 3) ‚Üí You earn 2.5-4% of their earnings\n```\n\n### Automatic Processing\n\nEvery time someone earns rewards:\n1. **Primary referrer** gets their percentage\n2. **Secondary referrer** gets their percentage  \n3. **Tertiary referrer** gets their percentage\n4. **Original earner** keeps 100% of their earnings\n5. All processed automatically in real-time\n\n## Getting Started\n\n### Step 1: Get Your Referral Code\n\n**For Users:**\n- Your referral code is your User ID\n- Find it in your [Dashboard](https://cxmpute.cloud/dashboard) under \"Referral Codes\"\n- Example: `usr_abc123...`\n\n**For Providers:**\n- Your referral code is your Provider ID  \n- Find it in your [Provider Dashboard](https://cxmpute.cloud/dashboard) under \"Referral Information\"\n- Example: `prov_xyz789...`\n\n### Step 2: Share Your Code\n\n**Direct Sharing:**\n- Send your ID to friends and colleagues\n- Include in community posts and tutorials\n- Mention when helping others with Cxmpute\n\n**Content Creation:**\n- **Blog Posts**: Write tutorials showing Cxmpute APIs in action\n- **Videos**: Create setup guides and earnings demonstrations\n- **Social Media**: Share your experience with specific examples\n- **Developer Content**: Help others solve problems with Cxmpute\n\n### Step 3: Apply Referral Codes\n\nIf someone referred you:\n1. Go to your dashboard\n2. Find the \"Enter Referral Code\" section\n3. Enter their User ID (for users) or Provider ID (for providers)\n4. Click \"Apply Referral\"\n5. They automatically get a direct referral bonus!\n\n**‚ö†Ô∏è Important**: You can only set one referral relationship - choose wisely!\n\n## Tracking Your Success\n\n### Dashboard Analytics\n\n**Users can track:**\n- Total usage points earned\n- Referral network size (direct, secondary, tertiary)\n- Referral rewards by level\n- Total earnings breakdown\n\n**Providers can track:**\n- Compute earnings from actual work\n- Earnings breakdown by tier and model\n- Referral network growth\n- Referral rewards by level\n- Combined earnings summary\n\n### Real-Time Updates\n\n- All rewards credited instantly\n- Dashboard updates in real-time\n- 30-day earning history maintained\n- Referral network stats updated automatically\n\n## Maximizing Your Earnings\n\n### For Users\n\n**üöÄ High-Value Strategies:**\n1. **Use More APIs**: Higher usage = more points = more value to referrers\n2. **Refer Active Developers**: Target people who will actually use AI APIs\n3. **Create Educational Content**: Tutorials featuring Cxmpute get shared more\n4. **Build in Communities**: Engage in Discord, Stack Overflow, GitHub\n\n**üí° Pro Tips:**\n- Focus on `/chat/completions` for highest points per request\n- Token-heavy usage maximizes your earning potential\n- Quality referrals compound better than quantity\n\n### For Providers\n\n**üöÄ High-Value Strategies:**\n1. **Upgrade Hardware**: Higher tiers earn significantly more per request\n2. **Maintain High Uptime**: More availability = more earnings = more value to referrers\n3. **Optimize Performance**: Fast responses get 10% bonuses\n4. **Refer Serious Providers**: Target people with good hardware and commitment\n5. **Share Real Earnings**: Demonstrate actual profitability\n\n**üí° Pro Tips:**\n- **Mariana Depth providers** (22GB+) earn 5-15√ó more than Tide Pool\n- Focus on chat completions for highest earning potential\n- Fast hardware gets performance bonuses\n- Provider referrals compound significantly due to higher earning potential\n\n### Tier Upgrade Benefits\n\n**Moving from Blue Surge (8GB) to Open Ocean (16GB):**\n- Base reward: 0.015 ‚Üí 0.035 (+133%)\n- Token multiplier: 0.00003 ‚Üí 0.00007 (+133%)\n- **Result**: ~2.3√ó earnings increase\n\n**Moving to Mariana Depth (22GB+):**\n- Base reward: 0.035 ‚Üí 0.075 (+114%)\n- Token multiplier: 0.00007 ‚Üí 0.00015 (+114%)\n- **Result**: ~2.1√ó additional increase\n\n## Best Practices\n\n### Effective Referral Sharing\n\n**Quality Over Quantity:**\n- Target people who will genuinely benefit from Cxmpute\n- Provide context about why it's valuable for them\n- Follow up to help with onboarding\n\n**Be Transparent:**\n- Clearly mention you'll earn from referrals\n- Explain how the system benefits everyone\n- Share your own positive experience\n\n**Build Relationships:**\n- Focus on helping rather than just promoting\n- Stay connected with your referrals\n- Celebrate their successes\n\n### Content Ideas\n\n**üìù Educational Content:**\n- \"Building an AI app with Cxmpute APIs\"\n- \"Cxmpute vs OpenAI: Cost and performance comparison\"\n- \"How I earn $X per month with my gaming PC\"\n- \"Provider tier comparison: Is upgrading worth it?\"\n\n**üé• Video Content:**\n- Provider setup walkthroughs by tier\n- Real earnings demonstrations with calculations\n- API integration tutorials\n- Hardware optimization guides\n\n**üí¨ Community Engagement:**\n- Help troubleshoot issues in Discord\n- Share usage examples and case studies\n- Answer questions about the platform\n- Compare earnings across different hardware setups\n\n## Referral Network Examples\n\n### Example 1: Active Developer Network\n\n**You refer:** 5 active developers (each earning 100 points/month)  \n**They refer:** 3 developers each (15 total, 50 points/month each)  \n**They refer:** 2 developers each (30 total, 25 points/month each)\n\n**Your Monthly Earnings:**\n- Direct referrals: 15% √ó (5 √ó 100) = 75 points\n- Secondary referrals: 8% √ó (15 √ó 50) = 60 points  \n- Tertiary referrals: 4% √ó (30 √ó 25) = 30 points\n- **Total**: 165 points/month passive income\n\n### Example 2: High-End Provider Network\n\n**You refer:** 3 Mariana Depth providers (1000 requests/month @ 0.375 each)  \n**They refer:** 2 providers each (6 total, 500 requests/month @ 0.375)  \n**They refer:** 1 provider each (6 total, 300 requests/month @ 0.375)\n\n**Your Monthly Earnings:**\n- Direct referrals: 10% √ó (3 √ó 375) = 112.5\n- Secondary referrals: 5% √ó (6 √ó 187.5) = 56.25\n- Tertiary referrals: 2.5% √ó (6 √ó 112.5) = 16.875\n- **Total**: 185.625/month passive income\n\n## Technical Details\n\n### Reward Processing\n\nAll rewards are processed automatically using recursive referral chain lookups:\n\n1. **Provider serves request** ‚Üí Provider gets tiered reward based on model/hardware\n2. **System finds referrer** ‚Üí Primary referrer gets 10% bonus\n3. **System finds referrer's referrer** ‚Üí Secondary referrer gets 5% bonus\n4. **System finds tertiary referrer** ‚Üí Tertiary referrer gets 2.5% bonus\n\n### Data Storage\n\n- All rewards stored with 30-day rolling window\n- Referral relationships are permanent once set\n- Real-time calculations with efficient database queries\n- Full audit trail of all reward distributions\n- Performance metrics tracked for bonus calculations\n\n## API Endpoints\n\n### Get Your Referral Stats\n\n**Users:**\n```\nGET /api/user/{userId}/referral-stats\n```\n\n**Providers:**\n```\nGET /api/providers/{providerId}/referral-stats\n```\n\n**Response includes:**\n- Total earnings breakdown (usage vs referral rewards)\n- Referral network size by level\n- Reward history and trends\n- Performance metrics\n- Tier information (providers)\n\n## Support & FAQs\n\n### Common Questions\n\n**Q: When do I receive referral rewards?**\nA: Immediately! All rewards are processed in real-time as activity happens.\n\n**Q: Can I change who referred me?**\nA: No, referral relationships are permanent once set.\n\n**Q: Is there a limit on referral earnings?**\nA: No limits! The more active your network, the more you earn.\n\n**Q: What if someone I referred stops using Cxmpute?**\nA: You keep all previously earned rewards, but future earnings from them stop.\n\n**Q: How do provider tiers affect referral earnings?**\nA: Higher-tier providers earn more per request, so referring them generates more referral income for you.\n\n**Q: Can I refer people outside my account type?**\nA: Users can only refer users, providers can only refer providers.\n\n**Q: How are percentages calculated?**\nA: Percentages are based on the original earner's rewards, and everyone gets their full amount plus bonuses.\n\n**Q: What's the best tier to target for referrals?**\nA: Mariana Depth providers (22GB+) generate the highest referral income due to their premium earnings.\n\n### Getting Help\n\n- **Dashboard**: Check your detailed referral stats and earnings\n- **Discord**: Get help from the community at [discord.gg/vE3xvFsZA8](https://discord.gg/vE3xvFsZA8)\n- **Documentation**: Review our [provider guide](/docs/provider) for setup help\n\n---\n\n**Ready to build your earning network?** Get your referral code from the [Dashboard](https://cxmpute.cloud/dashboard) and start earning from your community today! ",
  "scraping": "Extract content from web pages intelligently using Cxmpute's distributed web scraping service.\n\n## Overview\n\nCxmpute's Web Scraping service provides reliable content extraction from web pages with intelligent parsing, markdown conversion, and metadata extraction. Our global network of providers ensures consistent availability and bypasses common blocking mechanisms.\n\n### Key Features\n\n- **Intelligent Extraction**: Smart content parsing and cleaning\n- **Multiple Formats**: HTML, text, and markdown output\n- **Metadata Extraction**: Titles, descriptions, and structured data\n- **Batch Processing**: Handle multiple URLs efficiently\n- **Global Network**: Distributed scraping nodes worldwide\n\n## Quick Start\n\n### Basic Request\n\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/scrape \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"urls\": [\"https://example.com\"],\n    \"format\": \"markdown\"\n  }'\n```\n\n### Python Example\n\n```python\nimport requests\n\nurl = \"https://cxmpute.cloud/api/v1/scrape\"\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"YOUR_USER_ID\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"urls\": [\"https://docs.cxmpute.cloud\"],\n    \"format\": \"markdown\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n\nfor item in result[\"results\"]:\n    if item[\"success\"]:\n        print(f\"Title: {item['metadata']['title']}\")\n        print(f\"Content: {item['content'][:200]}...\")\n    else:\n        print(f\"Failed to scrape {item['url']}\")\n```\n\n## API Limits\n\n### URL Limits\n\n- **Maximum URLs per request**: 50 URLs\n- **Batch processing**: For larger datasets, split into multiple requests\n- **Rate limiting**: Recommended delay of 1-2 seconds between requests\n\n### Handling Large Batches\n\nFor processing more than 50 URLs, split your requests:\n\n```python\ndef scrape_large_batch(urls, batch_size=50):\n    \"\"\"Process large URL lists in batches\"\"\"\n    all_results = []\n    \n    for i in range(0, len(urls), batch_size):\n        batch = urls[i:i + batch_size]\n        \n        response = requests.post(\n            \"https://cxmpute.cloud/api/v1/scrape\",\n            headers=headers,\n            json={\"urls\": batch, \"format\": \"markdown\"}\n        )\n        \n        if response.status_code == 200:\n            all_results.extend(response.json()[\"results\"])\n        \n        # Respectful delay between batches\n        time.sleep(1)\n        print(f\"Processed batch {i//batch_size + 1}\")\n    \n    return all_results\n\n# Usage\nlarge_url_list = [\"https://example.com/page{}\".format(i) for i in range(1, 200)]\nresults = scrape_large_batch(large_url_list)\n```\n\n## API Reference\n\n### Endpoint\n\n```http\nPOST /v1/scrape\n```\n\n### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `urls` | array | Yes | Array of URLs to scrape (maximum 50 URLs per request) |\n| `format` | string | No | Output format: \"markdown\", \"text\", \"html\" (default: \"markdown\") |\n\n### Response Format\n\n```json\n{\n  \"results\": [\n    {\n      \"url\": \"https://example.com\",\n      \"content\": \"# Example Page\\n\\nThis is the content...\",\n      \"success\": true,\n      \"metadata\": {\n        \"title\": \"Example Page\",\n        \"description\": \"An example webpage\",\n        \"author\": \"John Doe\",\n        \"publish_date\": \"2024-01-15\"\n      }\n    }\n  ]\n}\n```\n\n## Use Cases\n\n### 1. Content Aggregation\n\nCollect articles and blog posts for analysis:\n\n```python\ndef scrape_news_articles(urls):\n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/scrape\",\n        headers=headers,\n        json={\"urls\": urls, \"format\": \"markdown\"}\n    )\n    \n    articles = []\n    for result in response.json()[\"results\"]:\n        if result[\"success\"]:\n            articles.append({\n                \"url\": result[\"url\"],\n                \"title\": result[\"metadata\"].get(\"title\", \"Unknown\"),\n                \"content\": result[\"content\"],\n                \"publish_date\": result[\"metadata\"].get(\"publish_date\")\n            })\n    \n    return articles\n\n# Usage\nnews_urls = [\n    \"https://techcrunch.com/article1\",\n    \"https://arstechnica.com/article2\"\n]\narticles = scrape_news_articles(news_urls)\n```\n\n### 2. Research Data Collection\n\nGather information for research projects:\n\n```python\ndef research_scraper(search_urls, keywords):\n    scraped_data = []\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/scrape\",\n        headers=headers,\n        json={\"urls\": search_urls, \"format\": \"text\"}\n    )\n    \n    for result in response.json()[\"results\"]:\n        if result[\"success\"]:\n            content = result[\"content\"].lower()\n            keyword_matches = sum(content.count(kw.lower()) for kw in keywords)\n            \n            if keyword_matches > 0:\n                scraped_data.append({\n                    \"url\": result[\"url\"],\n                    \"relevance_score\": keyword_matches,\n                    \"content\": result[\"content\"],\n                    \"metadata\": result[\"metadata\"]\n                })\n    \n    return sorted(scraped_data, key=lambda x: x[\"relevance_score\"], reverse=True)\n```\n\n### 3. E-commerce Product Monitoring\n\nTrack product information and pricing:\n\n```python\ndef monitor_product_pages(product_urls):\n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/scrape\",\n        headers=headers,\n        json={\"urls\": product_urls, \"format\": \"html\"}\n    )\n    \n    products = []\n    for result in response.json()[\"results\"]:\n        if result[\"success\"]:\n            # Extract price and availability (simplified example)\n            content = result[\"content\"]\n            # Use regex or HTML parsing to extract specific data\n            products.append({\n                \"url\": result[\"url\"],\n                \"title\": result[\"metadata\"].get(\"title\"),\n                \"raw_content\": content,\n                \"scraped_at\": datetime.now().isoformat()\n            })\n    \n    return products\n```\n\n### 4. Documentation Aggregation\n\nCollect API documentation and guides:\n\n```python\ndef scrape_documentation(doc_urls):\n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/scrape\",\n        headers=headers,\n        json={\"urls\": doc_urls, \"format\": \"markdown\"}\n    )\n    \n    docs = []\n    for result in response.json()[\"results\"]:\n        if result[\"success\"]:\n            docs.append({\n                \"url\": result[\"url\"],\n                \"title\": result[\"metadata\"].get(\"title\"),\n                \"content\": result[\"content\"],\n                \"sections\": extract_sections(result[\"content\"])\n            })\n    \n    return docs\n\ndef extract_sections(markdown_content):\n    \"\"\"Extract sections from markdown content\"\"\"\n    sections = []\n    current_section = None\n    \n    for line in markdown_content.split('\\n'):\n        if line.startswith('#'):\n            if current_section:\n                sections.append(current_section)\n            current_section = {\n                \"title\": line.strip('#').strip(),\n                \"content\": \"\"\n            }\n        elif current_section:\n            current_section[\"content\"] += line + \"\\n\"\n    \n    if current_section:\n        sections.append(current_section)\n    \n    return sections\n```\n\n## Advanced Features\n\n### Batch Processing with Error Handling\n\n```python\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef scrape_urls_batch(urls, batch_size=10, max_retries=3):\n    \"\"\"Scrape URLs in batches with retry logic\"\"\"\n    \n    def scrape_batch(url_batch):\n        for attempt in range(max_retries):\n            try:\n                response = requests.post(\n                    \"https://cxmpute.cloud/api/v1/scrape\",\n                    headers=headers,\n                    json={\"urls\": url_batch, \"format\": \"markdown\"},\n                    timeout=60\n                )\n                \n                if response.status_code == 200:\n                    return response.json()[\"results\"]\n                elif response.status_code == 503:\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    response.raise_for_status()\n                    \n            except requests.exceptions.RequestException as e:\n                if attempt == max_retries - 1:\n                    # Return failed results for this batch\n                    return [{\"url\": url, \"success\": False, \"error\": str(e)} for url in url_batch]\n                time.sleep(1)\n    \n    # Split URLs into batches\n    batches = [urls[i:i + batch_size] for i in range(0, len(urls), batch_size)]\n    all_results = []\n    \n    for batch in batches:\n        results = scrape_batch(batch)\n        all_results.extend(results)\n        print(f\"Processed batch of {len(batch)} URLs\")\n    \n    return all_results\n```\n\n### Content Filtering and Extraction\n\n```python\ndef extract_article_content(scraped_results):\n    \"\"\"Extract main article content from scraped pages\"\"\"\n    \n    articles = []\n    for result in scraped_results:\n        if not result[\"success\"]:\n            continue\n            \n        content = result[\"content\"]\n        metadata = result[\"metadata\"]\n        \n        # Basic content filtering\n        if len(content) < 100:  # Skip very short content\n            continue\n            \n        # Extract meaningful content\n        article = {\n            \"url\": result[\"url\"],\n            \"title\": metadata.get(\"title\", \"\"),\n            \"author\": metadata.get(\"author\", \"\"),\n            \"publish_date\": metadata.get(\"publish_date\", \"\"),\n            \"content\": content,\n            \"word_count\": len(content.split()),\n            \"reading_time\": len(content.split()) // 200  # Approximate reading time\n        }\n        \n        articles.append(article)\n    \n    return articles\n```\n\n### Integration with AI Services\n\nCombine scraping with AI analysis:\n\n```python\ndef scrape_and_analyze(urls, analysis_type=\"summary\"):\n    \"\"\"Scrape content and analyze it with AI\"\"\"\n    \n    # Scrape content\n    scrape_response = requests.post(\n        \"https://cxmpute.cloud/api/v1/scrape\",\n        headers=headers,\n        json={\"urls\": urls, \"format\": \"text\"}\n    )\n    \n    results = []\n    for result in scrape_response.json()[\"results\"]:\n        if not result[\"success\"]:\n            continue\n            \n        content = result[\"content\"]\n        \n        # Analyze with AI\n        if analysis_type == \"summary\":\n            prompt = f\"Summarize this article in 2-3 sentences:\\n\\n{content[:2000]}\"\n        elif analysis_type == \"sentiment\":\n            prompt = f\"Analyze the sentiment of this text:\\n\\n{content[:2000]}\"\n        elif analysis_type == \"keywords\":\n            prompt = f\"Extract the main keywords and topics from this text:\\n\\n{content[:2000]}\"\n        \n        ai_response = requests.post(\n            \"https://cxmpute.cloud/api/v1/chat/completions\",\n            headers=headers,\n            json={\n                \"model\": \"llama3.1:8b\",\n                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n                \"temperature\": 0.3\n            }\n        )\n        \n        if ai_response.status_code == 200:\n            analysis = ai_response.json()[\"choices\"][0][\"message\"][\"content\"]\n        else:\n            analysis = \"Analysis failed\"\n        \n        results.append({\n            \"url\": result[\"url\"],\n            \"title\": result[\"metadata\"].get(\"title\", \"\"),\n            \"content\": content,\n            \"analysis\": analysis,\n            \"analysis_type\": analysis_type\n        })\n    \n    return results\n\n# Usage\nurls = [\"https://techcrunch.com/some-article\"]\nanalyzed_content = scrape_and_analyze(urls, \"summary\")\n```\n\n## Best Practices\n\n### 1. Rate Limiting and Politeness\n\n```python\nimport time\nimport random\n\ndef polite_scraper(urls, delay_range=(1, 3)):\n    \"\"\"Scrape URLs with respectful delays\"\"\"\n    \n    results = []\n    for i, url in enumerate(urls):\n        # Add delay between requests\n        if i > 0:\n            delay = random.uniform(*delay_range)\n            time.sleep(delay)\n        \n        response = requests.post(\n            \"https://cxmpute.cloud/api/v1/scrape\",\n            headers=headers,\n            json={\"urls\": [url], \"format\": \"markdown\"}\n        )\n        \n        if response.status_code == 200:\n            results.extend(response.json()[\"results\"])\n        \n        print(f\"Scraped {i+1}/{len(urls)} URLs\")\n    \n    return results\n```\n\n### 2. Content Validation\n\n```python\ndef validate_scraped_content(results, min_length=100):\n    \"\"\"Validate and filter scraped content\"\"\"\n    \n    valid_results = []\n    for result in results:\n        if not result[\"success\"]:\n            print(f\"Skipping failed URL: {result['url']}\")\n            continue\n        \n        content = result[\"content\"]\n        \n        # Check content length\n        if len(content) < min_length:\n            print(f\"Skipping short content from {result['url']}\")\n            continue\n        \n        # Check for common error pages\n        error_indicators = [\n            \"404 not found\",\n            \"access denied\",\n            \"page not found\",\n            \"forbidden\"\n        ]\n        \n        if any(indicator in content.lower() for indicator in error_indicators):\n            print(f\"Detected error page: {result['url']}\")\n            continue\n        \n        valid_results.append(result)\n    \n    return valid_results\n```\n\n### 3. Caching and Storage\n\n```python\nimport json\nimport hashlib\nfrom datetime import datetime, timedelta\n\nclass ScrapingCache:\n    def __init__(self, cache_file=\"scraping_cache.json\", cache_duration_hours=24):\n        self.cache_file = cache_file\n        self.cache_duration = timedelta(hours=cache_duration_hours)\n        self.cache = self._load_cache()\n    \n    def _load_cache(self):\n        try:\n            with open(self.cache_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            return {}\n    \n    def _save_cache(self):\n        with open(self.cache_file, 'w') as f:\n            json.dump(self.cache, f, indent=2)\n    \n    def _get_cache_key(self, url, format_type):\n        return hashlib.md5(f\"{url}:{format_type}\".encode()).hexdigest()\n    \n    def get_cached_result(self, url, format_type=\"markdown\"):\n        cache_key = self._get_cache_key(url, format_type)\n        \n        if cache_key in self.cache:\n            cached_item = self.cache[cache_key]\n            cached_time = datetime.fromisoformat(cached_item[\"timestamp\"])\n            \n            if datetime.now() - cached_time < self.cache_duration:\n                return cached_item[\"result\"]\n        \n        return None\n    \n    def cache_result(self, url, format_type, result):\n        cache_key = self._get_cache_key(url, format_type)\n        \n        self.cache[cache_key] = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"result\": result\n        }\n        \n        self._save_cache()\n    \n    def scrape_with_cache(self, urls, format_type=\"markdown\"):\n        cached_results = []\n        urls_to_scrape = []\n        \n        # Check cache first\n        for url in urls:\n            cached = self.get_cached_result(url, format_type)\n            if cached:\n                cached_results.append(cached)\n            else:\n                urls_to_scrape.append(url)\n        \n        # Scrape uncached URLs\n        if urls_to_scrape:\n            response = requests.post(\n                \"https://cxmpute.cloud/api/v1/scrape\",\n                headers=headers,\n                json={\"urls\": urls_to_scrape, \"format\": format_type}\n            )\n            \n            if response.status_code == 200:\n                new_results = response.json()[\"results\"]\n                \n                # Cache new results\n                for result in new_results:\n                    self.cache_result(result[\"url\"], format_type, result)\n                \n                cached_results.extend(new_results)\n        \n        return cached_results\n\n# Usage\ncache = ScrapingCache(cache_duration_hours=6)\nresults = cache.scrape_with_cache([\"https://example.com\", \"https://test.com\"])\n```\n\n## Pricing\n\nDuring our **testnet phase**, all services are completely **free** for all users! Pricing for the mainnet launch is **to be determined (TBD)**.\n\nJoin our [Discord community](https://discord.gg/vE3xvFsZA8) to stay updated on pricing announcements, give feedback, and connect with other developers building with Cxmpute.\n\n## Error Handling\n\nCommon error codes and solutions:\n\n- `400`: Invalid URL, malformed request, or too many URLs (max 50 per request)\n- `403`: Access denied or blocked by target site\n- `404`: Page not found\n- `408`: Request timeout\n- `503`: No scraping providers available\n\n## Support\n\n- **Discord**: [Community support](https://discord.gg/vE3xvFsZA8)\n- **Documentation**: [Complete API reference](/docs/user)\n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready to extract web content?** Start building data collection pipelines with our reliable scraping service! ",
  "text-to-speech": "Convert text to natural, high-quality speech using Cxmpute's distributed text-to-speech service.\n\n## Overview\n\nCxmpute's Text-to-Speech (TTS) service transforms written text into lifelike audio using advanced voice synthesis models. Our global network of providers ensures fast generation times and high availability.\n\n### Key Features\n\n- **High-Quality Audio**: Professional-grade voice synthesis\n- **Multiple Voices**: Various voice models and styles\n- **Fast Generation**: Optimized for speed and reliability\n- **Global Network**: Low-latency access worldwide\n- **Simple API**: Easy integration with any application\n\n## Quick Start\n\n### Basic Request\n\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/tts \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"text\": \"Welcome to Cxmpute! This is a demonstration of our text-to-speech service.\",\n    \"voice\": \"af_bella\"\n  }' \\\n  --output welcome.wav\n```\n\n### Python Example\n\n```python\nimport requests\n\nurl = \"https://cxmpute.cloud/api/v1/tts\"\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"YOUR_USER_ID\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"text\": \"Hello from Cxmpute!\",\n    \"voice\": \"af_bella\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n\nif response.status_code == 200:\n    with open(\"output.wav\", \"wb\") as f:\n        f.write(response.content)\n    print(\"Audio saved as output.wav\")\nelse:\n    print(f\"Error: {response.status_code}\")\n```\n\n### JavaScript Example\n\n```javascript\nconst fs = require('fs');\n\nasync function generateSpeech() {\n  const response = await fetch('https://cxmpute.cloud/api/v1/tts', {\n    method: 'POST',\n    headers: {\n      'Authorization': 'Bearer YOUR_API_KEY',\n      'X-User-Id': 'YOUR_USER_ID',\n      'Content-Type': 'application/json'\n    },\n    body: JSON.stringify({\n      text: 'This is generated using Cxmpute TTS!',\n      voice: 'af_bella'\n    })\n  });\n\n  if (response.ok) {\n    const buffer = await response.arrayBuffer();\n    fs.writeFileSync('speech.wav', Buffer.from(buffer));\n    console.log('Audio saved as speech.wav');\n  } else {\n    console.error('Error:', response.status);\n  }\n}\n\ngenerateSpeech();\n```\n\n## API Reference\n\n### Endpoint\n\n```http\nPOST /v1/tts\n```\n\n### Request Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `text` | string | Yes | Text to convert to speech (max 10,000 characters) |\n| `voice` | string | No | Voice model to use (default: \"af_bella\") |\n\n### Available Voices\n\n| Voice | Description | Language | Style |\n|-------|-------------|----------|-------|\n| `af` | Standard American female voice | English (US) | Natural, balanced |\n| `af_bella` | Warm, professional female voice | English (US) | Clear, pleasant |\n| `af_nicole` | Energetic female voice | English (US) | Upbeat, dynamic |\n| `af_sarah` | Calm, soothing female voice | English (US) | Gentle, relaxed |\n| `af_sky` | Bright, youthful female voice | English (US) | Light, cheerful |\n| `am_adam` | Professional male voice | English (US) | Authoritative, clear |\n| `am_michael` | Friendly male voice | English (US) | Warm, approachable |\n| `bf_emma` | Sophisticated British female voice | English (UK) | Elegant, refined |\n| `bf_isabella` | Classic British female voice | English (UK) | Traditional, articulate |\n| `bm_george` | Distinguished British male voice | English (UK) | Formal, authoritative |\n| `bm_lewis` | Modern British male voice | English (UK) | Contemporary, friendly |\n\n*More voices are continuously being added to our network.*\n\n### Response\n\nThe endpoint returns raw audio data in WAV format:\n\n- **Content-Type**: `audio/wav`\n- **Format**: 16-bit PCM WAV\n- **Sample Rate**: 22,050 Hz\n- **Channels**: Mono\n\n### Error Responses\n\n```json\n{\n  \"error\": \"Missing 'text' field.\"\n}\n```\n\nCommon error codes:\n- `400`: Bad request (missing text, text too long)\n- `401`: Unauthorized (invalid API key)\n- `503`: Service unavailable (no TTS providers online)\n- `500`: Internal server error\n\n## Use Cases\n\n### 1. **Content Creation**\n\nGenerate voiceovers for videos, podcasts, and presentations:\n\n```python\ndef create_voiceover(script_segments):\n    audio_files = []\n    \n    for i, text in enumerate(script_segments):\n        response = requests.post(\n            \"https://cxmpute.cloud/api/v1/tts\",\n            headers=headers,\n            json={\"text\": text, \"voice\": \"af_bella\"}\n        )\n        \n        filename = f\"segment_{i}.wav\"\n        with open(filename, \"wb\") as f:\n            f.write(response.content)\n        audio_files.append(filename)\n    \n    return audio_files\n```\n\n### 2. **Accessibility Features**\n\nAdd screen reading capabilities to applications:\n\n```javascript\nasync function speakText(text) {\n  const audio = await generateSpeech(text);\n  const audioUrl = URL.createObjectURL(new Blob([audio]));\n  const audioElement = new Audio(audioUrl);\n  audioElement.play();\n}\n\n// Usage\ndocument.addEventListener('click', (e) => {\n  if (e.target.dataset.speak) {\n    speakText(e.target.textContent);\n  }\n});\n```\n\n### 3. **Language Learning**\n\nCreate pronunciation examples for educational apps:\n\n```python\ndef create_pronunciation_guide(phrases):\n    for phrase in phrases:\n        # Generate audio for the phrase\n        audio_response = requests.post(\n            \"https://cxmpute.cloud/api/v1/tts\",\n            headers=headers,\n            json={\n                \"text\": phrase[\"text\"],\n                \"voice\": \"af_sarah\"  # Clear, educational voice\n            }\n        )\n        \n        # Save with metadata\n        filename = f\"pronunciation_{phrase['id']}.wav\"\n        with open(filename, \"wb\") as f:\n            f.write(audio_response.content)\n```\n\n### 4. **Interactive Applications**\n\nAdd voice responses to chatbots and virtual assistants:\n\n```python\ndef voice_assistant_response(user_message):\n    # Get AI response\n    chat_response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.1:8b\",\n            \"messages\": [{\"role\": \"user\", \"content\": user_message}]\n        }\n    )\n    \n    ai_text = chat_response.json()[\"choices\"][0][\"message\"][\"content\"]\n    \n    # Convert to speech\n    tts_response = requests.post(\n        \"https://cxmpute.cloud/api/v1/tts\",\n        headers=headers,\n        json={\"text\": ai_text, \"voice\": \"af_nicole\"}\n    )\n    \n    return tts_response.content\n```\n\n### 5. **Notification Systems**\n\nCreate audio alerts and announcements:\n\n```python\ndef create_audio_notification(message, urgency=\"normal\"):\n    voice_map = {\n        \"normal\": \"af_bella\",\n        \"urgent\": \"am_adam\",\n        \"calm\": \"af_sarah\"\n    }\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/tts\",\n        headers=headers,\n        json={\n            \"text\": message,\n            \"voice\": voice_map.get(urgency, \"af_bella\")\n        }\n    )\n    \n    return response.content\n```\n\n## Advanced Usage\n\n### Batch Processing\n\nGenerate multiple audio files efficiently:\n\n```python\nimport concurrent.futures\nimport requests\n\ndef generate_single_audio(text_item):\n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/tts\",\n        headers=headers,\n        json={\n            \"text\": text_item[\"text\"],\n            \"voice\": text_item.get(\"voice\", \"af_bella\")\n        }\n    )\n    \n    return {\n        \"id\": text_item[\"id\"],\n        \"audio\": response.content if response.ok else None,\n        \"error\": None if response.ok else response.text\n    }\n\ndef batch_generate_audio(text_items, max_workers=5):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        results = list(executor.map(generate_single_audio, text_items))\n    \n    return results\n\n# Usage\ntexts = [\n    {\"id\": \"intro\", \"text\": \"Welcome to our service!\", \"voice\": \"af_bella\"},\n    {\"id\": \"guide\", \"text\": \"Here's how to get started...\", \"voice\": \"af_sarah\"},\n    {\"id\": \"thanks\", \"text\": \"Thank you for using our app!\", \"voice\": \"af_nicole\"}\n]\n\nresults = batch_generate_audio(texts)\nfor result in results:\n    if result[\"audio\"]:\n        with open(f\"{result['id']}.wav\", \"wb\") as f:\n            f.write(result[\"audio\"])\n```\n\n### Error Handling\n\nRobust error handling for production applications:\n\n```python\nimport time\nimport logging\n\ndef reliable_tts_request(text, voice=\"af_bella\", max_retries=3):\n    headers = {\n        \"Authorization\": f\"Bearer {API_KEY}\",\n        \"X-User-Id\": USER_ID,\n        \"Content-Type\": \"application/json\"\n    }\n    \n    for attempt in range(max_retries):\n        try:\n            response = requests.post(\n                \"https://cxmpute.cloud/api/v1/tts\",\n                headers=headers,\n                json={\"text\": text, \"voice\": voice},\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                return response.content\n            elif response.status_code == 503:\n                # No providers available, wait and retry\n                logging.warning(f\"No TTS providers available, attempt {attempt + 1}\")\n                time.sleep(2 ** attempt)  # Exponential backoff\n                continue\n            else:\n                response.raise_for_status()\n                \n        except requests.exceptions.RequestException as e:\n            logging.error(f\"TTS request failed: {e}\")\n            if attempt == max_retries - 1:\n                raise\n            time.sleep(1)\n    \n    raise Exception(\"TTS request failed after all retries\")\n```\n\n### Streaming Integration\n\nFor real-time applications, combine with streaming text generation:\n\n```python\nasync def streaming_tts_response(prompt):\n    \"\"\"Generate text and immediately convert to speech\"\"\"\n    \n    # Stream text response\n    text_response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.1:8b\",\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"stream\": True\n        },\n        stream=True\n    )\n    \n    accumulated_text = \"\"\n    sentences = []\n    \n    for line in text_response.iter_lines():\n        if line.startswith(b\"data: \"):\n            try:\n                data = json.loads(line[6:])\n                if \"choices\" in data and data[\"choices\"]:\n                    content = data[\"choices\"][0].get(\"delta\", {}).get(\"content\", \"\")\n                    accumulated_text += content\n                    \n                    # Check for sentence boundaries\n                    if any(punct in content for punct in ['.', '!', '?']):\n                        # Extract complete sentences\n                        new_sentences = extract_sentences(accumulated_text)\n                        for sentence in new_sentences[len(sentences):]:\n                            # Generate TTS for each complete sentence\n                            audio = generate_tts(sentence)\n                            yield audio\n                        sentences = new_sentences\n                        \n            except json.JSONDecodeError:\n                continue\n```\n\n## Best Practices\n\n### 1. **Text Optimization**\n\nPrepare text for optimal speech generation:\n\n```python\nimport re\n\ndef optimize_text_for_tts(text):\n    # Expand abbreviations\n    abbreviations = {\n        \"Mr.\": \"Mister\",\n        \"Dr.\": \"Doctor\",\n        \"Inc.\": \"Incorporated\",\n        \"Ltd.\": \"Limited\",\n        \"etc.\": \"et cetera\",\n        \"e.g.\": \"for example\",\n        \"i.e.\": \"that is\"\n    }\n    \n    for abbr, expansion in abbreviations.items():\n        text = text.replace(abbr, expansion)\n    \n    # Handle numbers\n    text = re.sub(r'\\b(\\d+)\\b', lambda m: num_to_words(int(m.group(1))), text)\n    \n    # Clean up extra whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text\n\ndef num_to_words(n):\n    # Simple number to words conversion\n    ones = [\"\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n    teens = [\"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\"]\n    tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n    \n    if n < 10:\n        return ones[n]\n    elif n < 20:\n        return teens[n-10]\n    elif n < 100:\n        return tens[n//10] + (\"\" if n%10 == 0 else \" \" + ones[n%10])\n    # Add more cases as needed\n    else:\n        return str(n)  # Fallback to digit representation\n```\n\n### 2. **Voice Selection**\n\nChoose appropriate voices for different contexts:\n\n```python\ndef select_voice_for_content(content_type, target_audience=\"general\"):\n    voice_map = {\n        (\"educational\", \"children\"): \"af_sarah\",\n        (\"educational\", \"adults\"): \"af_bella\",\n        (\"commercial\", \"general\"): \"af_nicole\",\n        (\"technical\", \"general\"): \"am_adam\",\n        (\"announcement\", \"general\"): \"am_michael\",\n        (\"storytelling\", \"children\"): \"af_sarah\",\n        (\"news\", \"general\"): \"am_adam\"\n    }\n    \n    return voice_map.get((content_type, target_audience), \"af_bella\")\n\n# Usage\nvoice = select_voice_for_content(\"educational\", \"adults\")\n```\n\n### 3. **Caching Strategy**\n\nImplement intelligent caching for repeated content:\n\n```python\nimport hashlib\nimport os\n\nclass TTSCache:\n    def __init__(self, cache_dir=\"tts_cache\"):\n        self.cache_dir = cache_dir\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    def get_cache_key(self, text, voice):\n        content = f\"{text}:{voice}\"\n        return hashlib.md5(content.encode()).hexdigest()\n    \n    def get_cached_audio(self, text, voice):\n        cache_key = self.get_cache_key(text, voice)\n        cache_file = os.path.join(self.cache_dir, f\"{cache_key}.wav\")\n        \n        if os.path.exists(cache_file):\n            with open(cache_file, \"rb\") as f:\n                return f.read()\n        return None\n    \n    def cache_audio(self, text, voice, audio_data):\n        cache_key = self.get_cache_key(text, voice)\n        cache_file = os.path.join(self.cache_dir, f\"{cache_key}.wav\")\n        \n        with open(cache_file, \"wb\") as f:\n            f.write(audio_data)\n    \n    def generate_or_get_cached(self, text, voice=\"af_bella\"):\n        # Check cache first\n        cached_audio = self.get_cached_audio(text, voice)\n        if cached_audio:\n            return cached_audio\n        \n        # Generate new audio\n        response = requests.post(\n            \"https://cxmpute.cloud/api/v1/tts\",\n            headers=headers,\n            json={\"text\": text, \"voice\": voice}\n        )\n        \n        if response.ok:\n            audio_data = response.content\n            self.cache_audio(text, voice, audio_data)\n            return audio_data\n        \n        raise Exception(f\"TTS generation failed: {response.status_code}\")\n\n# Usage\ntts_cache = TTSCache()\naudio = tts_cache.generate_or_get_cached(\"Welcome to our service!\", \"af_bella\")\n```\n\n## Pricing\n\nDuring our **testnet phase**, all services are completely **free** for all users! Pricing for the mainnet launch is **to be determined (TBD)**.\n\nJoin our [Discord community](https://discord.gg/vE3xvFsZA8) to stay updated on pricing announcements, give feedback, and connect with other developers building with Cxmpute.\n\n## Support & Community\n\n- **Discord**: Join our [community](https://discord.gg/vE3xvFsZA8) for TTS tips and support\n- **Examples**: Find more examples in our [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready to add voice to your applications?** Start with our simple API and create engaging audio experiences for your users! ",
  "text-to-text": "Generate human-like text responses using state-of-the-art language models through Cxmpute's distributed AI network.\n\n## Overview\n\nCxmpute's Text-to-Text service provides access to powerful large language models (LLMs) for chat completions, text generation, and conversational AI. Our **OpenAI-compatible API** makes it easy to integrate with existing applications.\n\n### Key Features\n\n- **OpenAI Compatibility**: Drop-in replacement for OpenAI's chat completions API\n- **Multiple Models**: Access to dozens of popular LLMs\n- **Streaming Support**: Real-time response generation\n- **Global Network**: Low-latency access through distributed providers\n- **Advanced Features**: Tool calling, JSON mode, and custom formats\n\n## Quick Start\n\n### Basic Chat Completion\n\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/chat/completions \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}\n    ]\n  }'\n```\n\n### Python Example\n\n```python\nimport requests\n\nurl = \"https://cxmpute.cloud/api/v1/chat/completions\"\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"YOUR_USER_ID\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Write a short story about AI and humanity.\"}\n    ],\n    \"temperature\": 0.7,\n    \"max_tokens\": 500\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n\nprint(result[\"choices\"][0][\"message\"][\"content\"])\n```\n\n### Using OpenAI Library\n\n```python\nimport openai\n\nclient = openai.OpenAI(\n    api_key=\"YOUR_API_KEY\",\n    base_url=\"https://cxmpute.cloud/api/v1\",\n    default_headers={\"X-User-Id\": \"YOUR_USER_ID\"}\n)\n\nresponse = client.chat.completions.create(\n    model=\"llama3.1:8b\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n        {\"role\": \"user\", \"content\": \"What are the benefits of renewable energy?\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n```\n\n## API Reference\n\n### Endpoint\n\n```http\nPOST /v1/chat/completions\n```\n\n### Request Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `model` | string | Yes | Model name (see available models) |\n| `messages` | array | Yes | Array of message objects |\n| `stream` | boolean | No | Enable streaming responses (default: false) |\n| `temperature` | number | No | Sampling temperature 0-2 (default: 0.7) |\n| `max_tokens` | number | No | Maximum tokens to generate |\n| `top_p` | number | No | Nucleus sampling parameter (0-1) |\n| `response_format` | object | No | Response format specification |\n| `tools` | array | No | Available tools for function calling |\n\n### Available Models\n\n| Model | Size | Description | Best For |\n|-------|------|-------------|----------|\n| `llama3.1:8b` | 8B | Fast, general-purpose | Most applications |\n| `llama3.1:70b` | 70B | High-quality responses | Complex reasoning |\n| `codellama:13b` | 13B | Code generation | Programming tasks |\n| `mixtral:8x7b` | 8x7B | Mixture of experts | Specialized tasks |\n| `qwen2.5:14b` | 14B | Balanced performance | General use |\n\n*See our full [model catalog](https://cxmpute.cloud/models) for more options.*\n\n## Streaming Responses\n\n### Enable Streaming\n\n```python\nimport requests\nimport json\n\ndef stream_chat_completion(messages, model=\"llama3.1:8b\"):\n    url = \"https://cxmpute.cloud/api/v1/chat/completions\"\n    headers = {\n        \"Authorization\": \"Bearer YOUR_API_KEY\",\n        \"X-User-Id\": \"YOUR_USER_ID\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    data = {\n        \"model\": model,\n        \"messages\": messages,\n        \"stream\": True\n    }\n    \n    response = requests.post(url, headers=headers, json=data, stream=True)\n    \n    for line in response.iter_lines():\n        if line.startswith(b\"data: \"):\n            chunk = line[6:]  # Remove \"data: \" prefix\n            if chunk == b\"[DONE]\":\n                break\n            \n            try:\n                data = json.loads(chunk)\n                if \"choices\" in data and data[\"choices\"]:\n                    delta = data[\"choices\"][0].get(\"delta\", {})\n                    if \"content\" in delta:\n                        yield delta[\"content\"]\n            except json.JSONDecodeError:\n                continue\n\n# Usage\nmessages = [{\"role\": \"user\", \"content\": \"Write a poem about the ocean.\"}]\nfor chunk in stream_chat_completion(messages):\n    print(chunk, end=\"\", flush=True)\n```\n\n## Use Cases\n\n### 1. Chatbot Development\n\nBuild conversational AI applications:\n\n```python\nclass ChatBot:\n    def __init__(self, system_prompt=\"You are a helpful assistant.\"):\n        self.conversation_history = [\n            {\"role\": \"system\", \"content\": system_prompt}\n        ]\n    \n    def chat(self, user_message):\n        self.conversation_history.append({\n            \"role\": \"user\", \n            \"content\": user_message\n        })\n        \n        response = requests.post(\n            \"https://cxmpute.cloud/api/v1/chat/completions\",\n            headers=headers,\n            json={\n                \"model\": \"llama3.1:8b\",\n                \"messages\": self.conversation_history,\n                \"temperature\": 0.7\n            }\n        )\n        \n        ai_response = response.json()[\"choices\"][0][\"message\"][\"content\"]\n        \n        self.conversation_history.append({\n            \"role\": \"assistant\",\n            \"content\": ai_response\n        })\n        \n        return ai_response\n\n# Usage\nbot = ChatBot(\"You are a friendly coding assistant.\")\nresponse = bot.chat(\"How do I reverse a string in Python?\")\nprint(response)\n```\n\n### 2. Content Generation\n\nGenerate blog posts, articles, and marketing content:\n\n```python\ndef generate_blog_post(topic, tone=\"professional\", length=\"medium\"):\n    length_map = {\n        \"short\": \"Write a concise 300-word blog post\",\n        \"medium\": \"Write a comprehensive 800-word blog post\", \n        \"long\": \"Write a detailed 1500-word blog post\"\n    }\n    \n    prompt = f\"\"\"\n    {length_map[length]} about {topic}.\n    Tone: {tone}\n    Include:\n    - Engaging introduction\n    - Clear main points with examples\n    - Actionable takeaways\n    - Compelling conclusion\n    \"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.1:70b\",\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.8,\n            \"max_tokens\": 2000\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Usage\narticle = generate_blog_post(\"sustainable energy solutions\", \"informative\", \"medium\")\nprint(article)\n```\n\n### 3. Code Generation\n\nGenerate and explain code:\n\n```python\ndef code_assistant(task, language=\"python\"):\n    prompt = f\"\"\"\n    Task: {task}\n    Language: {language}\n    \n    Please provide:\n    1. Clean, well-commented code\n    2. Explanation of how it works\n    3. Example usage\n    4. Best practices\n    \"\"\"\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"codellama:13b\",\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.3\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Usage\ncode_help = code_assistant(\"Create a REST API endpoint for user authentication using Flask\")\nprint(code_help)\n```\n\n## Best Practices\n\n### 1. Temperature Control\n\nAdjust response creativity:\n\n```python\ndef generate_with_creativity(prompt, creativity_level=\"balanced\"):\n    temperature_map = {\n        \"factual\": 0.1,      # Very consistent, factual responses\n        \"balanced\": 0.7,     # Good balance of accuracy and creativity\n        \"creative\": 1.2,     # More creative and diverse responses\n    }\n    \n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.1:8b\",\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": temperature_map[creativity_level]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n```\n\n### 2. Error Handling\n\nImplement robust error handling:\n\n```python\nimport time\nimport random\n\ndef resilient_chat_completion(messages, model=\"llama3.1:8b\", max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            response = requests.post(\n                \"https://cxmpute.cloud/api/v1/chat/completions\",\n                headers=headers,\n                json={\n                    \"model\": model,\n                    \"messages\": messages,\n                    \"temperature\": 0.7\n                },\n                timeout=60\n            )\n            \n            if response.status_code == 200:\n                return response.json()\n            elif response.status_code == 503:\n                wait_time = (2 ** attempt) + random.uniform(0, 1)\n                time.sleep(wait_time)\n                continue\n            else:\n                response.raise_for_status()\n                \n        except requests.exceptions.RequestException as e:\n            if attempt == max_retries - 1:\n                raise e\n            time.sleep(1)\n    \n    raise Exception(\"Failed to get response after all retries\")\n```\n\n## Pricing\n\nDuring our **testnet phase**, all services are completely **free** for all users! Pricing for the mainnet launch is **to be determined (TBD)**.\n\nJoin our [Discord community](https://discord.gg/vE3xvFsZA8) to stay updated on pricing announcements, give feedback, and connect with other developers building with Cxmpute.\n\n## Support\n\n- **Discord**: [Community support](https://discord.gg/vE3xvFsZA8)\n- **Contact**: [https://tally.so/r/w4DvLA](https://tally.so/r/w4DvLA)\n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n- **Model Catalog**: [Browse all available models](https://cxmpute.cloud/models)\n\n---\n\n**Ready to build with AI?** Start with our OpenAI-compatible API and create intelligent applications powered by the world's best language models! ",
  "tool-use-json": "Enable function calling and structured outputs with advanced language models.\n\n## Overview\n\nCxmpute supports tool calling and structured outputs, allowing models to interact with external functions, APIs, and return data in specific JSON formats.\n\n### Key Features\n\n- **Function Calling**: Models can call predefined functions and tools\n- **Structured Outputs**: Force models to return specific JSON schemas\n- **OpenAI Compatible**: Works with existing OpenAI tool calling code\n- **Multiple Models**: Available on supported models (Qwen3, Deepseek, Llama 3, etc.)\n\n## Tool Calling\n\nEnable models to call functions and interact with external systems.\n\n### Basic Example\n\n```python\nimport requests\n\n# Define available tools\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_weather\",\n            \"description\": \"Get the current weather for a city\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"city\": {\n                        \"type\": \"string\",\n                        \"description\": \"The name of the city\"\n                    }\n                },\n                \"required\": [\"city\"]\n            }\n        }\n    }\n]\n\ndata = {\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"What's the weather in New York?\"}\n    ],\n    \"tools\": tools\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n\n# Check if model wants to call a function\nif result[\"choices\"][0][\"message\"].get(\"tool_calls\"):\n    tool_call = result[\"choices\"][0][\"message\"][\"tool_calls\"][0]\n    function_name = tool_call[\"function\"][\"name\"]\n    function_args = tool_call[\"function\"][\"arguments\"]\n    \n    print(f\"Model wants to call: {function_name}\")\n    print(f\"With arguments: {function_args}\")\n```\n\n## JSON Mode\n\nForce models to return data in specific JSON formats.\n\n### Basic JSON Response\n\n```python\ndef get_structured_response(prompt, model=\"llama3.1:8b\"):\n    response = requests.post(\n        \"https://cxmpute.cloud/api/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [\n                {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nRespond with valid JSON only.\"}\n            ],\n            \"response_format\": {\n                \"type\": \"json_object\"\n            }\n        }\n    )\n    \n    return json.loads(response.json()[\"choices\"][0][\"message\"][\"content\"])\n\n# Usage\nprompt = \"Analyze this review: 'Great product, but expensive.'\"\nresult = get_structured_response(prompt)\nprint(json.dumps(result, indent=2))\n```\n\n## Use Cases\n\n### 1. Data Extraction\n\nExtract structured information from unstructured text.\n\n### 2. API Integration\n\nCreate tools that interact with external APIs and services.\n\n### 3. Content Classification\n\nAutomatically classify and tag content with structured metadata.\n\n### 4. Form Processing\n\nProcess documents and forms into structured data.\n\n## Supported Models\n\nTool calling and JSON mode are available on:\n\n- ‚úÖ **Qwen 3** (4B, 8B, 14B, 30B, 32B) - Full tool calling support\n- ‚úÖ **Llama 3.1** (8B) - Full tool calling support\n- ‚úÖ **Llama 3.2** (1B, 3B) - Tool calling support\n- ‚úÖ **Llama 3.3** (70B) - Tool calling support\n- ‚úÖ **Qwen 2.5** (7B, 14B, 32B, 72B) - Tool calling support\n- ‚úÖ **Qwen 2.5 Coder** (3B, 7B, 14B, 32B) - Tool calling support\n- ‚úÖ **QwQ** (32B) - Reasoning with tool calling support\n- ‚úÖ **Cogito** (3B, 8B, 14B, 32B, 70B) - Tool calling support\n- ‚úÖ **Mistral** (7B) - Tool calling support\n- ‚úÖ **Mistral Nemo** (12B) - Tool calling support\n- ‚úÖ **Mistral Small 3.1** (24B) - Vision + tool calling support\n- ‚úÖ **Phi-4 Mini** (3.8B) - Tool calling support\n- ‚úÖ **Granite 3.2 Vision** (2B) - Vision + tool calling support\n- üöß **Other models** - Basic JSON formatting\n\n## Examples\n\nVisit our [GitHub repository](https://github.com/unxversal/cxmpute-core) for complete examples and tutorials.\n\n## Support\n\n- **Discord**: [Community support](https://discord.gg/vE3xvFsZA8)\n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready to build intelligent applications?** Use our tool calling and structured outputs to create AI systems that can interact with the real world! ",
  "user": "Welcome to Cxmpute! This guide will help you get started using our AI services through our simple, OpenAI-compatible APIs.\n\n## Overview\n\nCxmpute provides an inference and related services powered by a global network of nodes run by providers. We offer:\n\n- **LLM inference** with dozens of popular models\n- **Text embeddings** for semantic search and RAG applications  \n- **Text-to-speech** with natural voice synthesis\n- **Web scraping** with intelligent content extraction\n- **Tool use and JSON mode** for structured outputs\n\nLearn more about specific use cases:\n- [Text-to-Speech](/docs/text-to-speech)\n- [Text-to-Text (LLM)](/docs/text-to-text) \n- [Embeddings](/docs/embeddings)\n- [Web Scraping](/docs/scraping)\n- [Tool Use & JSON](/docs/tool-use-json)\n- [Advanced LLMs](/docs/advanced-llms)\n\n## Getting Started\n\n### 1. Create Your Account\n\nGo to the [Cxmpute Dashboard](https://cxmpute.cloud/dashboard) to create your account.\n\n### 2. Get Your API Key\n\nWhen your account is created, you'll see your base user API key. This key has **no limits** in terms of usage and accessible services during our testnet phase.\n\n‚ö†Ô∏è **Important**: Practice good key management. Never expose your API keys in client-side code or public repositories. If your key has been compromised, refresh it immediately in the dashboard.\n\n### 3. Create Virtual API Keys (Optional)\n\nYou can create virtual API keys with specific limitations:\n- **Spend limits**: Set maximum credit usage\n- **Service restrictions**: Limit access to specific endpoints\n- **Usage tracking**: Monitor usage per key\n\n## Authentication\n\nAll API requests require authentication using your API key:\n\n```bash\nAuthorization: Bearer YOUR_API_KEY\nX-User-Id: YOUR_USER_ID\n```\n\n### Required Headers\n\n- `Authorization`: Your API key in Bearer token format\n- `X-User-Id`: Your user ID from the dashboard\n- `Content-Type: application/json` (for POST requests)\n\n### Optional Headers\n\n- `X-Title`: Service title for analytics\n- `HTTP-Referer`: Service URL for analytics\n\n## Base URL\n\nAll API endpoints use the base URL:\n```\nhttps://cxmpute.cloud/api\n```\n\n## API Reference\n\n### Chat Completions\n\n**OpenAI-compatible endpoint** for text generation and conversations.\n\n```http\nPOST /v1/chat/completions\n```\n\n#### Request Body\n\n```json\n{\n  \"model\": \"llama3.1:8b\",\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n  ],\n  \"stream\": false,\n  \"temperature\": 0.7,\n  \"max_tokens\": 1000\n}\n```\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `model` | string | Yes | Model name (see [model catalog](https://cxmpute.cloud/models)) |\n| `messages` | array | Yes | Array of message objects with `role` and `content` |\n| `stream` | boolean | No | Enable streaming responses (default: false) |\n| `temperature` | number | No | Sampling temperature 0-2 (default: 0.7) |\n| `max_tokens` | number | No | Maximum tokens to generate |\n| `top_p` | number | No | Nucleus sampling parameter |\n| `response_format` | string/object | No | Response format (see [JSON mode](/docs/tool-use-json)) |\n| `tools` | array | No | Available tools for function calling |\n\n#### Response\n\n**Non-streaming:**\n```json\n{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"llama3.1:8b\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"Hello! I'm doing well, thank you for asking. How can I help you today?\"\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 10,\n    \"completion_tokens\": 20,\n    \"total_tokens\": 30\n  }\n}\n```\n\n**Streaming:**\n```\ndata: {\"choices\":[{\"delta\":{\"content\":\"Hello\"}}]}\ndata: {\"choices\":[{\"delta\":{\"content\":\"!\"}}]}\ndata: [DONE]\n```\n\n#### Example\n\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/chat/completions \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Write a haiku about AI\"}\n    ],\n    \"temperature\": 0.8\n  }'\n```\n\n### Embeddings\n\nGenerate vector embeddings for text.\n\n```http\nPOST /v1/embeddings\n```\n\n#### Request Body\n\n```json\n{\n  \"model\": \"nomic-embed-text\",\n  \"input\": \"Your text to embed\",\n  \"truncate\": true\n}\n```\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `model` | string | Yes | Embedding model name |\n| `input` | string/array | Yes | Text(s) to embed |\n| `truncate` | boolean | No | Truncate input to model's max length |\n\n#### Response\n\n```json\n{\n  \"object\": \"list\",\n  \"data\": [{\n    \"object\": \"embedding\",\n    \"embedding\": [0.1, -0.2, 0.3, ...],\n    \"index\": 0\n  }],\n  \"model\": \"nomic-embed-text\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\n```\n\n#### Example\n\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/embeddings \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"nomic-embed-text\",\n    \"input\": \"This is a sample text for embedding\"\n  }'\n```\n\n### Text-to-Speech\n\nConvert text to natural speech.\n\n```http\nPOST /v1/tts\n```\n\n#### Request Body\n\n```json\n{\n  \"text\": \"Hello, this is a test of text to speech.\",\n  \"voice\": \"af_bella\"\n}\n```\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `text` | string | Yes | Text to convert to speech |\n| `voice` | string | No | Voice model (default: \"af_bella\") |\n\n#### Response\n\nReturns audio data in WAV format with `Content-Type: audio/wav`.\n\n#### Example\n\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/tts \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"text\": \"Welcome to Cxmpute!\",\n    \"voice\": \"af_bella\"\n  }' \\\n  --output speech.wav\n```\n\n### Web Scraping\n\nExtract content from web pages.\n\n```http\nPOST /v1/scrape\n```\n\n#### Request Body\n\n```json\n{\n  \"urls\": [\"https://example.com\"],\n  \"format\": \"markdown\"\n}\n```\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `urls` | array | Yes | Array of URLs to scrape |\n| `format` | string | No | Output format: \"markdown\", \"text\", \"html\" |\n\n#### Response\n\n```json\n{\n  \"results\": [{\n    \"url\": \"https://example.com\",\n    \"content\": \"# Example Page\\n\\nThis is the content...\",\n    \"success\": true,\n    \"metadata\": {\n      \"title\": \"Example Page\",\n      \"description\": \"An example webpage\"\n    }\n  }]\n}\n```\n\n#### Example\n\n```bash\ncurl -X POST https://cxmpute.cloud/api/v1/scrape \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"urls\": [\"https://docs.cxmpute.cloud\"],\n    \"format\": \"markdown\"\n  }'\n```\n\n## OpenAI Compatibility\n\nOur `/v1/chat/completions` endpoint is fully **OpenAI-compatible**! You can use existing OpenAI libraries by simply changing the base URL:\n\n### Python (OpenAI Library)\n\n```python\nimport openai\n\nclient = openai.OpenAI(\n    api_key=\"YOUR_API_KEY\",\n    base_url=\"https://cxmpute.cloud/api/v1\",\n    default_headers={\"X-User-Id\": \"YOUR_USER_ID\"}\n)\n\nresponse = client.chat.completions.create(\n    model=\"llama3.1:8b\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ]\n)\n```\n\n### JavaScript\n\n```javascript\nimport OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: 'YOUR_API_KEY',\n  baseURL: 'https://cxmpute.cloud/api/v1',\n  defaultHeaders: {\n    'X-User-Id': 'YOUR_USER_ID'\n  }\n});\n\nconst completion = await openai.chat.completions.create({\n  messages: [{ role: 'user', content: 'Hello!' }],\n  model: 'llama3.1:8b',\n});\n```\n\n## Model Catalog\n\nExplore our full model list at [cxmpute.cloud/models](https://cxmpute.cloud/models).\n\nPopular models include:\n- **llama3.1:8b** - Fast, capable general-purpose model\n- **llama3.1:70b** - Larger model for complex tasks\n- **nomic-embed-text** - High-quality text embeddings\n- **codellama:13b** - Specialized for code generation\n\nVisit specific model pages in our catalog to see their request formats and capabilities.\n\n## Testnet & Rewards\n\nüéâ **During our testnet phase, all services are currently free!** You also earn rewards based on usage and referrals.\n\n[Learn more about our rewards program ‚Üí](/docs/rewards)\n\n## Error Handling\n\n### HTTP Status Codes\n\n- `200` - Success\n- `400` - Bad Request (missing/invalid parameters)\n- `401` - Unauthorized (invalid API key)\n- `429` - Rate Limited\n- `503` - Service Unavailable (no healthy providers)\n- `500` - Internal Server Error\n\n### Error Response Format\n\n```json\n{\n  \"error\": \"Error description\"\n}\n```\n\n### Common Errors\n\n**Invalid API Key:**\n```json\n{\n  \"error\": \"Invalid API key\"\n}\n```\n\n**Missing Model:**\n```json\n{\n  \"error\": \"Missing required parameter: model or messages\"\n}\n```\n\n**No Providers Available:**\n```json\n{\n  \"error\": \"No provisions available for the requested model\"\n}\n```\n\n## Rate Limits\n\nDuring testnet, there are no strict rate limits. However, fair usage policies apply to ensure service availability for all users.\n\n## Support\n\nNeed help? We're here for you:\n\n- **Discord**: Join our [community](https://discord.com/invite/CJGA7B2zKT) for real-time support\n- **Email**: Contact [support@cxmpute.cloud](https://tally.so/r/w4DvLA)\n- **GitHub**: Report issues on our [repository](https://github.com/unxversal/cxmpute-core)\n\n## Next Steps\n\n- [Explore specific services](/docs) for detailed guides\n- [Learn about becoming a provider](/docs/provider) \n- [Join our Discord](https://discord.com/invite/CJGA7B2zKT) for the latest news\n- [Check out our model catalog](https://cxmpute.cloud/models) "
};
// Doc interface and data moved from docs.ts
export interface Doc {
    slug: string;
    title: string;
    description: string;
    content: string; // markdown
    icon: LucideIcon; // lucide icon component
    category?: string;
}

export const docs: Doc[] = [
  {
    slug: '',
    title: 'Documentation Home',
    description: 'Welcome to Cxmpute documentation - your guide to distributed AI services',
    content: docsContent.index,
    icon: FileText,
    category: 'Getting Started'
  },
  {
    slug: 'user',
    title: 'User Guide',
    description: 'Complete API reference and getting started guide for using Cxmpute services',
    content: docsContent.user,
    icon: Users,
    category: 'Getting Started'
  },
  {
    slug: 'provider',
    title: 'Provider Guide',
    description: 'How to become a compute provider and start earning rewards',
    content: docsContent.provider,
    icon: Cpu,
    category: 'Getting Started'
  },
  {
    slug: 'about',
    title: 'About Cxmpute',
    description: 'Platform overview, architecture, and technical details',
    content: docsContent.about,
    icon: Info,
    category: 'Platform'
  },
  {
    slug: 'rewards',
    title: 'Rewards System',
    description: 'Learn about earning rewards, referrals, and the points system',
    content: docsContent.rewards,
    icon: Gift,
    category: 'Platform'
  },
  {
    slug: 'text-to-text',
    title: 'Text-to-Text (LLM)',
    description: 'Chat completions and text generation with large language models',
    content: docsContent['text-to-text'],
    icon: MessageSquare,
    category: 'AI Services'
  },
  {
    slug: 'embeddings',
    title: 'Text Embeddings',
    description: 'Vector embeddings for semantic search and RAG applications',
    content: docsContent.embeddings,
    icon: Search,
    category: 'AI Services'
  },
  {
    slug: 'text-to-speech',
    title: 'Text-to-Speech',
    description: 'Natural voice synthesis and audio generation from text',
    content: docsContent['text-to-speech'],
    icon: Volume2,
    category: 'AI Services'
  },
  {
    slug: 'scraping',
    title: 'Web Scraping',
    description: 'Intelligent content extraction and web data collection',
    content: docsContent.scraping,
    icon: Globe,
    category: 'AI Services'
  },
  {
    slug: 'tool-use-json',
    title: 'Tool Use & JSON',
    description: 'Structured outputs, function calling, and advanced features',
    content: docsContent['tool-use-json'],
    icon: Wrench,
    category: 'Advanced'
  },
  {
    slug: 'advanced-llms',
    title: 'Advanced LLMs',
    description: 'Advanced features for large language models and specialized capabilities',
    content: docsContent['advanced-llms'],
    icon: Brain,
    category: 'Advanced'
  }
];

// Helper function to get doc by slug
export const getDocBySlug = (slug: string): Doc | undefined => {
  return docs.find(doc => doc.slug === slug);
};

// Helper function to get docs by category
export const getDocsByCategory = (): Record<string, Doc[]> => {
  return docs.reduce((acc, doc) => {
    const category = doc.category || 'Other';
    if (!acc[category]) {
      acc[category] = [];
    }
    acc[category].push(doc);
    return acc;
  }, {} as Record<string, Doc[]>);
};

export default function DocsHomePage() {
  const doc = getDocBySlug(''); // Get the home doc (index.md)
  
  if (!doc) {
    notFound();
  }

  return (
    <div className={styles.docsPage}>
      <header className={styles.docHeader}>
        <h1>{doc.title}</h1>
        <p className={styles.docDescription}>{doc.description}</p>
      </header>

      <div className={styles.docContent}>
        <ReactMarkdown
          remarkPlugins={[remarkGfm]}
          components={{
            code({ className, children, ...props }) {
              const match = /language-(\w+)/.exec(className || '');
              const language = match ? match[1] : '';
              const code = String(children).replace(/\n$/, '');
              
              // Check if this is a code block (has language) vs inline code
              return match ? (
                <CodeBlock language={language} code={code} />
              ) : (
                <code className={styles.inlineCode} {...props}>
                  {children}
                </code>
              );
            },
            a({ href, children, ...props }) {
              // Handle internal links
              if (href?.startsWith('/docs/')) {
                return (
                  <Link href={href} {...props}>
                    {children}
                  </Link>
                );
              }
              // External links open in new tab
              return (
                <a href={href} target="_blank" rel="noopener noreferrer" {...props}>
                  {children}
                </a>
              );
            },
            h1: ({ children }) => <h1 className={styles.h1}>{children}</h1>,
            h2: ({ children }) => <h2 className={styles.h2}>{children}</h2>,
            h3: ({ children }) => <h3 className={styles.h3}>{children}</h3>,
            h4: ({ children }) => <h4 className={styles.h4}>{children}</h4>,
            p: ({ children }) => <p className={styles.paragraph}>{children}</p>,
            ul: ({ children }) => <ul className={styles.list}>{children}</ul>,
            ol: ({ children }) => <ol className={styles.orderedList}>{children}</ol>,
            li: ({ children }) => <li className={styles.listItem}>{children}</li>,
            blockquote: ({ children }) => <blockquote className={styles.blockquote}>{children}</blockquote>,
            table: ({ children }) => <table className={styles.table}>{children}</table>,
            thead: ({ children }) => <thead className={styles.tableHead}>{children}</thead>,
            tbody: ({ children }) => <tbody className={styles.tableBody}>{children}</tbody>,
            tr: ({ children }) => <tr className={styles.tableRow}>{children}</tr>,
            th: ({ children }) => <th className={styles.tableHeader}>{children}</th>,
            td: ({ children }) => <td className={styles.tableCell}>{children}</td>,
            pre: ({ children }) => <div className={styles.preWrapper}>{children}</div>,
          }}
        >
          {doc.content}
        </ReactMarkdown>
      </div>
    </div>
  );
}
