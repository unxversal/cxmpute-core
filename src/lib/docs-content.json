{
  "about": "# About Cxmpute\n\nCxmpute is a distributed AI/Compute services platform that connects users who need AI services with providers who offer compute resources, creating a global network of AI compute power.\n\n## Our Mission\n\nWe're building the future of AI infrastructure by democratizing access to compute resources and creating new income opportunities for hardware owners worldwide.\n\n### The Problem We Solve\n\n- **High AI Costs**: Traditional cloud providers charge premium rates for AI services\n- **Limited Access**: Many developers can't afford enterprise-grade AI infrastructure\n- **Wasted Resources**: Millions of powerful computers sit idle while AI demand grows\n- **Centralization**: AI compute is concentrated in a few major cloud providers\n\n### Our Solution\n\nCxmpute creates a **decentralized marketplace** where:\n- **Users** get affordable, high-quality AI services\n- **Providers** monetize their idle hardware\n- **Everyone** benefits from a more distributed, resilient AI infrastructure\n\n## How Cxmpute Works\n\n### The Network\n\n```\n‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n‚îÇ   Users & Apps  ‚îÇ    ‚îÇ  Cxmpute Core    ‚îÇ    ‚îÇ    Providers    ‚îÇ\n‚îÇ                 ‚îÇ    ‚îÇ  (AWS/Platform)  ‚îÇ    ‚îÇ                 ‚îÇ\n‚îÇ ‚Ä¢ Developers    ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ                  ‚îÇ‚óÑ‚îÄ‚îÄ‚ñ∫‚îÇ ‚Ä¢ Home Gamers   ‚îÇ\n‚îÇ ‚Ä¢ Businesses    ‚îÇ    ‚îÇ  ‚Ä¢ Load Balancer ‚îÇ    ‚îÇ ‚Ä¢ Data Centers  ‚îÇ\n‚îÇ ‚Ä¢ AI Companies  ‚îÇ    ‚îÇ  ‚Ä¢ Health Monitor‚îÇ    ‚îÇ ‚Ä¢ Universities  ‚îÇ\n‚îÇ ‚Ä¢ Researchers   ‚îÇ    ‚îÇ  ‚Ä¢ Orchestrator  ‚îÇ    ‚îÇ ‚Ä¢ Crypto Miners ‚îÇ\n‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n```\n\n### Core Components\n\n#### 1. **Cxmpute Core** (Central Platform)\n- **Load Balancing**: Routes requests to optimal providers\n- **Health Monitoring**: Ensures provider reliability\n- **Orchestration**: Manages the entire network\n- **Billing & Rewards**: Handles payments and provider compensation\n\n#### 2. **User Layer** (API & Dashboard)\n- **OpenAI-Compatible APIs**: Easy integration for developers\n- **Dashboard**: User-friendly interface for management\n- **Analytics**: Usage tracking and insights\n- **Billing**: Transparent pricing and usage monitoring\n\n#### 3. **Provider Network** (Distributed Compute)\n- **Provider CLI**: Simple onboarding and management\n- **Auto-Discovery**: Automatic hardware profiling\n- **Service Orchestration**: Smart service assignment\n- **Earnings Dashboard**: Real-time earnings tracking\n\n## What We Offer\n\n### For Users\n\n**ü§ñ LLM Inference**\n- Chat completions with dozens of models\n- OpenAI-compatible API endpoints\n- Streaming and non-streaming responses\n- Custom model support\n\n**üîç Text Embeddings**\n- High-quality vector embeddings\n- Multiple embedding models\n- Batch processing support\n- Optimized for semantic search\n\n**üó£Ô∏è Text-to-Speech**\n- Natural voice synthesis\n- Multiple voice models\n- High-quality audio output\n- Fast generation times\n\n**üåê Web Scraping**\n- Intelligent content extraction\n- Markdown conversion\n- Batch URL processing\n- Metadata extraction\n\n**üõ†Ô∏è Advanced Features**\n- Tool calling and function execution\n- Structured JSON outputs\n- Custom response formats\n- Vision and multimodal capabilities\n\n### For Providers\n\n**üí∞ Passive Income**\n- Earn money from idle hardware\n- Automatic service orchestration\n- Real-time earnings tracking\n- Flexible participation levels\n\n**üèÜ Tiered System**\n- Rewards based on hardware capabilities\n- Higher tiers get premium rates\n- Performance-based bonuses\n- Referral earnings\n\n**üîß Simple Setup**\n- One-click CLI installation\n- Automatic hardware detection\n- No technical expertise required\n- Continuous updates and support\n\n## Technology Stack\n\n### Platform Architecture\n\n**Frontend & API**\n- **Next.js 15**: Modern React framework with App Router\n- **TypeScript**: Type-safe development\n- **OpenAI Compatibility**: Seamless integration\n\n**Backend Infrastructure**\n- **AWS Serverless**: Lambda, DynamoDB, API Gateway\n- **SST v3**: Infrastructure as Code\n- **Health Monitoring**: Real-time provider tracking\n- **Load Balancing**: Intelligent request routing\n\n**Provider Network**\n- **React Ink CLI**: Professional terminal interface\n- **Ollama Integration**: Local LLM serving\n- **Tunneling**: Secure public access via Tunnelmole\n- **Multi-platform**: macOS, Linux, Windows support\n\n### Security & Privacy\n\n**Data Protection**\n- End-to-end encryption for all communications\n- No access to provider's personal files\n- Isolated compute environments\n- Privacy-first architecture\n\n**Provider Security**\n- Sandboxed AI model execution\n- No system access beyond compute\n- Automatic security updates\n- Encrypted credential management\n\n**Network Security**\n- DDoS protection and mitigation\n- Rate limiting and abuse prevention\n- Health monitoring and automatic failover\n- Secure tunnel management\n\n## Business Model\n\n### Revenue Streams\n\n1. **Service Fees**: Small fee on AI service transactions\n2. **Premium Features**: Advanced analytics and custom models\n3. **Enterprise Solutions**: Dedicated infrastructure and support\n\n### Provider Economics\n\n- **Direct Rewards**: Providers earn majority of service fees\n- **Performance Bonuses**: Extra rewards for reliable service\n- **Referral Program**: Ongoing earnings from network growth\n- **Transparent Pricing**: Clear, predictable reward structure\n\n### Sustainability\n\n- **Community-Driven**: Network grows through user and provider satisfaction\n- **Efficient Resource Use**: Better utilization of existing hardware\n- **Competitive Pricing**: Market-driven rates benefit everyone\n\n## Network Statistics\n\n### Global Reach\n\n- **Providers**: Thousands of active compute providers\n- **Coverage**: 50+ countries with growing presence\n- **Capacity**: Petabytes of available compute power\n- **Uptime**: 99.5%+ network availability\n\n### Performance Metrics\n\n- **Latency**: <200ms average response time globally\n- **Throughput**: Millions of requests processed daily\n- **Reliability**: Automatic failover and health monitoring\n- **Scalability**: Dynamic scaling based on demand\n\n## Roadmap & Vision\n\n### Current Phase: Testnet\n\n‚úÖ **Complete**\n- Core platform infrastructure\n- Provider CLI and onboarding\n- Basic AI services (chat, embeddings, TTS, scraping)\n- Reward system and analytics\n\n### Near Term (6 months)\n\nüöß **In Progress**\n- Advanced model support and custom models\n- Enhanced provider analytics and optimization\n- Mobile SDK and expanded API features\n- Mainnet launch with full payments\n\n### Long Term (12+ months)\n\nüîÆ **Planned**\n- Cross-chain integration and crypto payments\n- Advanced governance and DAO features\n- Enterprise partnerships and custom solutions\n- Global expansion and regulatory compliance\n\n## Community & Governance\n\n### Open Source Commitment\n\n- **Transparent Development**: Core platform is open source\n- **Community Contributions**: Open to external developers\n- **Public Roadmap**: Community input on feature priorities\n- **Regular Updates**: Frequent communication and releases\n\n### Community Channels\n\n- **Discord**: [Real-time community chat](https://discord.com/invite/CJGA7B2zKT)\n- **GitHub**: [Open source development](https://github.com/unxversal/cxmpute-core)\n- **Twitter**: [@cxmpute](https://twitter.com/cxmpute) for news and updates\n- **Reddit**: [r/cxmpute](https://reddit.com/r/cxmpute) for discussions\n\n## Team & Support\n\n### Founded By\n\nExperienced developers and entrepreneurs passionate about democratizing AI infrastructure and creating new economic opportunities through technology.\n\n### Values\n\n- **Accessibility**: Making AI services available to everyone\n- **Transparency**: Open development and clear communication\n- **Community**: Building together with users and providers\n- **Innovation**: Pushing the boundaries of distributed computing\n\n### Support\n\n- **24/7 Community**: Active Discord community for peer support\n- **Documentation**: Comprehensive guides and API reference\n- **Email Support**: Direct contact for technical issues\n- **Regular Updates**: Continuous platform improvements\n\n## Getting Started\n\n### For Users\n1. **[Create Account](https://cxmpute.cloud/dashboard)** - Sign up and get your API key\n2. **[Read Docs](/docs/user)** - Learn about our APIs and services\n3. **[Make First Request](/docs/user#getting-started)** - Try our services for free\n\n### For Providers\n1. **[Download CLI](https://github.com/unxversal/cxmpute-core/releases)** - Get the provider software\n2. **[Follow Setup](/docs/provider)** - Complete onboarding process\n3. **[Start Earning](/docs/provider#step-5-start-earning)** - Begin receiving requests and rewards\n\n### For Developers\n1. **[API Documentation](/docs/user)** - Complete API reference\n2. **[Code Examples](/docs/text-to-text)** - Sample implementations\n3. **[Community](/docs#community--support)** - Join our developer community\n\n---\n\n**Ready to be part of the future of AI?** Whether you want to use our services or provide compute power, Cxmpute makes it simple to participate in the decentralized AI economy.\n\n[Get Started Today ‚Üí](https://cxmpute.cloud/dashboard) ",
  "advanced-llms": "# Advanced LLMs\n\nExplore advanced features and capabilities of Cxmpute's large language models for sophisticated AI applications.\n\n## Overview\n\nCxmpute provides access to state-of-the-art language models with advanced features like thinking modes, structured outputs, multi-modal capabilities, and specialized model variants.\n\n### Advanced Features\n\n- **Thinking Models**: Models with visible reasoning processes\n- **Vision Capabilities**: Analyze images and visual content\n- **Structured Outputs**: Reliable JSON and schema-based responses\n- **Custom Fine-tuned Models**: Specialized models for specific domains\n- **Multi-turn Conversations**: Long-context conversations with memory\n\n## Thinking Models\n\nSome models support \"thinking\" mode where you can see their reasoning process.\n\n### Models with Thinking\n\n- **DeepSeek R1**: Advanced reasoning with visible thought process\n- **Qwen 3**: Thinking-capable model with step-by-step reasoning\n\n### Enable Thinking\n\n```python\nresponse = requests.post(\n    \"https://api.cxmpute.cloud/v1/chat/completions\",\n    headers=headers,\n    json={\n        \"model\": \"deepseek-r1:8b\",\n        \"messages\": [\n            {\"role\": \"user\", \"content\": \"How many r's are in the word strawberry?\"}\n        ],\n        \"think\": True\n    }\n)\n\nresult = response.json()\nmessage = result[\"choices\"][0][\"message\"]\n\nprint(\"Thinking:\")\nprint(message.get(\"thinking\", \"\"))\nprint(\"\\nFinal Answer:\")\nprint(message[\"content\"])\n```\n\n### Thinking vs No Thinking\n\n**With Thinking**: More accurate, shows reasoning, takes longer\n**Without Thinking**: Faster responses, direct answers\n\n## Vision Models\n\nAnalyze images and visual content with vision-capable models.\n\n### Supported Models\n\n- **Llama 3.2 Vision**: General vision understanding\n- **GPT-4V Compatible**: Image analysis and description\n\n### Image Analysis\n\n```python\nimport base64\n\ndef encode_image(image_path):\n    with open(image_path, \"rb\") as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\n# Analyze an image\nimage_base64 = encode_image(\"path/to/image.jpg\")\n\nresponse = requests.post(\n    \"https://api.cxmpute.cloud/v1/chat/completions\",\n    headers=headers,\n    json={\n        \"model\": \"llama3.2-vision\",\n        \"messages\": [\n            {\n                \"role\": \"user\",\n                \"content\": [\n                    {\"type\": \"text\", \"text\": \"What do you see in this image?\"},\n                    {\n                        \"type\": \"image_url\",\n                        \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}\n                    }\n                ]\n            }\n        ]\n    }\n)\n\nresult = response.json()\nprint(result[\"choices\"][0][\"message\"][\"content\"])\n```\n\n### Vision Use Cases\n\n- **Document Analysis**: Extract text and data from documents\n- **Object Detection**: Identify objects and scenes in images\n- **Chart Reading**: Analyze graphs, charts, and diagrams\n- **Medical Imaging**: Analyze medical scans (with proper disclaimers)\n\n## Code Generation Models\n\nSpecialized models optimized for programming tasks.\n\n### CodeLlama Variants\n\n- **CodeLlama Base**: General code generation\n- **CodeLlama Instruct**: Code with natural language instructions\n- **CodeLlama Python**: Python-specialized variant\n\n### Code Generation\n\n```python\ndef generate_code(task, language=\"python\", model=\"codellama:13b\"):\n    prompt = f\"\"\"\n    Task: {task}\n    Language: {language}\n    \n    Requirements:\n    - Write clean, well-commented code\n    - Include error handling where appropriate\n    - Provide usage examples\n    - Follow best practices\n    \"\"\"\n    \n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.2  # Lower temperature for more deterministic code\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Usage\ncode = generate_code(\"Create a REST API endpoint for user authentication using Flask\")\nprint(code)\n```\n\n## Specialized Models\n\nDomain-specific models for particular use cases.\n\n### Available Specialized Models\n\n- **Medical Models**: Healthcare and medical text analysis\n- **Legal Models**: Legal document analysis and drafting\n- **Financial Models**: Financial analysis and reporting\n- **Scientific Models**: Research paper analysis and scientific writing\n\n### Domain-Specific Analysis\n\n```python\ndef analyze_medical_text(text):\n    \"\"\"Analyze medical text with specialized model\"\"\"\n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"medical-llama:8b\",\n            \"messages\": [\n                {\"role\": \"system\", \"content\": \"You are a medical AI assistant. Provide informative responses while emphasizing that this is not medical advice.\"},\n                {\"role\": \"user\", \"content\": f\"Analyze this medical text: {text}\"}\n            ]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n```\n\n## Long Context Models\n\nModels capable of handling very long conversations and documents.\n\n### Context Length Capabilities\n\n| Model | Context Length | Best For |\n|-------|----------------|----------|\n| Llama 3.1 70B | 128K tokens | Long documents |\n| Claude-compatible | 200K tokens | Entire books |\n| GPT-4 Turbo | 128K tokens | Extended conversations |\n\n### Long Document Processing\n\n```python\ndef process_long_document(document_text, query):\n    \"\"\"Process long documents with high-context models\"\"\"\n    \n    # Estimate tokens (rough: 4 chars per token)\n    estimated_tokens = len(document_text) // 4\n    \n    if estimated_tokens > 100000:\n        model = \"llama3.1:70b\"  # Use larger context model\n    else:\n        model = \"llama3.1:8b\"\n    \n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [\n                {\"role\": \"user\", \"content\": f\"Document:\\n{document_text}\\n\\nQuery: {query}\"}\n            ]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n```\n\n## Multi-Modal Capabilities\n\nAdvanced models that can handle multiple types of input.\n\n### Text + Image Analysis\n\n```python\ndef analyze_chart_with_context(image_base64, context_text):\n    \"\"\"Analyze charts and graphs with additional context\"\"\"\n    \n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.2-vision\",\n            \"messages\": [\n                {\n                    \"role\": \"user\",\n                    \"content\": [\n                        {\"type\": \"text\", \"text\": f\"Context: {context_text}\"},\n                        {\"type\": \"text\", \"text\": \"Please analyze this chart in the context provided:\"},\n                        {\n                            \"type\": \"image_url\",\n                            \"image_url\": {\"url\": f\"data:image/jpeg;base64,{image_base64}\"}\n                        }\n                    ]\n                }\n            ]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n```\n\n## Performance Optimization\n\nTips for getting the best performance from advanced models.\n\n### Model Selection Strategy\n\n```python\ndef select_optimal_model(task_type, quality_requirement, speed_requirement):\n    \"\"\"Select the best model based on requirements\"\"\"\n    \n    if quality_requirement == \"highest\":\n        if task_type == \"coding\":\n            return \"codellama:34b\"\n        elif task_type == \"reasoning\":\n            return \"llama3.1:70b\"\n        else:\n            return \"gpt4-turbo\"\n    \n    elif speed_requirement == \"fastest\":\n        if task_type == \"coding\":\n            return \"codellama:7b\"\n        else:\n            return \"llama3.1:8b\"\n    \n    else:  # Balanced\n        if task_type == \"coding\":\n            return \"codellama:13b\"\n        elif task_type == \"vision\":\n            return \"llama3.2-vision\"\n        else:\n            return \"llama3.1:8b\"\n\n# Usage\nmodel = select_optimal_model(\"reasoning\", \"highest\", \"medium\")\n```\n\n### Prompt Engineering for Advanced Models\n\n```python\ndef create_advanced_prompt(task, context=\"\", examples=\"\", constraints=\"\"):\n    \"\"\"Create optimized prompts for advanced models\"\"\"\n    \n    prompt_parts = []\n    \n    if context:\n        prompt_parts.append(f\"Context: {context}\")\n    \n    prompt_parts.append(f\"Task: {task}\")\n    \n    if examples:\n        prompt_parts.append(f\"Examples:\\n{examples}\")\n    \n    if constraints:\n        prompt_parts.append(f\"Constraints: {constraints}\")\n    \n    prompt_parts.append(\"Please provide a comprehensive response:\")\n    \n    return \"\\n\\n\".join(prompt_parts)\n\n# Usage\nprompt = create_advanced_prompt(\n    task=\"Analyze the financial implications of this merger\",\n    context=\"Two tech companies in the AI space\",\n    constraints=\"Focus on market impact and technical synergies\"\n)\n```\n\n## Batch Processing\n\nProcess multiple requests efficiently with advanced models.\n\n### Parallel Processing\n\n```python\nimport asyncio\nimport aiohttp\n\nasync def process_batch_advanced(prompts, model=\"llama3.1:8b\"):\n    \"\"\"Process multiple prompts in parallel\"\"\"\n    \n    async def single_request(session, prompt):\n        async with session.post(\n            \"https://api.cxmpute.cloud/v1/chat/completions\",\n            headers=headers,\n            json={\n                \"model\": model,\n                \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n            }\n        ) as response:\n            result = await response.json()\n            return result[\"choices\"][0][\"message\"][\"content\"]\n    \n    async with aiohttp.ClientSession() as session:\n        tasks = [single_request(session, prompt) for prompt in prompts]\n        results = await asyncio.gather(*tasks)\n    \n    return results\n\n# Usage\nprompts = [\n    \"Analyze the market trends in AI\",\n    \"Explain quantum computing\",\n    \"Write a Python function for data analysis\"\n]\n\n# results = asyncio.run(process_batch_advanced(prompts))\n```\n\n## Error Handling & Reliability\n\nRobust error handling for advanced model features.\n\n### Fallback Strategy\n\n```python\ndef robust_model_request(prompt, preferred_models, max_retries=3):\n    \"\"\"Try multiple models with fallback strategy\"\"\"\n    \n    for model in preferred_models:\n        for attempt in range(max_retries):\n            try:\n                response = requests.post(\n                    \"https://api.cxmpute.cloud/v1/chat/completions\",\n                    headers=headers,\n                    json={\n                        \"model\": model,\n                        \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n                        \"timeout\": 60\n                    }\n                )\n                \n                if response.status_code == 200:\n                    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n                elif response.status_code == 503:\n                    # Model unavailable, try next\n                    break\n                    \n            except Exception as e:\n                if attempt == max_retries - 1:\n                    continue  # Try next model\n                time.sleep(2 ** attempt)\n    \n    raise Exception(\"All models failed\")\n\n# Usage\nmodels = [\"llama3.1:70b\", \"llama3.1:8b\", \"mixtral:8x7b\"]\nresult = robust_model_request(\"Complex reasoning task\", models)\n```\n\n## Pricing for Advanced Models\n\nDuring **testnet**, all advanced features are **free**! Future pricing:\n\n- **Standard Models**: $0.10-0.20 per 1K tokens\n- **Large Models**: $0.40-0.80 per 1K tokens\n- **Vision Models**: $0.50-1.00 per image + text tokens\n- **Specialized Models**: $0.60-1.20 per 1K tokens\n\n## Support\n\n- **Discord**: [Community support](https://discord.com/invite/CJGA7B2zKT)\n- **Documentation**: [Complete API reference](/docs/user)\n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready for advanced AI?** Explore the cutting edge of language model capabilities with Cxmpute's advanced features! ",
  "embeddings": "# Text Embeddings\n\nGenerate high-quality vector embeddings for semantic search, RAG applications, and AI-powered features using Cxmpute's distributed embedding service.\n\n## Overview\n\nCxmpute's Text Embeddings service converts text into dense vector representations that capture semantic meaning. These embeddings are essential for building semantic search, recommendation systems, and retrieval-augmented generation (RAG) applications.\n\n### Key Features\n\n- **High-Quality Embeddings**: State-of-the-art embedding models\n- **Multiple Models**: Various embedding models optimized for different use cases\n- **Batch Processing**: Efficient processing of multiple texts\n- **Global Network**: Low-latency access worldwide\n- **OpenAI Compatible**: Familiar API structure\n\n## Quick Start\n\n### Basic Request\n\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/embeddings \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"nomic-embed-text\",\n    \"input\": \"Cxmpute provides distributed AI inference services.\"\n  }'\n```\n\n### Python Example\n\n```python\nimport requests\n\nurl = \"https://api.cxmpute.cloud/v1/embeddings\"\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"YOUR_USER_ID\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"model\": \"nomic-embed-text\",\n    \"input\": \"This is a sample text for embedding\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n\nembedding = result[\"data\"][0][\"embedding\"]\nprint(f\"Embedding dimension: {len(embedding)}\")\n```\n\n## API Reference\n\n### Endpoint\n\n```http\nPOST /v1/embeddings\n```\n\n### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `model` | string | Yes | Embedding model name |\n| `input` | string/array | Yes | Text(s) to embed |\n| `truncate` | boolean | No | Truncate input to model's max length |\n\n### Available Models\n\n| Model | Dimension | Description |\n|-------|-----------|-------------|\n| `nomic-embed-text` | 768 | General-purpose embeddings |\n| `all-minilm-l6-v2` | 384 | Fast, lightweight |\n| `bge-large-en-v1.5` | 1024 | High-quality English |\n\n### Response Format\n\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"object\": \"embedding\", \n      \"embedding\": [0.1, -0.2, 0.3, ...],\n      \"index\": 0\n    }\n  ],\n  \"model\": \"nomic-embed-text\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\n```\n\n## Use Cases\n\n### 1. Semantic Search\n\nBuild search systems that understand meaning, not just keywords.\n\n### 2. Recommendation Systems\n\nRecommend content based on semantic similarity.\n\n### 3. RAG Applications\n\nEnhance LLM responses with relevant context retrieval.\n\n### 4. Document Clustering\n\nGroup similar documents automatically.\n\n### 5. Text Classification\n\nClassify text using embedding-based similarity.\n\n## Pricing\n\nDuring our **testnet phase**, embedding services are completely **free**! \n\n## Support\n\n- **Discord**: [Community support](https://discord.com/invite/CJGA7B2zKT)\n- **Documentation**: [Complete API reference](/docs/user)\n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready to build semantic applications?** Start with our high-quality embeddings and create intelligent search, recommendation, and AI systems! ",
  "index": "# Cxmpute Documentation\n\nWelcome to the Cxmpute documentation! Cxmpute is a distributed AI/Compute services platform that connects users who need AI services with providers who offer compute resources, creating a global network of AI compute power.\n\n## Quick Start\n\n### For Users\n- **Get Started**: [Create an account](https://cxmpute.cloud/dashboard) and start using AI services in minutes\n- **API Reference**: [Complete API documentation](/docs/user) for all endpoints\n- **Service Guides**: Learn about specific services like [chat](/docs/text-to-text), [embeddings](/docs/embeddings), [TTS](/docs/text-to-speech), and [scraping](/docs/scraping)\n\n### For Providers\n- **Become a Provider**: [Download the CLI](https://github.com/unxversal/cxmpute-core/releases) and start earning rewards\n- **Provider Guide**: [Complete setup instructions](/docs/provider) and earning tips\n- **Rewards System**: Learn about [earnings and referrals](/docs/rewards)\n\n## What is Cxmpute?\n\nCxmpute provides inference and related services powered by a global network of nodes run by providers. We offer:\n\n- **LLM Inference**: OpenAI-compatible chat completions with dozens of models\n- **Text Embeddings**: High-quality vector embeddings for your applications\n- **Text-to-Speech**: Natural voice synthesis with multiple voice models\n- **Web Scraping**: Reliable content extraction and markdown conversion\n- **Tool Use & JSON**: Structured outputs and function calling capabilities\n\n[Learn more about Cxmpute ‚Üí](/docs/about)\n\n## Service Documentation\n\n### AI Services\n- [**Text-to-Text (LLM)**](/docs/text-to-text) - Chat completions and text generation\n- [**Embeddings**](/docs/embeddings) - Vector embeddings for semantic search\n- [**Text-to-Speech**](/docs/text-to-speech) - Audio generation from text\n- [**Web Scraping**](/docs/scraping) - Content extraction and processing\n- [**Tool Use & JSON**](/docs/tool-use-json) - Structured outputs and function calling\n- [**Advanced LLMs**](/docs/advanced-llms) - Advanced features for large language models\n\n### Platform\n- [**User Guide**](/docs/user) - Complete API reference and getting started\n- [**Provider Guide**](/docs/provider) - How to become a compute provider\n- [**Rewards System**](/docs/rewards) - Earning rewards and referral program\n- [**About Cxmpute**](/docs/about) - Platform overview and architecture\n\n## Key Features\n\n### üöÄ **Easy to Use**\n- OpenAI-compatible APIs - just change the base URL\n- Simple authentication with API keys\n- Comprehensive documentation and examples\n\n### üåç **Global Network**\n- Distributed provider network for low latency\n- Automatic load balancing and health monitoring\n- Geographic distribution for optimal performance\n\n### üí∞ **Cost-Effective**\n- Competitive pricing through decentralized providers\n- Currently free during testnet phase\n- Transparent pricing with no hidden fees\n\n### üîí **Secure & Reliable**\n- Enterprise-grade security and privacy\n- 99.5%+ uptime with automatic failover\n- Provider verification and health monitoring\n\n## Getting Started\n\n### 1. Create an Account\nVisit the [Cxmpute Dashboard](https://cxmpute.cloud/dashboard) to create your account and get your API key.\n\n### 2. Make Your First Request\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/chat/completions \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [{\"role\": \"user\", \"content\": \"Hello, world!\"}]\n  }'\n```\n\n### 3. Explore Services\nTry different AI services:\n- [Chat completions](/docs/text-to-text) for conversations and text generation\n- [Embeddings](/docs/embeddings) for semantic search and RAG\n- [Text-to-speech](/docs/text-to-speech) for voice applications\n- [Web scraping](/docs/scraping) for data collection\n\n## Testnet Phase\n\nüéâ **All services are currently free!** During our testnet phase, you can use all Cxmpute services without charges. You also earn rewards based on usage and referrals.\n\n[Learn more about rewards ‚Üí](/docs/rewards)\n\n## Community & Support\n\n- **Discord**: Join our [community](https://discord.com/invite/CJGA7B2zKT) for support and latest news\n- **GitHub**: Check out our [open source code](https://github.com/unxversal/cxmpute-core)\n- **Email**: Contact us at support@cxmpute.cloud\n\n## Model Catalog\n\nExplore our full range of available models at [cxmpute.cloud/models](https://cxmpute.cloud/models).\n\n---\n\n*Ready to get started? [Create your account](https://cxmpute.cloud/dashboard) or [become a provider](https://github.com/unxversal/cxmpute-core/releases) today!* ",
  "provider": "# Provider Guide\n\nTransform your computer into an AI compute provider and start earning rewards! This guide will walk you through becoming part of the Cxmpute network.\n\n## What is a Cxmpute Provider?\n\nCxmpute provides inference and related services powered by a global network of nodes run by providers. [Learn more about using Cxmpute services ‚Üí](/docs/user)\n\nA **provider** is someone who runs a Cxmpute node on their computer. This node is essentially an inference server connected to our main orchestrator, so requests are routed to your node for inference and completion, and you are rewarded proportionally.\n\n## Hardware Tiers\n\nWe categorize devices into different tiers based on their capabilities. **We need devices of all tiers**, but we highly recommend becoming a provider if you have at least **16GB RAM and 30GB free disc space**.\n\n### Device Tiers\n\n| Tier | Name | VRAM | Capabilities | Example Earnings |\n|------|------|------|--------------|------------------|\n| **Tier 0** | Basic | <1GB | Lightweight tasks, TTS | $5-15/month |\n| **Tier 1** | Tide Pool | 1-4GB | Small embeddings, basic TTS | $15-40/month |\n| **Tier 2** | Blue Surf | 4-8GB | Small LLMs, all services | $40-100/month |\n| **Tier 3** | Open Ocean | 8-22GB | Medium LLMs, high throughput | $100-300/month |\n| **Tier 4** | Mariana Depth | 22GB+ | Large LLMs, premium rates | $300-800/month |\n\n*Earnings are estimates based on 24/7 operation and network demand. Actual earnings may vary.*\n\n### System Requirements\n\n#### Minimum Requirements\n- **OS**: macOS 10.15+, Linux (Ubuntu 18.04+), Windows 10+\n- **RAM**: 4GB+ (8GB+ recommended for LLM services)\n- **Storage**: 10GB+ free space\n- **Internet**: Stable broadband connection\n\n#### Optimal Requirements\n- **GPU**: NVIDIA GPU with 8GB+ VRAM (for LLM hosting)\n- **RAM**: 16GB+ (32GB+ for large models)\n- **CPU**: Multi-core processor (Intel i5/AMD Ryzen 5+)\n- **Internet**: High-speed connection (100+ Mbps)\n\n## Getting Started\n\n### Step 1: Create an Account\n\nCreate an account in the [Cxmpute Dashboard](https://cxmpute.cloud/dashboard).\n\n### Step 2: Download the Provider CLI\n\nDownload the Cxmpute Provider CLI from our releases:\nüëâ **[Download Latest Release](https://github.com/unxversal/cxmpute-core/releases)**\n\n#### Choose Your Platform\n\n**üçé macOS**\n- Intel Macs (x64): `cxmpute-provider-macos` or `cxmpute-provider-macos-intel`\n- Apple Silicon (M1/M2/M3/M4): `cxmpute-provider-macos-arm64` or `cxmpute-provider-macos-m1`\n\n**üêß Linux**\n- x64: `cxmpute-provider-linux`\n\n**ü™ü Windows**\n- x64: `cxmpute-provider.exe` or `cxmpute-provider-windows.exe`\n\n### Step 3: Install and Setup\n\n#### Make Executable (macOS/Linux)\n\n```bash\n# Navigate to your Downloads folder\ncd ~/Downloads\n\n# Make the file executable\nchmod +x cxmpute-provider-macos    # or cxmpute-provider-linux\n```\n\n#### Run the Provider\n\n**üçé macOS**\n```bash\n# Run directly\n./cxmpute-provider-macos\n\n# First time? macOS might show security warning:\n# Go to System Preferences > Security & Privacy > General\n# Click \"Allow Anyway\" for cxmpute-provider-macos\n```\n\n**üêß Linux**\n```bash\n# Run directly\n./cxmpute-provider-linux\n```\n\n**ü™ü Windows**\n```bash\n# Run directly (double-click or command line)\ncxmpute-provider.exe\n\n# First time? Windows might show SmartScreen warning:\n# Click \"More info\" > \"Run anyway\"\n```\n\n### Step 4: Follow the Setup Wizard\n\nWhen you run `cxmpute-provider` for the first time, you'll see:\n\n```\n ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïó  ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïó   ‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ñà‚ñà‚ïó ‚ñà‚ñà‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë‚ïö‚ïê‚ïê‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïê‚ïù\n‚ñà‚ñà‚ïë      ‚ïö‚ñà‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïî‚ñà‚ñà‚ñà‚ñà‚ïî‚ñà‚ñà‚ïë‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó  \n‚ñà‚ñà‚ïë      ‚ñà‚ñà‚ïî‚ñà‚ñà‚ïó ‚ñà‚ñà‚ïë‚ïö‚ñà‚ñà‚ïî‚ïù‚ñà‚ñà‚ïë‚ñà‚ñà‚ïî‚ïê‚ïê‚ïê‚ïù ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ïî‚ïê‚ïê‚ïù  \n‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó‚ñà‚ñà‚ïî‚ïù ‚ñà‚ñà‚ïó‚ñà‚ñà‚ïë ‚ïö‚ïê‚ïù ‚ñà‚ñà‚ïë‚ñà‚ñà‚ïë     ‚ïö‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïî‚ïù   ‚ñà‚ñà‚ïë   ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ïó\n ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù‚ïö‚ïê‚ïù  ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù     ‚ïö‚ïê‚ïù‚ïö‚ïê‚ïù      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù    ‚ïö‚ïê‚ïù   ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n\nüîß SETUP WIZARD\n```\n\nThe CLI will guide you through:\n\n1. **Hardware Detection**: Automatic system profiling\n2. **Provider Registration**: Creating your provider account\n3. **Service Configuration**: Selecting services based on your hardware\n4. **Network Setup**: Configuring tunnels and connectivity\n\n### Step 5: Start Earning!\n\nAfter setup, you'll see your **provider dashboard**:\n\n```\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ PROVIDER/REFERRAL ID: abc123...                        ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ ‚óè STATUS: ACTIVE                                       ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ ‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ TODAY'S EARNINGS: $12.45 ‚îÇ ‚îÇ ALL TIME EARNINGS: $342.10‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ ‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ REFERRALS: 3                    LEARN MORE             ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n\n‚ï≠‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïÆ\n‚îÇ DEVICE TIER: Deep Ocean (Tier 4 - 22GB+ VRAM)         ‚îÇ\n‚ï∞‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ïØ\n```\n\n**üéâ Congratulations!** Your node is running and earning rewards.\n\n## Maximizing Your Earnings\n\n### üí∞ Earning Rewards\n\n#### Service Types & Earnings\n\n- **ü§ñ LLM Inference**: $0.10-0.50 per 1K tokens (varies by model)\n- **üîç Embeddings**: $0.01-0.05 per 1K tokens\n- **üåê Web Scraping**: $0.02-0.10 per request\n- **üó£Ô∏è Text-to-Speech**: $0.05-0.15 per request\n\n#### Best Practices\n\n1. **‚è∞ Uptime**: Keep your provider running 24/7 for maximum earnings\n2. **üöÄ Performance**: Ensure stable internet and optimal hardware\n3. **üë• Referrals**: Invite others and earn from their activity ([learn more](/docs/rewards))\n4. **üîÑ Updates**: Keep your CLI updated for new features\n5. **üîß Optimization**: Run when you're not using your computer to maximize resources\n\n### When to Run Your Node\n\n**üí° Recommended**: Run your node when you're not using your computer, as it tries to use most of your computing power to maximize earnings.\n\n- **üåô Overnight**: Perfect time for maximum resource allocation\n- **üìÖ Weekends**: Extended periods of high earning potential\n- **üéØ Scheduled**: Set up automated schedules for consistent operation\n\n## How Providers Earn\n\n### Points System\n\nProviders earn **points** based on:\n- **Usage**: Requests processed and tokens generated\n- **Quality**: Response time and reliability\n- **Referrals**: People you invite who become active users or providers\n\n### Revenue Distribution\n\nAt the end of each **epoch** (usually a month), revenue is distributed proportionally based on points accumulated:\n\n1. Platform collects revenue from users\n2. Points are tallied for all providers\n3. Revenue is distributed based on each provider's share of total points\n4. Payments are processed automatically\n\n### Earning More Points\n\n- **üìà High Uptime**: Consistent availability increases point multiplier\n- **‚ö° Fast Response**: Better performance = more requests routed to you\n- **üéØ Referrals**: Earn bonus points from referred users' activity\n- **üîß Better Hardware**: Higher tiers get priority for premium requests\n\n## Service Types\n\nYour node will automatically provide services based on your hardware capabilities:\n\n### ü§ñ LLM Inference (`/chat/completions`)\n- **Requirements**: 4GB+ VRAM recommended\n- **Models**: Various sizes from 7B to 70B+ parameters\n- **Earnings**: Highest earning potential\n\n### üîç Embeddings (`/embeddings`)\n- **Requirements**: 2GB+ VRAM\n- **Models**: Specialized embedding models\n- **Earnings**: Consistent, moderate volume\n\n### üó£Ô∏è Text-to-Speech (`/tts`)\n- **Requirements**: 1GB+ VRAM or good CPU\n- **Models**: Voice synthesis models\n- **Earnings**: Steady demand\n\n### üåê Web Scraping (`/scrape`)\n- **Requirements**: Good internet connection\n- **Function**: Content extraction and processing\n- **Earnings**: Per-request based\n\n## Troubleshooting\n\n### Common Issues\n\n#### \"Command not found: cxmpute-provider\"\n- **Cause**: Binary not in PATH or not executable\n- **Fix**: Follow the installation steps above, ensure file is executable\n\n#### \"Permission denied\"\n- **macOS/Linux**: Run `chmod +x cxmpute-provider-*`\n- **Windows**: Run as Administrator\n\n#### \"Node start failed: ECONNREFUSED\"\n- **Cause**: Network connectivity issue\n- **Fix**: Check internet connection, restart the CLI\n\n#### macOS Security Warning\n1. Go to **System Preferences** > **Security & Privacy** > **General**\n2. Click **\"Allow Anyway\"** for cxmpute-provider\n3. Re-run the application\n\n#### Windows SmartScreen Warning\n1. Click **\"More info\"**\n2. Click **\"Run anyway\"**\n3. The application will start normally\n\n#### Low Earnings\n- Check your device tier - upgrade hardware for better rates\n- Ensure stable internet connection (100+ Mbps recommended)\n- Maximize uptime - run 24/7 for consistent earnings\n- Check for software conflicts (antivirus, firewall)\n\n### Log Files\n\nProvider logs are stored in:\n- **macOS**: `~/Library/Logs/cxmpute-provider/`\n- **Linux**: `~/.local/share/cxmpute-provider/logs/`\n- **Windows**: `%APPDATA%\\cxmpute-provider\\logs\\`\n\n### Status Indicators\n\n- **Green ‚óè**: Provider active and earning\n- **Yellow ‚óè**: Provider starting up\n- **Red ‚óè**: Provider error or offline\n\n## Security & Privacy\n\n### What Data is Collected\n- **Hardware specs**: For service assignment\n- **Usage metrics**: For earnings calculation\n- **Error logs**: For debugging and support\n\n### What's NOT Collected\n- **Personal files**: No access to your documents\n- **Browsing history**: No tracking of web activity\n- **Sensitive data**: No personal information stored\n\n### Data Protection\n- All communications are encrypted\n- Provider credentials are embedded securely\n- No sensitive data is transmitted\n\n## Install Globally (Optional)\n\nMake `cxmpute-provider` available from anywhere on your system:\n\n**üçé macOS**\n```bash\n# Install globally\nsudo mv ~/Downloads/cxmpute-provider-macos /usr/local/bin/cxmpute-provider\n\n# Now run from anywhere\ncxmpute-provider\n```\n\n**üêß Linux**\n```bash\n# Install globally\nsudo mv ~/Downloads/cxmpute-provider-linux /usr/local/bin/cxmpute-provider\n\n# Now run from anywhere\ncxmpute-provider\n```\n\n**ü™ü Windows**\n\n*Option 1: System32 (requires admin)*\n```cmd\n# Open Command Prompt as Administrator\nmove \"%USERPROFILE%\\Downloads\\cxmpute-provider.exe\" \"C:\\Windows\\System32\\cxmpute-provider.exe\"\n\n# Now run from anywhere\ncxmpute-provider\n```\n\n*Option 2: Add to PATH*\n1. Create folder: `C:\\cxmpute\\`\n2. Move `cxmpute-provider.exe` to `C:\\cxmpute\\`\n3. Add `C:\\cxmpute\\` to your PATH environment variable\n4. Restart Command Prompt/PowerShell\n5. Run: `cxmpute-provider`\n\n## Commands & Controls\n\n### Basic Commands\n```bash\n# Start the provider\ncxmpute-provider\n\n# Stop the provider\n# Press Ctrl+C in the terminal\n```\n\n### Advanced Usage\n- The CLI handles all complex operations automatically\n- No manual configuration required\n- Updates are handled through new releases\n\n## Support\n\n### Getting Help\n- **Discord**: Join our [community](https://discord.com/invite/CJGA7B2zKT) for real-time support\n- **GitHub**: Report issues on our [repository](https://github.com/unxversal/cxmpute-core)\n- **Email**: Contact support@cxmpute.cloud\n\n### Community\nJoin our Discord for:\n- Latest news and updates\n- Provider tips and tricks\n- Community support\n- Feature announcements\n\n## Next Steps\n\n1. **üìä Monitor Earnings**: Keep track of your progress in the dashboard\n2. **üë• Invite Friends**: Use the [referral system](/docs/rewards) to boost earnings\n3. **‚¨ÜÔ∏è Upgrade Hardware**: Consider hardware improvements for higher tiers\n4. **üåç Join Community**: Connect with other providers on Discord\n\n---\n\n**Ready to start earning?** [Download the CLI](https://github.com/unxversal/cxmpute-core/releases) and join thousands of providers powering the Cxmpute network! ",
  "rewards": "# Rewards & Referrals\n\nBoost your earnings and help grow the Cxmpute network through our referral system! Whether you're a user or provider, you can earn more points by inviting others to join.\n\n## How Rewards Work\n\n### Points-Based Economy\n\nCxmpute operates on a **points-based reward system** where:\n\n- **Users** earn points for API usage and activity\n- **Providers** earn points for serving requests and maintaining uptime\n- **Everyone** earns additional points through successful referrals\n\nAt the end of each **epoch** (usually monthly), points are converted to actual rewards based on platform revenue.\n\n### Testnet Phase Benefits\n\nüéâ **During our testnet phase:**\n- All services are completely **free**\n- You still earn points for future rewards\n- Referral bonuses are active and accumulating\n- Early participants get bonus multipliers\n\n## Referral System\n\n### How Referrals Work\n\nYou earn more points when you:\n1. **Refer new users** who start using Cxmpute services\n2. **Refer new providers** who join the network\n3. **Earn ongoing bonuses** from their continued activity\n\n### Your Referral Benefits\n\nWhen someone uses your referral:\n- You get **bonus points** for the successful referral\n- You earn a **percentage of their points** as they use the platform\n- They get **starter bonuses** to help them get going\n\n## For Users: Earning Through Referrals\n\n### Share Your Referral Link\n\n1. Go to your [Dashboard](https://cxmpute.cloud/dashboard)\n2. Find your unique referral link\n3. Share it with friends, colleagues, or your community\n\n### User Referral Rewards\n\n| Action | Your Reward | Their Bonus |\n|--------|------------|-------------|\n| Friend signs up | 100 points | 50 points |\n| Friend makes first API call | 200 points | 100 points |\n| Friend's monthly activity | 5% of their points | - |\n| Friend becomes active user | 500 bonus points | 200 bonus points |\n\n### Best Referral Strategies\n\n- **Developers**: Share in coding communities, GitHub, Stack Overflow\n- **AI Enthusiasts**: Post in AI/ML forums and Discord servers\n- **Content Creators**: Include in tutorials about AI APIs\n- **Businesses**: Recommend to teams needing AI services\n\n## For Providers: Maximizing Provider Earnings\n\n### Provider Referral Rewards\n\n| Action | Your Reward | Their Bonus |\n|--------|------------|-------------|\n| Refer new provider | 500 points | 250 points |\n| They complete setup | 1000 points | 500 points |\n| Their monthly earnings | 10% of their points | - |\n| They reach Tier 2+ | 2000 bonus points | 1000 bonus points |\n\n### Provider Referral Benefits\n\n**Higher Multipliers**: Provider referrals typically earn more because:\n- Providers contribute valuable compute resources\n- They tend to be long-term participants\n- They often refer other high-value participants\n\n### Building Your Provider Network\n\n1. **Tech Communities**: Share in hardware/mining forums\n2. **Gaming Communities**: Gamers often have powerful GPUs\n3. **Universities**: Students and researchers with access to hardware\n4. **Data Centers**: Professionals with enterprise hardware\n\n## Referral Tracking\n\n### Your Referral Dashboard\n\nTrack your referral success:\n- **Active Referrals**: People currently using your link\n- **Total Points Earned**: From all referral activity\n- **Monthly Breakdown**: See trends in your referral earnings\n- **Conversion Rates**: How many clicks become active users\n\n### Real-Time Updates\n\n- Points are credited in real-time\n- See immediate updates when referrals are active\n- Monthly summaries show accumulated rewards\n\n## Point Values & Conversion\n\n### Current Point Values (Testnet)\n\nDuring testnet, points accumulate for future conversion:\n- **1 Point = ~$0.001** (estimated, subject to change)\n- **Minimum Payout**: 10,000 points ($10)\n- **Payment Methods**: Crypto, PayPal, bank transfer\n\n### Point Categories\n\n| Activity Type | Point Value | Referral Bonus |\n|---------------|-------------|----------------|\n| API Usage | 1-10 points/request | 5% to referrer |\n| Provider Uptime | 10-100 points/hour | 10% to referrer |\n| Quality Metrics | Multiplier bonus | Shared bonus |\n| Community Activity | 50-500 points | Direct bonus |\n\n## Maximizing Your Rewards\n\n### Multi-Level Benefits\n\nYour referral network can include:\n- **Direct Referrals**: People you invited\n- **Their Networks**: Additional bonuses when your referrals refer others\n- **Community Building**: Extra rewards for active referral networks\n\n### Special Bonuses\n\n**üéØ Community Builder Rewards**\n- Refer 10+ active users: 50% bonus multiplier\n- Refer 5+ providers: 100% bonus multiplier\n- Build active community: Custom reward packages\n\n**üöÄ Early Adopter Benefits**\n- Testnet participants get permanent 25% bonus\n- First 1000 providers get lifetime 50% bonus\n- Beta testers receive special recognition rewards\n\n## Referral Best Practices\n\n### For Users\n\n1. **Educational Content**: Create tutorials showing Cxmpute APIs\n2. **Social Media**: Share your experience with specific examples\n3. **Technical Communities**: Help others solve problems with Cxmpute\n4. **Comparison Content**: Show how Cxmpute compares to alternatives\n\n### For Providers\n\n1. **Hardware Communities**: Share earnings and setup experiences\n2. **Passive Income Content**: Demonstrate real earnings potential\n3. **Technical Guides**: Help others optimize their setups\n4. **Success Stories**: Share your provider journey\n\n### Content Ideas\n\n**üìù Blog Posts**\n- \"How I earn $X/month with my gaming PC\"\n- \"OpenAI vs Cxmpute: Cost comparison\"\n- \"Setting up passive income with AI compute\"\n\n**üé• Videos**\n- Provider setup tutorials\n- Earnings demonstrations\n- Hardware optimization guides\n\n**üí¨ Community Posts**\n- Share real usage examples\n- Help troubleshoot issues\n- Celebrate milestones\n\n## Referral Terms\n\n### Fair Usage\n\n- Referrals must be genuine new users\n- Self-referrals are not allowed\n- Gaming the system results in point forfeiture\n- Quality referrals are rewarded more than quantity\n\n### Attribution\n\n- 30-day attribution window for new signups\n- Last-click attribution for referral credit\n- Clear tracking through unique referral codes\n- Transparent reporting in your dashboard\n\n## Getting Started with Referrals\n\n### Step 1: Get Your Link\n\nVisit your dashboard and copy your unique referral link:\n- **Users**: `https://cxmpute.cloud/signup?ref=YOUR_USER_ID`\n- **Providers**: `https://cxmpute.cloud/provider?ref=YOUR_PROVIDER_ID`\n\n### Step 2: Share Strategically\n\nFocus on quality over quantity:\n- Target people who would genuinely benefit\n- Provide context about why Cxmpute is valuable\n- Follow up to help with onboarding\n\n### Step 3: Support Your Referrals\n\nHelp them succeed:\n- Answer questions about setup\n- Share best practices and tips\n- Celebrate their achievements\n\n### Step 4: Track and Optimize\n\nMonitor your referral performance:\n- See which channels work best\n- Optimize your messaging\n- Focus on high-converting audiences\n\n## Payment & Rewards\n\n### Payout Schedule\n\n- **Testnet**: Points accumulate for future conversion\n- **Mainnet**: Monthly payouts for 10,000+ points\n- **Instant**: Small rewards for immediate motivation\n\n### Payment Methods\n\nAvailable options:\n- **Cryptocurrency**: USDC, ETH, BTC\n- **Traditional**: PayPal, bank transfer\n- **Platform Credits**: Use for API services\n\n### Tax Considerations\n\n- Rewards may be taxable income\n- Keep records of your referral earnings\n- Consult tax professionals for guidance\n\n## Community Rewards\n\n### Special Events\n\nRegular bonus opportunities:\n- **Double Points Weekends**\n- **Referral Competitions**\n- **Community Challenges**\n- **Holiday Bonuses**\n\n### Recognition Program\n\nTop referrers get:\n- **Discord Badges** and special roles\n- **Public Recognition** in community updates\n- **Early Access** to new features\n- **Direct Communication** with the team\n\n## Support & FAQs\n\n### Common Questions\n\n**Q: When do I get referral points?**\nA: Points are credited immediately when actions are completed.\n\n**Q: Is there a limit to referrals?**\nA: No limit! The more quality referrals, the better.\n\n**Q: Can I refer businesses?**\nA: Yes! Business referrals often have the highest value.\n\n**Q: What if my referral stops using Cxmpute?**\nA: You keep already-earned points, but ongoing bonuses stop.\n\n### Need Help?\n\n- **Discord**: Get help from the community\n- **Email**: referrals@cxmpute.cloud\n- **Dashboard**: Check your referral stats and earnings\n\n---\n\n**Ready to start earning more?** Share your referral link and watch your rewards grow as you help build the future of decentralized AI compute!\n\n[Get Your Referral Link ‚Üí](https://cxmpute.cloud/dashboard) ",
  "scraping": "# Web Scraping\n\nExtract content from web pages intelligently using Cxmpute's distributed web scraping service.\n\n## Overview\n\nCxmpute's Web Scraping service provides reliable content extraction from web pages with intelligent parsing, markdown conversion, and metadata extraction. Our global network of providers ensures consistent availability and bypasses common blocking mechanisms.\n\n### Key Features\n\n- **Intelligent Extraction**: Smart content parsing and cleaning\n- **Multiple Formats**: HTML, text, and markdown output\n- **Metadata Extraction**: Titles, descriptions, and structured data\n- **Batch Processing**: Handle multiple URLs efficiently\n- **Global Network**: Distributed scraping nodes worldwide\n\n## Quick Start\n\n### Basic Request\n\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/scrape \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"urls\": [\"https://example.com\"],\n    \"format\": \"markdown\"\n  }'\n```\n\n### Python Example\n\n```python\nimport requests\n\nurl = \"https://api.cxmpute.cloud/v1/scrape\"\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"YOUR_USER_ID\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"urls\": [\"https://docs.cxmpute.cloud\"],\n    \"format\": \"markdown\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n\nfor item in result[\"results\"]:\n    if item[\"success\"]:\n        print(f\"Title: {item['metadata']['title']}\")\n        print(f\"Content: {item['content'][:200]}...\")\n    else:\n        print(f\"Failed to scrape {item['url']}\")\n```\n\n## API Reference\n\n### Endpoint\n\n```http\nPOST /v1/scrape\n```\n\n### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `urls` | array | Yes | Array of URLs to scrape |\n| `format` | string | No | Output format: \"markdown\", \"text\", \"html\" (default: \"markdown\") |\n\n### Response Format\n\n```json\n{\n  \"results\": [\n    {\n      \"url\": \"https://example.com\",\n      \"content\": \"# Example Page\\n\\nThis is the content...\",\n      \"success\": true,\n      \"metadata\": {\n        \"title\": \"Example Page\",\n        \"description\": \"An example webpage\",\n        \"author\": \"John Doe\",\n        \"publish_date\": \"2024-01-15\"\n      }\n    }\n  ]\n}\n```\n\n## Use Cases\n\n### 1. Content Aggregation\n\nCollect articles and blog posts for analysis:\n\n```python\ndef scrape_news_articles(urls):\n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/scrape\",\n        headers=headers,\n        json={\"urls\": urls, \"format\": \"markdown\"}\n    )\n    \n    articles = []\n    for result in response.json()[\"results\"]:\n        if result[\"success\"]:\n            articles.append({\n                \"url\": result[\"url\"],\n                \"title\": result[\"metadata\"].get(\"title\", \"Unknown\"),\n                \"content\": result[\"content\"],\n                \"publish_date\": result[\"metadata\"].get(\"publish_date\")\n            })\n    \n    return articles\n\n# Usage\nnews_urls = [\n    \"https://techcrunch.com/article1\",\n    \"https://arstechnica.com/article2\"\n]\narticles = scrape_news_articles(news_urls)\n```\n\n### 2. Research Data Collection\n\nGather information for research projects:\n\n```python\ndef research_scraper(search_urls, keywords):\n    scraped_data = []\n    \n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/scrape\",\n        headers=headers,\n        json={\"urls\": search_urls, \"format\": \"text\"}\n    )\n    \n    for result in response.json()[\"results\"]:\n        if result[\"success\"]:\n            content = result[\"content\"].lower()\n            keyword_matches = sum(content.count(kw.lower()) for kw in keywords)\n            \n            if keyword_matches > 0:\n                scraped_data.append({\n                    \"url\": result[\"url\"],\n                    \"relevance_score\": keyword_matches,\n                    \"content\": result[\"content\"],\n                    \"metadata\": result[\"metadata\"]\n                })\n    \n    return sorted(scraped_data, key=lambda x: x[\"relevance_score\"], reverse=True)\n```\n\n### 3. E-commerce Product Monitoring\n\nTrack product information and pricing:\n\n```python\ndef monitor_product_pages(product_urls):\n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/scrape\",\n        headers=headers,\n        json={\"urls\": product_urls, \"format\": \"html\"}\n    )\n    \n    products = []\n    for result in response.json()[\"results\"]:\n        if result[\"success\"]:\n            # Extract price and availability (simplified example)\n            content = result[\"content\"]\n            # Use regex or HTML parsing to extract specific data\n            products.append({\n                \"url\": result[\"url\"],\n                \"title\": result[\"metadata\"].get(\"title\"),\n                \"raw_content\": content,\n                \"scraped_at\": datetime.now().isoformat()\n            })\n    \n    return products\n```\n\n### 4. Documentation Aggregation\n\nCollect API documentation and guides:\n\n```python\ndef scrape_documentation(doc_urls):\n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/scrape\",\n        headers=headers,\n        json={\"urls\": doc_urls, \"format\": \"markdown\"}\n    )\n    \n    docs = []\n    for result in response.json()[\"results\"]:\n        if result[\"success\"]:\n            docs.append({\n                \"url\": result[\"url\"],\n                \"title\": result[\"metadata\"].get(\"title\"),\n                \"content\": result[\"content\"],\n                \"sections\": extract_sections(result[\"content\"])\n            })\n    \n    return docs\n\ndef extract_sections(markdown_content):\n    \"\"\"Extract sections from markdown content\"\"\"\n    sections = []\n    current_section = None\n    \n    for line in markdown_content.split('\\n'):\n        if line.startswith('#'):\n            if current_section:\n                sections.append(current_section)\n            current_section = {\n                \"title\": line.strip('#').strip(),\n                \"content\": \"\"\n            }\n        elif current_section:\n            current_section[\"content\"] += line + \"\\n\"\n    \n    if current_section:\n        sections.append(current_section)\n    \n    return sections\n```\n\n## Advanced Features\n\n### Batch Processing with Error Handling\n\n```python\nimport time\nfrom concurrent.futures import ThreadPoolExecutor\n\ndef scrape_urls_batch(urls, batch_size=10, max_retries=3):\n    \"\"\"Scrape URLs in batches with retry logic\"\"\"\n    \n    def scrape_batch(url_batch):\n        for attempt in range(max_retries):\n            try:\n                response = requests.post(\n                    \"https://api.cxmpute.cloud/v1/scrape\",\n                    headers=headers,\n                    json={\"urls\": url_batch, \"format\": \"markdown\"},\n                    timeout=60\n                )\n                \n                if response.status_code == 200:\n                    return response.json()[\"results\"]\n                elif response.status_code == 503:\n                    time.sleep(2 ** attempt)\n                    continue\n                else:\n                    response.raise_for_status()\n                    \n            except requests.exceptions.RequestException as e:\n                if attempt == max_retries - 1:\n                    # Return failed results for this batch\n                    return [{\"url\": url, \"success\": False, \"error\": str(e)} for url in url_batch]\n                time.sleep(1)\n    \n    # Split URLs into batches\n    batches = [urls[i:i + batch_size] for i in range(0, len(urls), batch_size)]\n    all_results = []\n    \n    for batch in batches:\n        results = scrape_batch(batch)\n        all_results.extend(results)\n        print(f\"Processed batch of {len(batch)} URLs\")\n    \n    return all_results\n```\n\n### Content Filtering and Extraction\n\n```python\ndef extract_article_content(scraped_results):\n    \"\"\"Extract main article content from scraped pages\"\"\"\n    \n    articles = []\n    for result in scraped_results:\n        if not result[\"success\"]:\n            continue\n            \n        content = result[\"content\"]\n        metadata = result[\"metadata\"]\n        \n        # Basic content filtering\n        if len(content) < 100:  # Skip very short content\n            continue\n            \n        # Extract meaningful content\n        article = {\n            \"url\": result[\"url\"],\n            \"title\": metadata.get(\"title\", \"\"),\n            \"author\": metadata.get(\"author\", \"\"),\n            \"publish_date\": metadata.get(\"publish_date\", \"\"),\n            \"content\": content,\n            \"word_count\": len(content.split()),\n            \"reading_time\": len(content.split()) // 200  # Approximate reading time\n        }\n        \n        articles.append(article)\n    \n    return articles\n```\n\n### Integration with AI Services\n\nCombine scraping with AI analysis:\n\n```python\ndef scrape_and_analyze(urls, analysis_type=\"summary\"):\n    \"\"\"Scrape content and analyze it with AI\"\"\"\n    \n    # Scrape content\n    scrape_response = requests.post(\n        \"https://api.cxmpute.cloud/v1/scrape\",\n        headers=headers,\n        json={\"urls\": urls, \"format\": \"text\"}\n    )\n    \n    results = []\n    for result in scrape_response.json()[\"results\"]:\n        if not result[\"success\"]:\n            continue\n            \n        content = result[\"content\"]\n        \n        # Analyze with AI\n        if analysis_type == \"summary\":\n            prompt = f\"Summarize this article in 2-3 sentences:\\n\\n{content[:2000]}\"\n        elif analysis_type == \"sentiment\":\n            prompt = f\"Analyze the sentiment of this text:\\n\\n{content[:2000]}\"\n        elif analysis_type == \"keywords\":\n            prompt = f\"Extract the main keywords and topics from this text:\\n\\n{content[:2000]}\"\n        \n        ai_response = requests.post(\n            \"https://api.cxmpute.cloud/v1/chat/completions\",\n            headers=headers,\n            json={\n                \"model\": \"llama3.1:8b\",\n                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n                \"temperature\": 0.3\n            }\n        )\n        \n        if ai_response.status_code == 200:\n            analysis = ai_response.json()[\"choices\"][0][\"message\"][\"content\"]\n        else:\n            analysis = \"Analysis failed\"\n        \n        results.append({\n            \"url\": result[\"url\"],\n            \"title\": result[\"metadata\"].get(\"title\", \"\"),\n            \"content\": content,\n            \"analysis\": analysis,\n            \"analysis_type\": analysis_type\n        })\n    \n    return results\n\n# Usage\nurls = [\"https://techcrunch.com/some-article\"]\nanalyzed_content = scrape_and_analyze(urls, \"summary\")\n```\n\n## Best Practices\n\n### 1. Rate Limiting and Politeness\n\n```python\nimport time\nimport random\n\ndef polite_scraper(urls, delay_range=(1, 3)):\n    \"\"\"Scrape URLs with respectful delays\"\"\"\n    \n    results = []\n    for i, url in enumerate(urls):\n        # Add delay between requests\n        if i > 0:\n            delay = random.uniform(*delay_range)\n            time.sleep(delay)\n        \n        response = requests.post(\n            \"https://api.cxmpute.cloud/v1/scrape\",\n            headers=headers,\n            json={\"urls\": [url], \"format\": \"markdown\"}\n        )\n        \n        if response.status_code == 200:\n            results.extend(response.json()[\"results\"])\n        \n        print(f\"Scraped {i+1}/{len(urls)} URLs\")\n    \n    return results\n```\n\n### 2. Content Validation\n\n```python\ndef validate_scraped_content(results, min_length=100):\n    \"\"\"Validate and filter scraped content\"\"\"\n    \n    valid_results = []\n    for result in results:\n        if not result[\"success\"]:\n            print(f\"Skipping failed URL: {result['url']}\")\n            continue\n        \n        content = result[\"content\"]\n        \n        # Check content length\n        if len(content) < min_length:\n            print(f\"Skipping short content from {result['url']}\")\n            continue\n        \n        # Check for common error pages\n        error_indicators = [\n            \"404 not found\",\n            \"access denied\",\n            \"page not found\",\n            \"forbidden\"\n        ]\n        \n        if any(indicator in content.lower() for indicator in error_indicators):\n            print(f\"Detected error page: {result['url']}\")\n            continue\n        \n        valid_results.append(result)\n    \n    return valid_results\n```\n\n### 3. Caching and Storage\n\n```python\nimport json\nimport hashlib\nfrom datetime import datetime, timedelta\n\nclass ScrapingCache:\n    def __init__(self, cache_file=\"scraping_cache.json\", cache_duration_hours=24):\n        self.cache_file = cache_file\n        self.cache_duration = timedelta(hours=cache_duration_hours)\n        self.cache = self._load_cache()\n    \n    def _load_cache(self):\n        try:\n            with open(self.cache_file, 'r') as f:\n                return json.load(f)\n        except FileNotFoundError:\n            return {}\n    \n    def _save_cache(self):\n        with open(self.cache_file, 'w') as f:\n            json.dump(self.cache, f, indent=2)\n    \n    def _get_cache_key(self, url, format_type):\n        return hashlib.md5(f\"{url}:{format_type}\".encode()).hexdigest()\n    \n    def get_cached_result(self, url, format_type=\"markdown\"):\n        cache_key = self._get_cache_key(url, format_type)\n        \n        if cache_key in self.cache:\n            cached_item = self.cache[cache_key]\n            cached_time = datetime.fromisoformat(cached_item[\"timestamp\"])\n            \n            if datetime.now() - cached_time < self.cache_duration:\n                return cached_item[\"result\"]\n        \n        return None\n    \n    def cache_result(self, url, format_type, result):\n        cache_key = self._get_cache_key(url, format_type)\n        \n        self.cache[cache_key] = {\n            \"timestamp\": datetime.now().isoformat(),\n            \"result\": result\n        }\n        \n        self._save_cache()\n    \n    def scrape_with_cache(self, urls, format_type=\"markdown\"):\n        cached_results = []\n        urls_to_scrape = []\n        \n        # Check cache first\n        for url in urls:\n            cached = self.get_cached_result(url, format_type)\n            if cached:\n                cached_results.append(cached)\n            else:\n                urls_to_scrape.append(url)\n        \n        # Scrape uncached URLs\n        if urls_to_scrape:\n            response = requests.post(\n                \"https://api.cxmpute.cloud/v1/scrape\",\n                headers=headers,\n                json={\"urls\": urls_to_scrape, \"format\": format_type}\n            )\n            \n            if response.status_code == 200:\n                new_results = response.json()[\"results\"]\n                \n                # Cache new results\n                for result in new_results:\n                    self.cache_result(result[\"url\"], format_type, result)\n                \n                cached_results.extend(new_results)\n        \n        return cached_results\n\n# Usage\ncache = ScrapingCache(cache_duration_hours=6)\nresults = cache.scrape_with_cache([\"https://example.com\", \"https://test.com\"])\n```\n\n## Pricing\n\nDuring our **testnet phase**, web scraping services are completely **free**! Once we transition to mainnet:\n\n- **Standard Scraping**: ~$0.02-0.10 per request\n- **Batch Discounts**: Available for high-volume usage\n- **Premium Features**: Enhanced extraction and custom parsing\n\n## Error Handling\n\nCommon error codes and solutions:\n\n- `400`: Invalid URL or malformed request\n- `403`: Access denied or blocked by target site\n- `404`: Page not found\n- `408`: Request timeout\n- `503`: No scraping providers available\n\n## Support\n\n- **Discord**: [Community support](https://discord.com/invite/CJGA7B2zKT)\n- **Documentation**: [Complete API reference](/docs/user)\n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready to extract web content?** Start building data collection pipelines with our reliable scraping service! ",
  "text-to-speech": "# Text-to-Speech\n\nConvert text to natural, high-quality speech using Cxmpute's distributed text-to-speech service.\n\n## Overview\n\nCxmpute's Text-to-Speech (TTS) service transforms written text into lifelike audio using advanced voice synthesis models. Our global network of providers ensures fast generation times and high availability.\n\n### Key Features\n\n- **High-Quality Audio**: Professional-grade voice synthesis\n- **Multiple Voices**: Various voice models and styles\n- **Fast Generation**: Optimized for speed and reliability\n- **Global Network**: Low-latency access worldwide\n- **Simple API**: Easy integration with any application\n\n## Quick Start\n\n### Basic Request\n\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/tts \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"text\": \"Welcome to Cxmpute! This is a demonstration of our text-to-speech service.\",\n    \"voice\": \"af_bella\"\n  }' \\\n  --output welcome.wav\n```\n\n### Python Example\n\n```python\nimport requests\n\nurl = \"https://api.cxmpute.cloud/v1/tts\"\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"YOUR_USER_ID\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"text\": \"Hello from Cxmpute!\",\n    \"voice\": \"af_bella\"\n}\n\nresponse = requests.post(url, headers=headers, json=data)\n\nif response.status_code == 200:\n    with open(\"output.wav\", \"wb\") as f:\n        f.write(response.content)\n    print(\"Audio saved as output.wav\")\nelse:\n    print(f\"Error: {response.status_code}\")\n```\n\n### JavaScript Example\n\n```javascript\nconst fs = require('fs');\n\nasync function generateSpeech() {\n  const response = await fetch('https://api.cxmpute.cloud/v1/tts', {\n    method: 'POST',\n    headers: {\n      'Authorization': 'Bearer YOUR_API_KEY',\n      'X-User-Id': 'YOUR_USER_ID',\n      'Content-Type': 'application/json'\n    },\n    body: JSON.stringify({\n      text: 'This is generated using Cxmpute TTS!',\n      voice: 'af_bella'\n    })\n  });\n\n  if (response.ok) {\n    const buffer = await response.arrayBuffer();\n    fs.writeFileSync('speech.wav', Buffer.from(buffer));\n    console.log('Audio saved as speech.wav');\n  } else {\n    console.error('Error:', response.status);\n  }\n}\n\ngenerateSpeech();\n```\n\n## API Reference\n\n### Endpoint\n\n```http\nPOST /v1/tts\n```\n\n### Request Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `text` | string | Yes | Text to convert to speech (max 10,000 characters) |\n| `voice` | string | No | Voice model to use (default: \"af_bella\") |\n\n### Available Voices\n\n| Voice | Description | Language | Style |\n|-------|-------------|----------|-------|\n| `af_bella` | Warm, professional female voice | English | Clear, pleasant |\n| `af_nicole` | Energetic female voice | English | Upbeat, dynamic |\n| `af_sarah` | Calm, soothing female voice | English | Gentle, relaxed |\n| `am_adam` | Professional male voice | English | Authoritative, clear |\n| `am_michael` | Friendly male voice | English | Warm, approachable |\n\n*More voices are continuously being added to our network.*\n\n### Response\n\nThe endpoint returns raw audio data in WAV format:\n\n- **Content-Type**: `audio/wav`\n- **Format**: 16-bit PCM WAV\n- **Sample Rate**: 22,050 Hz\n- **Channels**: Mono\n\n### Error Responses\n\n```json\n{\n  \"error\": \"Missing 'text' field.\"\n}\n```\n\nCommon error codes:\n- `400`: Bad request (missing text, text too long)\n- `401`: Unauthorized (invalid API key)\n- `503`: Service unavailable (no TTS providers online)\n- `500`: Internal server error\n\n## Use Cases\n\n### 1. **Content Creation**\n\nGenerate voiceovers for videos, podcasts, and presentations:\n\n```python\ndef create_voiceover(script_segments):\n    audio_files = []\n    \n    for i, text in enumerate(script_segments):\n        response = requests.post(\n            \"https://api.cxmpute.cloud/v1/tts\",\n            headers=headers,\n            json={\"text\": text, \"voice\": \"af_bella\"}\n        )\n        \n        filename = f\"segment_{i}.wav\"\n        with open(filename, \"wb\") as f:\n            f.write(response.content)\n        audio_files.append(filename)\n    \n    return audio_files\n```\n\n### 2. **Accessibility Features**\n\nAdd screen reading capabilities to applications:\n\n```javascript\nasync function speakText(text) {\n  const audio = await generateSpeech(text);\n  const audioUrl = URL.createObjectURL(new Blob([audio]));\n  const audioElement = new Audio(audioUrl);\n  audioElement.play();\n}\n\n// Usage\ndocument.addEventListener('click', (e) => {\n  if (e.target.dataset.speak) {\n    speakText(e.target.textContent);\n  }\n});\n```\n\n### 3. **Language Learning**\n\nCreate pronunciation examples for educational apps:\n\n```python\ndef create_pronunciation_guide(phrases):\n    for phrase in phrases:\n        # Generate audio for the phrase\n        audio_response = requests.post(\n            \"https://api.cxmpute.cloud/v1/tts\",\n            headers=headers,\n            json={\n                \"text\": phrase[\"text\"],\n                \"voice\": \"af_sarah\"  # Clear, educational voice\n            }\n        )\n        \n        # Save with metadata\n        filename = f\"pronunciation_{phrase['id']}.wav\"\n        with open(filename, \"wb\") as f:\n            f.write(audio_response.content)\n```\n\n### 4. **Interactive Applications**\n\nAdd voice responses to chatbots and virtual assistants:\n\n```python\ndef voice_assistant_response(user_message):\n    # Get AI response\n    chat_response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.1:8b\",\n            \"messages\": [{\"role\": \"user\", \"content\": user_message}]\n        }\n    )\n    \n    ai_text = chat_response.json()[\"choices\"][0][\"message\"][\"content\"]\n    \n    # Convert to speech\n    tts_response = requests.post(\n        \"https://api.cxmpute.cloud/v1/tts\",\n        headers=headers,\n        json={\"text\": ai_text, \"voice\": \"af_nicole\"}\n    )\n    \n    return tts_response.content\n```\n\n### 5. **Notification Systems**\n\nCreate audio alerts and announcements:\n\n```python\ndef create_audio_notification(message, urgency=\"normal\"):\n    voice_map = {\n        \"normal\": \"af_bella\",\n        \"urgent\": \"am_adam\",\n        \"calm\": \"af_sarah\"\n    }\n    \n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/tts\",\n        headers=headers,\n        json={\n            \"text\": message,\n            \"voice\": voice_map.get(urgency, \"af_bella\")\n        }\n    )\n    \n    return response.content\n```\n\n## Advanced Usage\n\n### Batch Processing\n\nGenerate multiple audio files efficiently:\n\n```python\nimport concurrent.futures\nimport requests\n\ndef generate_single_audio(text_item):\n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/tts\",\n        headers=headers,\n        json={\n            \"text\": text_item[\"text\"],\n            \"voice\": text_item.get(\"voice\", \"af_bella\")\n        }\n    )\n    \n    return {\n        \"id\": text_item[\"id\"],\n        \"audio\": response.content if response.ok else None,\n        \"error\": None if response.ok else response.text\n    }\n\ndef batch_generate_audio(text_items, max_workers=5):\n    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n        results = list(executor.map(generate_single_audio, text_items))\n    \n    return results\n\n# Usage\ntexts = [\n    {\"id\": \"intro\", \"text\": \"Welcome to our service!\", \"voice\": \"af_bella\"},\n    {\"id\": \"guide\", \"text\": \"Here's how to get started...\", \"voice\": \"af_sarah\"},\n    {\"id\": \"thanks\", \"text\": \"Thank you for using our app!\", \"voice\": \"af_nicole\"}\n]\n\nresults = batch_generate_audio(texts)\nfor result in results:\n    if result[\"audio\"]:\n        with open(f\"{result['id']}.wav\", \"wb\") as f:\n            f.write(result[\"audio\"])\n```\n\n### Error Handling\n\nRobust error handling for production applications:\n\n```python\nimport time\nimport logging\n\ndef reliable_tts_request(text, voice=\"af_bella\", max_retries=3):\n    headers = {\n        \"Authorization\": f\"Bearer {API_KEY}\",\n        \"X-User-Id\": USER_ID,\n        \"Content-Type\": \"application/json\"\n    }\n    \n    for attempt in range(max_retries):\n        try:\n            response = requests.post(\n                \"https://api.cxmpute.cloud/v1/tts\",\n                headers=headers,\n                json={\"text\": text, \"voice\": voice},\n                timeout=30\n            )\n            \n            if response.status_code == 200:\n                return response.content\n            elif response.status_code == 503:\n                # No providers available, wait and retry\n                logging.warning(f\"No TTS providers available, attempt {attempt + 1}\")\n                time.sleep(2 ** attempt)  # Exponential backoff\n                continue\n            else:\n                response.raise_for_status()\n                \n        except requests.exceptions.RequestException as e:\n            logging.error(f\"TTS request failed: {e}\")\n            if attempt == max_retries - 1:\n                raise\n            time.sleep(1)\n    \n    raise Exception(\"TTS request failed after all retries\")\n```\n\n### Streaming Integration\n\nFor real-time applications, combine with streaming text generation:\n\n```python\nasync def streaming_tts_response(prompt):\n    \"\"\"Generate text and immediately convert to speech\"\"\"\n    \n    # Stream text response\n    text_response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.1:8b\",\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"stream\": True\n        },\n        stream=True\n    )\n    \n    accumulated_text = \"\"\n    sentences = []\n    \n    for line in text_response.iter_lines():\n        if line.startswith(b\"data: \"):\n            try:\n                data = json.loads(line[6:])\n                if \"choices\" in data and data[\"choices\"]:\n                    content = data[\"choices\"][0].get(\"delta\", {}).get(\"content\", \"\")\n                    accumulated_text += content\n                    \n                    # Check for sentence boundaries\n                    if any(punct in content for punct in ['.', '!', '?']):\n                        # Extract complete sentences\n                        new_sentences = extract_sentences(accumulated_text)\n                        for sentence in new_sentences[len(sentences):]:\n                            # Generate TTS for each complete sentence\n                            audio = generate_tts(sentence)\n                            yield audio\n                        sentences = new_sentences\n                        \n            except json.JSONDecodeError:\n                continue\n```\n\n## Best Practices\n\n### 1. **Text Optimization**\n\nPrepare text for optimal speech generation:\n\n```python\nimport re\n\ndef optimize_text_for_tts(text):\n    # Expand abbreviations\n    abbreviations = {\n        \"Mr.\": \"Mister\",\n        \"Dr.\": \"Doctor\",\n        \"Inc.\": \"Incorporated\",\n        \"Ltd.\": \"Limited\",\n        \"etc.\": \"et cetera\",\n        \"e.g.\": \"for example\",\n        \"i.e.\": \"that is\"\n    }\n    \n    for abbr, expansion in abbreviations.items():\n        text = text.replace(abbr, expansion)\n    \n    # Handle numbers\n    text = re.sub(r'\\b(\\d+)\\b', lambda m: num_to_words(int(m.group(1))), text)\n    \n    # Clean up extra whitespace\n    text = re.sub(r'\\s+', ' ', text).strip()\n    \n    return text\n\ndef num_to_words(n):\n    # Simple number to words conversion\n    ones = [\"\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\"]\n    teens = [\"ten\", \"eleven\", \"twelve\", \"thirteen\", \"fourteen\", \"fifteen\", \"sixteen\", \"seventeen\", \"eighteen\", \"nineteen\"]\n    tens = [\"\", \"\", \"twenty\", \"thirty\", \"forty\", \"fifty\", \"sixty\", \"seventy\", \"eighty\", \"ninety\"]\n    \n    if n < 10:\n        return ones[n]\n    elif n < 20:\n        return teens[n-10]\n    elif n < 100:\n        return tens[n//10] + (\"\" if n%10 == 0 else \" \" + ones[n%10])\n    # Add more cases as needed\n    else:\n        return str(n)  # Fallback to digit representation\n```\n\n### 2. **Voice Selection**\n\nChoose appropriate voices for different contexts:\n\n```python\ndef select_voice_for_content(content_type, target_audience=\"general\"):\n    voice_map = {\n        (\"educational\", \"children\"): \"af_sarah\",\n        (\"educational\", \"adults\"): \"af_bella\",\n        (\"commercial\", \"general\"): \"af_nicole\",\n        (\"technical\", \"general\"): \"am_adam\",\n        (\"announcement\", \"general\"): \"am_michael\",\n        (\"storytelling\", \"children\"): \"af_sarah\",\n        (\"news\", \"general\"): \"am_adam\"\n    }\n    \n    return voice_map.get((content_type, target_audience), \"af_bella\")\n\n# Usage\nvoice = select_voice_for_content(\"educational\", \"adults\")\n```\n\n### 3. **Caching Strategy**\n\nImplement intelligent caching for repeated content:\n\n```python\nimport hashlib\nimport os\n\nclass TTSCache:\n    def __init__(self, cache_dir=\"tts_cache\"):\n        self.cache_dir = cache_dir\n        os.makedirs(cache_dir, exist_ok=True)\n    \n    def get_cache_key(self, text, voice):\n        content = f\"{text}:{voice}\"\n        return hashlib.md5(content.encode()).hexdigest()\n    \n    def get_cached_audio(self, text, voice):\n        cache_key = self.get_cache_key(text, voice)\n        cache_file = os.path.join(self.cache_dir, f\"{cache_key}.wav\")\n        \n        if os.path.exists(cache_file):\n            with open(cache_file, \"rb\") as f:\n                return f.read()\n        return None\n    \n    def cache_audio(self, text, voice, audio_data):\n        cache_key = self.get_cache_key(text, voice)\n        cache_file = os.path.join(self.cache_dir, f\"{cache_key}.wav\")\n        \n        with open(cache_file, \"wb\") as f:\n            f.write(audio_data)\n    \n    def generate_or_get_cached(self, text, voice=\"af_bella\"):\n        # Check cache first\n        cached_audio = self.get_cached_audio(text, voice)\n        if cached_audio:\n            return cached_audio\n        \n        # Generate new audio\n        response = requests.post(\n            \"https://api.cxmpute.cloud/v1/tts\",\n            headers=headers,\n            json={\"text\": text, \"voice\": voice}\n        )\n        \n        if response.ok:\n            audio_data = response.content\n            self.cache_audio(text, voice, audio_data)\n            return audio_data\n        \n        raise Exception(f\"TTS generation failed: {response.status_code}\")\n\n# Usage\ntts_cache = TTSCache()\naudio = tts_cache.generate_or_get_cached(\"Welcome to our service!\", \"af_bella\")\n```\n\n## Pricing\n\nDuring our **testnet phase**, TTS services are completely **free**! Once we transition to mainnet, pricing will be:\n\n- **Base Rate**: ~$0.05-0.15 per request\n- **Volume Discounts**: Available for high usage\n- **Provider Network**: Competitive rates through decentralized providers\n\n## Support & Community\n\n- **Discord**: Join our [community](https://discord.com/invite/CJGA7B2zKT) for TTS tips and support\n- **Documentation**: [Complete API reference](/docs/user)\n- **Examples**: Find more examples in our [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready to add voice to your applications?** Start with our simple API and create engaging audio experiences for your users! ",
  "text-to-text": "# Text-to-Text (LLM)\n\nGenerate human-like text responses using state-of-the-art language models through Cxmpute's distributed AI network.\n\n## Overview\n\nCxmpute's Text-to-Text service provides access to powerful large language models (LLMs) for chat completions, text generation, and conversational AI. Our **OpenAI-compatible API** makes it easy to integrate with existing applications.\n\n### Key Features\n\n- **OpenAI Compatibility**: Drop-in replacement for OpenAI's chat completions API\n- **Multiple Models**: Access to dozens of popular LLMs\n- **Streaming Support**: Real-time response generation\n- **Global Network**: Low-latency access through distributed providers\n- **Advanced Features**: Tool calling, JSON mode, and custom formats\n\n## Quick Start\n\n### Basic Chat Completion\n\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/chat/completions \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Explain quantum computing in simple terms.\"}\n    ]\n  }'\n```\n\n### Python Example\n\n```python\nimport requests\n\nurl = \"https://api.cxmpute.cloud/v1/chat/completions\"\nheaders = {\n    \"Authorization\": \"Bearer YOUR_API_KEY\",\n    \"X-User-Id\": \"YOUR_USER_ID\",\n    \"Content-Type\": \"application/json\"\n}\n\ndata = {\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"Write a short story about AI and humanity.\"}\n    ],\n    \"temperature\": 0.7,\n    \"max_tokens\": 500\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n\nprint(result[\"choices\"][0][\"message\"][\"content\"])\n```\n\n### Using OpenAI Library\n\n```python\nimport openai\n\nclient = openai.OpenAI(\n    api_key=\"YOUR_API_KEY\",\n    base_url=\"https://api.cxmpute.cloud/v1\",\n    default_headers={\"X-User-Id\": \"YOUR_USER_ID\"}\n)\n\nresponse = client.chat.completions.create(\n    model=\"llama3.1:8b\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a helpful AI assistant.\"},\n        {\"role\": \"user\", \"content\": \"What are the benefits of renewable energy?\"}\n    ]\n)\n\nprint(response.choices[0].message.content)\n```\n\n## API Reference\n\n### Endpoint\n\n```http\nPOST /v1/chat/completions\n```\n\n### Request Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `model` | string | Yes | Model name (see available models) |\n| `messages` | array | Yes | Array of message objects |\n| `stream` | boolean | No | Enable streaming responses (default: false) |\n| `temperature` | number | No | Sampling temperature 0-2 (default: 0.7) |\n| `max_tokens` | number | No | Maximum tokens to generate |\n| `top_p` | number | No | Nucleus sampling parameter (0-1) |\n| `response_format` | object | No | Response format specification |\n| `tools` | array | No | Available tools for function calling |\n\n### Available Models\n\n| Model | Size | Description | Best For |\n|-------|------|-------------|----------|\n| `llama3.1:8b` | 8B | Fast, general-purpose | Most applications |\n| `llama3.1:70b` | 70B | High-quality responses | Complex reasoning |\n| `codellama:13b` | 13B | Code generation | Programming tasks |\n| `mixtral:8x7b` | 8x7B | Mixture of experts | Specialized tasks |\n| `qwen2.5:14b` | 14B | Balanced performance | General use |\n\n*See our full [model catalog](https://cxmpute.cloud/models) for more options.*\n\n## Streaming Responses\n\n### Enable Streaming\n\n```python\nimport requests\nimport json\n\ndef stream_chat_completion(messages, model=\"llama3.1:8b\"):\n    url = \"https://api.cxmpute.cloud/v1/chat/completions\"\n    headers = {\n        \"Authorization\": \"Bearer YOUR_API_KEY\",\n        \"X-User-Id\": \"YOUR_USER_ID\",\n        \"Content-Type\": \"application/json\"\n    }\n    \n    data = {\n        \"model\": model,\n        \"messages\": messages,\n        \"stream\": True\n    }\n    \n    response = requests.post(url, headers=headers, json=data, stream=True)\n    \n    for line in response.iter_lines():\n        if line.startswith(b\"data: \"):\n            chunk = line[6:]  # Remove \"data: \" prefix\n            if chunk == b\"[DONE]\":\n                break\n            \n            try:\n                data = json.loads(chunk)\n                if \"choices\" in data and data[\"choices\"]:\n                    delta = data[\"choices\"][0].get(\"delta\", {})\n                    if \"content\" in delta:\n                        yield delta[\"content\"]\n            except json.JSONDecodeError:\n                continue\n\n# Usage\nmessages = [{\"role\": \"user\", \"content\": \"Write a poem about the ocean.\"}]\nfor chunk in stream_chat_completion(messages):\n    print(chunk, end=\"\", flush=True)\n```\n\n## Use Cases\n\n### 1. Chatbot Development\n\nBuild conversational AI applications:\n\n```python\nclass ChatBot:\n    def __init__(self, system_prompt=\"You are a helpful assistant.\"):\n        self.conversation_history = [\n            {\"role\": \"system\", \"content\": system_prompt}\n        ]\n    \n    def chat(self, user_message):\n        self.conversation_history.append({\n            \"role\": \"user\", \n            \"content\": user_message\n        })\n        \n        response = requests.post(\n            \"https://api.cxmpute.cloud/v1/chat/completions\",\n            headers=headers,\n            json={\n                \"model\": \"llama3.1:8b\",\n                \"messages\": self.conversation_history,\n                \"temperature\": 0.7\n            }\n        )\n        \n        ai_response = response.json()[\"choices\"][0][\"message\"][\"content\"]\n        \n        self.conversation_history.append({\n            \"role\": \"assistant\",\n            \"content\": ai_response\n        })\n        \n        return ai_response\n\n# Usage\nbot = ChatBot(\"You are a friendly coding assistant.\")\nresponse = bot.chat(\"How do I reverse a string in Python?\")\nprint(response)\n```\n\n### 2. Content Generation\n\nGenerate blog posts, articles, and marketing content:\n\n```python\ndef generate_blog_post(topic, tone=\"professional\", length=\"medium\"):\n    length_map = {\n        \"short\": \"Write a concise 300-word blog post\",\n        \"medium\": \"Write a comprehensive 800-word blog post\", \n        \"long\": \"Write a detailed 1500-word blog post\"\n    }\n    \n    prompt = f\"\"\"\n    {length_map[length]} about {topic}.\n    Tone: {tone}\n    Include:\n    - Engaging introduction\n    - Clear main points with examples\n    - Actionable takeaways\n    - Compelling conclusion\n    \"\"\"\n    \n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.1:70b\",\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.8,\n            \"max_tokens\": 2000\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Usage\narticle = generate_blog_post(\"sustainable energy solutions\", \"informative\", \"medium\")\nprint(article)\n```\n\n### 3. Code Generation\n\nGenerate and explain code:\n\n```python\ndef code_assistant(task, language=\"python\"):\n    prompt = f\"\"\"\n    Task: {task}\n    Language: {language}\n    \n    Please provide:\n    1. Clean, well-commented code\n    2. Explanation of how it works\n    3. Example usage\n    4. Best practices\n    \"\"\"\n    \n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"codellama:13b\",\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": 0.3\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n\n# Usage\ncode_help = code_assistant(\"Create a REST API endpoint for user authentication using Flask\")\nprint(code_help)\n```\n\n## Best Practices\n\n### 1. Temperature Control\n\nAdjust response creativity:\n\n```python\ndef generate_with_creativity(prompt, creativity_level=\"balanced\"):\n    temperature_map = {\n        \"factual\": 0.1,      # Very consistent, factual responses\n        \"balanced\": 0.7,     # Good balance of accuracy and creativity\n        \"creative\": 1.2,     # More creative and diverse responses\n    }\n    \n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": \"llama3.1:8b\",\n            \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n            \"temperature\": temperature_map[creativity_level]\n        }\n    )\n    \n    return response.json()[\"choices\"][0][\"message\"][\"content\"]\n```\n\n### 2. Error Handling\n\nImplement robust error handling:\n\n```python\nimport time\nimport random\n\ndef resilient_chat_completion(messages, model=\"llama3.1:8b\", max_retries=3):\n    for attempt in range(max_retries):\n        try:\n            response = requests.post(\n                \"https://api.cxmpute.cloud/v1/chat/completions\",\n                headers=headers,\n                json={\n                    \"model\": model,\n                    \"messages\": messages,\n                    \"temperature\": 0.7\n                },\n                timeout=60\n            )\n            \n            if response.status_code == 200:\n                return response.json()\n            elif response.status_code == 503:\n                wait_time = (2 ** attempt) + random.uniform(0, 1)\n                time.sleep(wait_time)\n                continue\n            else:\n                response.raise_for_status()\n                \n        except requests.exceptions.RequestException as e:\n            if attempt == max_retries - 1:\n                raise e\n            time.sleep(1)\n    \n    raise Exception(\"Failed to get response after all retries\")\n```\n\n## Pricing\n\nDuring our **testnet phase**, all LLM services are completely **free**! Once we transition to mainnet:\n\n- **Small Models** (7B-8B): ~$0.10-0.20 per 1K tokens\n- **Medium Models** (13B-30B): ~$0.20-0.40 per 1K tokens  \n- **Large Models** (70B+): ~$0.40-0.80 per 1K tokens\n\n## Support\n\n- **Discord**: [Community support](https://discord.com/invite/CJGA7B2zKT)\n- **Documentation**: [Complete API reference](/docs/user) \n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n- **Model Catalog**: [Browse all available models](https://cxmpute.cloud/models)\n\n---\n\n**Ready to build with AI?** Start with our OpenAI-compatible API and create intelligent applications powered by the world's best language models! ",
  "tool-use-json": "# Tool Use & JSON Mode\n\nEnable function calling and structured outputs with Cxmpute's advanced language models.\n\n## Overview\n\nCxmpute supports tool calling and structured outputs, allowing models to interact with external functions, APIs, and return data in specific JSON formats.\n\n### Key Features\n\n- **Function Calling**: Models can call predefined functions and tools\n- **Structured Outputs**: Force models to return specific JSON schemas\n- **OpenAI Compatible**: Works with existing OpenAI tool calling code\n- **Multiple Models**: Available on supported models (Llama 3.1, Mixtral, etc.)\n\n## Tool Calling\n\nEnable models to call functions and interact with external systems.\n\n### Basic Example\n\n```python\nimport requests\n\n# Define available tools\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_weather\",\n            \"description\": \"Get the current weather for a city\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"city\": {\n                        \"type\": \"string\",\n                        \"description\": \"The name of the city\"\n                    }\n                },\n                \"required\": [\"city\"]\n            }\n        }\n    }\n]\n\ndata = {\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [\n        {\"role\": \"user\", \"content\": \"What's the weather in New York?\"}\n    ],\n    \"tools\": tools\n}\n\nresponse = requests.post(url, headers=headers, json=data)\nresult = response.json()\n\n# Check if model wants to call a function\nif result[\"choices\"][0][\"message\"].get(\"tool_calls\"):\n    tool_call = result[\"choices\"][0][\"message\"][\"tool_calls\"][0]\n    function_name = tool_call[\"function\"][\"name\"]\n    function_args = tool_call[\"function\"][\"arguments\"]\n    \n    print(f\"Model wants to call: {function_name}\")\n    print(f\"With arguments: {function_args}\")\n```\n\n## JSON Mode\n\nForce models to return data in specific JSON formats.\n\n### Basic JSON Response\n\n```python\ndef get_structured_response(prompt, model=\"llama3.1:8b\"):\n    response = requests.post(\n        \"https://api.cxmpute.cloud/v1/chat/completions\",\n        headers=headers,\n        json={\n            \"model\": model,\n            \"messages\": [\n                {\"role\": \"user\", \"content\": f\"{prompt}\\n\\nRespond with valid JSON only.\"}\n            ],\n            \"response_format\": {\n                \"type\": \"json_object\"\n            }\n        }\n    )\n    \n    return json.loads(response.json()[\"choices\"][0][\"message\"][\"content\"])\n\n# Usage\nprompt = \"Analyze this review: 'Great product, but expensive.'\"\nresult = get_structured_response(prompt)\nprint(json.dumps(result, indent=2))\n```\n\n## Use Cases\n\n### 1. Data Extraction\n\nExtract structured information from unstructured text.\n\n### 2. API Integration\n\nCreate tools that interact with external APIs and services.\n\n### 3. Content Classification\n\nAutomatically classify and tag content with structured metadata.\n\n### 4. Form Processing\n\nProcess documents and forms into structured data.\n\n## Supported Models\n\nTool calling and JSON mode are available on:\n\n- ‚úÖ **Llama 3.1** (8B, 70B) - Full support\n- ‚úÖ **Mixtral 8x7B** - Tool calling support\n- ‚úÖ **Qwen 2.5** - JSON mode support\n- üöß **Other models** - Basic JSON formatting\n\n## Examples\n\nVisit our [GitHub repository](https://github.com/unxversal/cxmpute-core) for complete examples and tutorials.\n\n## Support\n\n- **Discord**: [Community support](https://discord.com/invite/CJGA7B2zKT)\n- **Documentation**: [Complete API reference](/docs/user)\n- **Examples**: [GitHub repository](https://github.com/unxversal/cxmpute-core)\n\n---\n\n**Ready to build intelligent applications?** Use our tool calling and structured outputs to create AI systems that can interact with the real world! ",
  "user": "# User Guide\n\nWelcome to Cxmpute! This guide will help you get started using our AI services through our simple, OpenAI-compatible APIs.\n\n## Overview\n\nCxmpute provides an inference and related services powered by a global network of nodes run by providers. We offer:\n\n- **LLM inference** with dozens of popular models\n- **Text embeddings** for semantic search and RAG applications  \n- **Text-to-speech** with natural voice synthesis\n- **Web scraping** with intelligent content extraction\n- **Tool use and JSON mode** for structured outputs\n\nLearn more about specific use cases:\n- [Text-to-Speech](/docs/text-to-speech)\n- [Text-to-Text (LLM)](/docs/text-to-text) \n- [Embeddings](/docs/embeddings)\n- [Web Scraping](/docs/scraping)\n- [Tool Use & JSON](/docs/tool-use-json)\n- [Advanced LLMs](/docs/advanced-llms)\n\n## Getting Started\n\n### 1. Create Your Account\n\nGo to the [Cxmpute Dashboard](https://cxmpute.cloud/dashboard) to create your account.\n\n### 2. Get Your API Key\n\nWhen your account is created, you'll see your base user API key. This key has **no limits** in terms of usage and accessible services during our testnet phase.\n\n‚ö†Ô∏è **Important**: Practice good key management. Never expose your API keys in client-side code or public repositories. If your key has been compromised, refresh it immediately in the dashboard.\n\n### 3. Create Virtual API Keys (Optional)\n\nYou can create virtual API keys with specific limitations:\n- **Spend limits**: Set maximum credit usage\n- **Service restrictions**: Limit access to specific endpoints\n- **Usage tracking**: Monitor usage per key\n\n## Authentication\n\nAll API requests require authentication using your API key:\n\n```bash\nAuthorization: Bearer YOUR_API_KEY\nX-User-Id: YOUR_USER_ID\n```\n\n### Required Headers\n\n- `Authorization`: Your API key in Bearer token format\n- `X-User-Id`: Your user ID from the dashboard\n- `Content-Type: application/json` (for POST requests)\n\n### Optional Headers\n\n- `X-Title`: Service title for analytics\n- `HTTP-Referer`: Service URL for analytics\n\n## Base URL\n\nAll API endpoints use the base URL:\n```\nhttps://api.cxmpute.cloud\n```\n\n## API Reference\n\n### Chat Completions\n\n**OpenAI-compatible endpoint** for text generation and conversations.\n\n```http\nPOST /v1/chat/completions\n```\n\n#### Request Body\n\n```json\n{\n  \"model\": \"llama3.1:8b\",\n  \"messages\": [\n    {\"role\": \"user\", \"content\": \"Hello, how are you?\"}\n  ],\n  \"stream\": false,\n  \"temperature\": 0.7,\n  \"max_tokens\": 1000\n}\n```\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `model` | string | Yes | Model name (see [model catalog](https://cxmpute.cloud/models)) |\n| `messages` | array | Yes | Array of message objects with `role` and `content` |\n| `stream` | boolean | No | Enable streaming responses (default: false) |\n| `temperature` | number | No | Sampling temperature 0-2 (default: 0.7) |\n| `max_tokens` | number | No | Maximum tokens to generate |\n| `top_p` | number | No | Nucleus sampling parameter |\n| `response_format` | string/object | No | Response format (see [JSON mode](/docs/tool-use-json)) |\n| `tools` | array | No | Available tools for function calling |\n\n#### Response\n\n**Non-streaming:**\n```json\n{\n  \"id\": \"chatcmpl-123\",\n  \"object\": \"chat.completion\",\n  \"created\": 1677652288,\n  \"model\": \"llama3.1:8b\",\n  \"choices\": [{\n    \"index\": 0,\n    \"message\": {\n      \"role\": \"assistant\",\n      \"content\": \"Hello! I'm doing well, thank you for asking. How can I help you today?\"\n    },\n    \"finish_reason\": \"stop\"\n  }],\n  \"usage\": {\n    \"prompt_tokens\": 10,\n    \"completion_tokens\": 20,\n    \"total_tokens\": 30\n  }\n}\n```\n\n**Streaming:**\n```\ndata: {\"choices\":[{\"delta\":{\"content\":\"Hello\"}}]}\ndata: {\"choices\":[{\"delta\":{\"content\":\"!\"}}]}\ndata: [DONE]\n```\n\n#### Example\n\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/chat/completions \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"llama3.1:8b\",\n    \"messages\": [\n      {\"role\": \"user\", \"content\": \"Write a haiku about AI\"}\n    ],\n    \"temperature\": 0.8\n  }'\n```\n\n### Embeddings\n\nGenerate vector embeddings for text.\n\n```http\nPOST /v1/embeddings\n```\n\n#### Request Body\n\n```json\n{\n  \"model\": \"nomic-embed-text\",\n  \"input\": \"Your text to embed\",\n  \"truncate\": true\n}\n```\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `model` | string | Yes | Embedding model name |\n| `input` | string/array | Yes | Text(s) to embed |\n| `truncate` | boolean | No | Truncate input to model's max length |\n\n#### Response\n\n```json\n{\n  \"object\": \"list\",\n  \"data\": [{\n    \"object\": \"embedding\",\n    \"embedding\": [0.1, -0.2, 0.3, ...],\n    \"index\": 0\n  }],\n  \"model\": \"nomic-embed-text\",\n  \"usage\": {\n    \"prompt_tokens\": 8,\n    \"total_tokens\": 8\n  }\n}\n```\n\n#### Example\n\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/embeddings \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"model\": \"nomic-embed-text\",\n    \"input\": \"This is a sample text for embedding\"\n  }'\n```\n\n### Text-to-Speech\n\nConvert text to natural speech.\n\n```http\nPOST /v1/tts\n```\n\n#### Request Body\n\n```json\n{\n  \"text\": \"Hello, this is a test of text to speech.\",\n  \"voice\": \"af_bella\"\n}\n```\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `text` | string | Yes | Text to convert to speech |\n| `voice` | string | No | Voice model (default: \"af_bella\") |\n\n#### Response\n\nReturns audio data in WAV format with `Content-Type: audio/wav`.\n\n#### Example\n\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/tts \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"text\": \"Welcome to Cxmpute!\",\n    \"voice\": \"af_bella\"\n  }' \\\n  --output speech.wav\n```\n\n### Web Scraping\n\nExtract content from web pages.\n\n```http\nPOST /v1/scrape\n```\n\n#### Request Body\n\n```json\n{\n  \"urls\": [\"https://example.com\"],\n  \"format\": \"markdown\"\n}\n```\n\n#### Parameters\n\n| Parameter | Type | Required | Description |\n|-----------|------|----------|-------------|\n| `urls` | array | Yes | Array of URLs to scrape |\n| `format` | string | No | Output format: \"markdown\", \"text\", \"html\" |\n\n#### Response\n\n```json\n{\n  \"results\": [{\n    \"url\": \"https://example.com\",\n    \"content\": \"# Example Page\\n\\nThis is the content...\",\n    \"success\": true,\n    \"metadata\": {\n      \"title\": \"Example Page\",\n      \"description\": \"An example webpage\"\n    }\n  }]\n}\n```\n\n#### Example\n\n```bash\ncurl -X POST https://api.cxmpute.cloud/v1/scrape \\\n  -H \"Authorization: Bearer YOUR_API_KEY\" \\\n  -H \"X-User-Id: YOUR_USER_ID\" \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n    \"urls\": [\"https://docs.cxmpute.cloud\"],\n    \"format\": \"markdown\"\n  }'\n```\n\n## OpenAI Compatibility\n\nOur `/v1/chat/completions` endpoint is fully **OpenAI-compatible**! You can use existing OpenAI libraries by simply changing the base URL:\n\n### Python (OpenAI Library)\n\n```python\nimport openai\n\nclient = openai.OpenAI(\n    api_key=\"YOUR_API_KEY\",\n    base_url=\"https://api.cxmpute.cloud/v1\",\n    default_headers={\"X-User-Id\": \"YOUR_USER_ID\"}\n)\n\nresponse = client.chat.completions.create(\n    model=\"llama3.1:8b\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello!\"}\n    ]\n)\n```\n\n### JavaScript\n\n```javascript\nimport OpenAI from 'openai';\n\nconst openai = new OpenAI({\n  apiKey: 'YOUR_API_KEY',\n  baseURL: 'https://api.cxmpute.cloud/v1',\n  defaultHeaders: {\n    'X-User-Id': 'YOUR_USER_ID'\n  }\n});\n\nconst completion = await openai.chat.completions.create({\n  messages: [{ role: 'user', content: 'Hello!' }],\n  model: 'llama3.1:8b',\n});\n```\n\n## Model Catalog\n\nExplore our full model list at [cxmpute.cloud/models](https://cxmpute.cloud/models).\n\nPopular models include:\n- **llama3.1:8b** - Fast, capable general-purpose model\n- **llama3.1:70b** - Larger model for complex tasks\n- **nomic-embed-text** - High-quality text embeddings\n- **codellama:13b** - Specialized for code generation\n\nVisit specific model pages in our catalog to see their request formats and capabilities.\n\n## Testnet & Rewards\n\nüéâ **During our testnet phase, all services are currently free!** You also earn rewards based on usage and referrals.\n\n[Learn more about our rewards program ‚Üí](/docs/rewards)\n\n## Error Handling\n\n### HTTP Status Codes\n\n- `200` - Success\n- `400` - Bad Request (missing/invalid parameters)\n- `401` - Unauthorized (invalid API key)\n- `429` - Rate Limited\n- `503` - Service Unavailable (no healthy providers)\n- `500` - Internal Server Error\n\n### Error Response Format\n\n```json\n{\n  \"error\": \"Error description\"\n}\n```\n\n### Common Errors\n\n**Invalid API Key:**\n```json\n{\n  \"error\": \"Invalid API key\"\n}\n```\n\n**Missing Model:**\n```json\n{\n  \"error\": \"Missing required parameter: model or messages\"\n}\n```\n\n**No Providers Available:**\n```json\n{\n  \"error\": \"No provisions available for the requested model\"\n}\n```\n\n## Rate Limits\n\nDuring testnet, there are no strict rate limits. However, fair usage policies apply to ensure service availability for all users.\n\n## Support\n\nNeed help? We're here for you:\n\n- **Discord**: Join our [community](https://discord.com/invite/CJGA7B2zKT) for real-time support\n- **Email**: Contact support@cxmpute.cloud\n- **GitHub**: Report issues on our [repository](https://github.com/unxversal/cxmpute-core)\n\n## Next Steps\n\n- [Explore specific services](/docs) for detailed guides\n- [Learn about becoming a provider](/docs/provider) \n- [Join our Discord](https://discord.com/invite/CJGA7B2zKT) for the latest news\n- [Check out our model catalog](https://cxmpute.cloud/models) "
}